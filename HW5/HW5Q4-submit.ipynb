{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e28928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.distributions import Normal as norm\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e45c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45cabe",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5a7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((50,), (1.0,))])\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1.0,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f6c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not exist, download mnist dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, transform=trans, download=True)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24be868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "N = len(mnist_trainset)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3baca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_test = len(mnist_testset)\n",
    "N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fdfbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=mnist_trainset,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=mnist_testset,\n",
    "                batch_size=N_test,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1b7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "FF = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdce4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "Flatten torch.Size([128, 784])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "Flatten torch.Size([128, 784])\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for batch_idx, (example_data, example_targets) in enumerate(train_loader):\n",
    "    c += 1\n",
    "    print(example_data.shape)\n",
    "    print(example_targets.shape)\n",
    "    print(\"Flatten\", FF(example_data).shape)\n",
    "    if c ==2:   \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1471cf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd4d8b",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292fb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(nn.Module):\n",
    "    def __init__(self, mu, rho):\n",
    "        super(Gaussian, self).__init__()\n",
    "        self.norm   = norm(0,1)\n",
    "        self.mu_    = mu\n",
    "        self.rho_   = rho\n",
    "        self.sigma_ = torch.ones(self.mu_.shape).to(device)\n",
    "        \n",
    "        \n",
    "    def sample(self):\n",
    "        self.eps    = eps_scale * self.norm.sample(self.mu_.shape).type(self.mu_.type()).to(device)\n",
    "        self.sigma_ = eps_scale * torch.log(1 + torch.exp(self.rho_)).to(device)\n",
    "        self.W      = self.mu_  + self.sigma_ * self.eps\n",
    "        return self.W\n",
    "            \n",
    "    def loss(self):\n",
    "        return (0.5 * self.mu_**2 + 0.5 * eps_scale * self.sigma_ \n",
    "                - eps_scale * 0.5 * torch.log(1e-20 + self.sigma_)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552d31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blinear(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(Blinear, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.n_input  = n_input\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mu    = nn.Parameter(torch.Tensor(n_output, n_input).normal_(0., .05))  # or .01\n",
    "        self.rho   = nn.Parameter(torch.Tensor(n_output, n_input).uniform_(-3., -3.))\n",
    "        \n",
    "        self.W     = Gaussian(self.mu, self.rho)\n",
    "        \n",
    "        self.b_mu  = nn.Parameter(torch.Tensor(n_output).normal_(0., .05))\n",
    "        self.b_rho = nn.Parameter(torch.Tensor(n_output).uniform_(-3., -3.))\n",
    "        \n",
    "        self.b     = Gaussian(self.b_mu, self.b_rho)   \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        W = self.W.sample()\n",
    "        b = self.b.sample()\n",
    "        \n",
    "        return F.linear(x, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe5bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers, act):\n",
    "        super(BNet, self).__init__()\n",
    "        \n",
    "        self.act = act\n",
    "        self.fc  = nn.ModuleList()\n",
    "        self.flatten = nn.Flatten()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.fc.append(Blinear(layers[i], layers[i+1]))  \n",
    "            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        for i in range(len(self.fc) - 1):\n",
    "            x = self.fc[i].forward(x) #forward based on Blinear \n",
    "            x = self.act(x)\n",
    "            \n",
    "        x = F.log_softmax(self.fc[-1](x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c75b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN():\n",
    "    def __init__(self, train_loader, layers, act, n_epochs = 10000):\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.n_layers = len(layers)\n",
    "        \n",
    "        self.nepochs = n_epochs\n",
    "        self.BNet    = BNet(layers, act)\n",
    "        \n",
    "        self.History_learning = []\n",
    "        \n",
    "    def get_neg_elbo(self):\n",
    "        neg_elbo = 0\n",
    "        for i in range(self.n_layers-1):\n",
    "            neg_elbo += self.BNet.fc[i].W.loss()\n",
    "            neg_elbo += self.BNet.fc[i].b.loss()\n",
    "            \n",
    "        p_pred = self.BNet(self.x)\n",
    "        \n",
    "        return neg_elbo + N/batch_size * F.nll_loss(p_pred, self.y, reduction='sum') #sum or mean?\n",
    "\n",
    "#         return 1/(N//batch_size) * neg_elbo + N//batch_size * F.nll_loss(p_pred, self.y, reduction='sum')\n",
    "        \n",
    "#         loss_1 = 0\n",
    "#         for i in range(10):\n",
    "#             loss_1 += p_pred[self.y == i, i].sum()\n",
    "#         return neg_elbo - N/batch_size * loss_1\n",
    "        \n",
    "    \n",
    "    def train(self, lr, decay, step_size = 1000):\n",
    "    \n",
    "        optimizer = torch.optim.Adam(self.BNet.parameters(), lr = lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=decay)\n",
    "        \n",
    "        \n",
    "                        \n",
    "        with torch.no_grad():\n",
    "            for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "                A = example_data/126\n",
    "                b = example_targets\n",
    "            z = self.BNet(A).detach()\n",
    "            T_pred = torch.argmax(z, dim = 1)\n",
    "            self.History_learning.append((T_pred == b).sum()/len(T_pred)) \n",
    "        \n",
    "        for n in range(self.nepochs):\n",
    "            \n",
    "\n",
    "            \n",
    "            for batch_idx, (example_data, example_targets) in enumerate(train_loader):\n",
    "                \n",
    "                self.x = example_data/126\n",
    "                self.y = example_targets\n",
    "             \n",
    "                loss = self.get_neg_elbo()\n",
    "                if batch_idx %100 == 0:\n",
    "                    print(n, batch_idx)\n",
    "                    with torch.no_grad():\n",
    "                        print(\"Loss = \", loss.item())\n",
    "                        acc = 0\n",
    "                        pl = 0\n",
    "                        for i in range(100):\n",
    "                            p_pred = self.BNet(self.x).numpy()\n",
    "                            y_hat = np.argmax(p_pred, axis = 1)\n",
    "                            acc += (self.y.numpy() == y_hat).astype(int).mean()\n",
    "                    \n",
    "                        print(colored('learning rate:{}'.format(optimizer.param_groups[0]['lr']), 'blue'))\n",
    "                        print(colored('Train accuracy for iteration {} is {}'.format(n, acc/100), 'red'))\n",
    "#                         print('Predictive log-likelihood for trainat iteration {} is {}'.format(n, pl/100))\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "                    A = example_data/126\n",
    "                    b = example_targets\n",
    "                z = self.BNet(A).detach()\n",
    "                T_pred = torch.argmax(z, dim = 1)\n",
    "                self.History_learning.append((T_pred == b).sum()/len(T_pred))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79fed219",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eps_scale = 1\n",
    "# for lr in [1e-3, 1e-4, 1e-5]:\n",
    "#     for l in [400, 800, 1200]:\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         model = BNN(train_loader, [784, l, l, 10], act = nn.ReLU(), n_epochs = 20)\n",
    "#         model.train(lr = lr, decay = 1)\n",
    "#         #models.append(model)\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "    \n",
    "#         for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "#             A = example_data/126\n",
    "#             b = example_targets\n",
    "#         z = model.BNet(A).detach()\n",
    "#         T_pred = torch.argmax(z, dim = 1)\n",
    "#         print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4c4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_scale = 1\n",
    "# for lr in [1e-3, 1e-4, 1e-5]:\n",
    "#     for l in [400, 800, 1200]:\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         model = BNN(train_loader, [784, l, l, 10], act = nn.Tanh(), n_epochs = 20)\n",
    "#         model.train(lr = lr, decay = 1)\n",
    "#         #models.append(model)\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "    \n",
    "#         for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "#             A = example_data/126\n",
    "#             b = example_targets\n",
    "#         z = model.BNet(A).detach()\n",
    "#         T_pred = torch.argmax(z, dim = 1)\n",
    "#         print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01dbe7",
   "metadata": {},
   "source": [
    "## Vanilla NN training with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48a40625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eps_scale = 0 # if it is zero, then the netwok become non Bayesian\n",
    "# for lr in [1e-3, 1e-4, 1e-5]:\n",
    "#     for l in [400, 800,1200]:\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         model = BNN(train_loader, [784, l, l, 10], act = nn.ReLU(), n_epochs = 2)\n",
    "#         model.train(lr = lr, decay = 1)\n",
    "#         #models.append(model)\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "\n",
    "#         for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "#             A = example_data/126\n",
    "#             b = example_targets\n",
    "#         z = model.BNet(A).detach()\n",
    "#         T_pred = torch.argmax(z, dim = 1)\n",
    "#         print('for ReLU(), lr = {}, l={}, acc = {}'.format(lr,l,(T_pred == b).sum()/len(T_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4af0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_scale = 0 # if it is zero, then the netwok become non Bayesian\n",
    "# for lr in [1e-3, 1e-4, 1e-5]:\n",
    "#     for l in [400, 800,1200]:\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         model = BNN(train_loader, [784, l, l, 10], act = nn.Tanh(), n_epochs = 2)\n",
    "#         model.train(lr = lr, decay = 1)\n",
    "#         #models.append(model)\n",
    "#         print('---------------------------------------------------------------------')\n",
    "#         print('---------------------------------------------------------------------')\n",
    "\n",
    "#         for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "#             A = example_data/126\n",
    "#             b = example_targets\n",
    "#         z = model.BNet(A).detach()\n",
    "#         T_pred = torch.argmax(z, dim = 1)\n",
    "#         print('for Tanh(), lr = {}, l={}, acc = {}'.format(lr,l,(T_pred == b).sum()/len(T_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888102f",
   "metadata": {},
   "source": [
    "## Bayesian ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829d7778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  3824120.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.096171875\u001b[0m\n",
      "0 100\n",
      "Loss =  3713389.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.37546875\u001b[0m\n",
      "0 200\n",
      "Loss =  3566965.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.681484375\u001b[0m\n",
      "0 300\n",
      "Loss =  3473729.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7728125\u001b[0m\n",
      "0 400\n",
      "Loss =  3402498.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7728125\u001b[0m\n",
      "1 0\n",
      "Loss =  3330120.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8446875\u001b[0m\n",
      "1 100\n",
      "Loss =  3263983.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81234375\u001b[0m\n",
      "1 200\n",
      "Loss =  3188375.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8565625\u001b[0m\n",
      "1 300\n",
      "Loss =  3118814.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.854140625\u001b[0m\n",
      "1 400\n",
      "Loss =  3047287.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.892421875\u001b[0m\n",
      "2 0\n",
      "Loss =  3011699.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.85140625\u001b[0m\n",
      "2 100\n",
      "Loss =  2938296.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.86875\u001b[0m\n",
      "2 200\n",
      "Loss =  2866721.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.8840625\u001b[0m\n",
      "2 300\n",
      "Loss =  2801115.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.874453125\u001b[0m\n",
      "2 400\n",
      "Loss =  2740164.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.91015625\u001b[0m\n",
      "3 0\n",
      "Loss =  2694048.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.879375\u001b[0m\n",
      "3 100\n",
      "Loss =  2645011.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.865234375\u001b[0m\n",
      "3 200\n",
      "Loss =  2581928.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.87203125\u001b[0m\n",
      "3 300\n",
      "Loss =  2520425.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.9209375\u001b[0m\n",
      "3 400\n",
      "Loss =  2470418.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.90296875\u001b[0m\n",
      "4 0\n",
      "Loss =  2430601.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.920390625\u001b[0m\n",
      "4 100\n",
      "Loss =  2401845.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.884609375\u001b[0m\n",
      "4 200\n",
      "Loss =  2335037.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.93\u001b[0m\n",
      "4 300\n",
      "Loss =  2299555.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.8815625\u001b[0m\n",
      "4 400\n",
      "Loss =  2260791.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.8534375\u001b[0m\n",
      "5 0\n",
      "Loss =  2223140.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.90140625\u001b[0m\n",
      "5 100\n",
      "Loss =  2183819.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.887421875\u001b[0m\n",
      "5 200\n",
      "Loss =  2140153.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.92953125\u001b[0m\n",
      "5 300\n",
      "Loss =  2112534.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.8625\u001b[0m\n",
      "5 400\n",
      "Loss =  2067015.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.930390625\u001b[0m\n",
      "6 0\n",
      "Loss =  2047695.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.89859375\u001b[0m\n",
      "6 100\n",
      "Loss =  2015979.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.899609375\u001b[0m\n",
      "6 200\n",
      "Loss =  1983109.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.9134375\u001b[0m\n",
      "6 300\n",
      "Loss =  1950424.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.93859375\u001b[0m\n",
      "6 400\n",
      "Loss =  1927114.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.924609375\u001b[0m\n",
      "7 0\n",
      "Loss =  1912715.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.915703125\u001b[0m\n",
      "7 100\n",
      "Loss =  1888173.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.919453125\u001b[0m\n",
      "7 200\n",
      "Loss =  1862301.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.915625\u001b[0m\n",
      "7 300\n",
      "Loss =  1835296.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.910078125\u001b[0m\n",
      "7 400\n",
      "Loss =  1814094.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.935390625\u001b[0m\n",
      "8 0\n",
      "Loss =  1804147.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.90484375\u001b[0m\n",
      "8 100\n",
      "Loss =  1792795.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.88015625\u001b[0m\n",
      "8 200\n",
      "Loss =  1764561.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.93046875\u001b[0m\n",
      "8 300\n",
      "Loss =  1749626.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.89296875\u001b[0m\n",
      "8 400\n",
      "Loss =  1728700.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.913203125\u001b[0m\n",
      "9 0\n",
      "Loss =  1720764.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.905546875\u001b[0m\n",
      "9 100\n",
      "Loss =  1701318.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.941171875\u001b[0m\n",
      "9 200\n",
      "Loss =  1693891.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.879765625\u001b[0m\n",
      "9 300\n",
      "Loss =  1672753.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.933046875\u001b[0m\n",
      "9 400\n",
      "Loss =  1656599.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.923125\u001b[0m\n",
      "10 0\n",
      "Loss =  1645956.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.948984375\u001b[0m\n",
      "10 100\n",
      "Loss =  1643258.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.916875\u001b[0m\n",
      "10 200\n",
      "Loss =  1624909.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.92671875\u001b[0m\n",
      "10 300\n",
      "Loss =  1611475.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.948125\u001b[0m\n",
      "10 400\n",
      "Loss =  1598950.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.92015625\u001b[0m\n",
      "11 0\n",
      "Loss =  1587551.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.935390625\u001b[0m\n",
      "11 100\n",
      "Loss =  1581166.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.94203125\u001b[0m\n",
      "11 200\n",
      "Loss =  1585367.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.8675\u001b[0m\n",
      "11 300\n",
      "Loss =  1566572.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.905625\u001b[0m\n",
      "11 400\n",
      "Loss =  1554346.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.929921875\u001b[0m\n",
      "12 0\n",
      "Loss =  1540721.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.963671875\u001b[0m\n",
      "12 100\n",
      "Loss =  1535311.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.932578125\u001b[0m\n",
      "12 200\n",
      "Loss =  1523044.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9528125\u001b[0m\n",
      "12 300\n",
      "Loss =  1515498.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.944921875\u001b[0m\n",
      "12 400\n",
      "Loss =  1505534.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.94546875\u001b[0m\n",
      "13 0\n",
      "Loss =  1503193.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.94125\u001b[0m\n",
      "13 100\n",
      "Loss =  1496746.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.93265625\u001b[0m\n",
      "13 200\n",
      "Loss =  1496116.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.895390625\u001b[0m\n",
      "13 300\n",
      "Loss =  1483133.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.933515625\u001b[0m\n",
      "13 400\n",
      "Loss =  1476219.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.928203125\u001b[0m\n",
      "14 0\n",
      "Loss =  1467443.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9546875\u001b[0m\n",
      "14 100\n",
      "Loss =  1475574.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.882421875\u001b[0m\n",
      "14 200\n",
      "Loss =  1468246.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9409375\u001b[0m\n",
      "14 300\n",
      "Loss =  1455266.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.897421875\u001b[0m\n",
      "14 400\n",
      "Loss =  1446221.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.91921875\u001b[0m\n",
      "15 0\n",
      "Loss =  1446858.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.941484375\u001b[0m\n",
      "15 100\n",
      "Loss =  1432387.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.94734375\u001b[0m\n",
      "15 200\n",
      "Loss =  1433994.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.92078125\u001b[0m\n",
      "15 300\n",
      "Loss =  1428052.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.921328125\u001b[0m\n",
      "15 400\n",
      "Loss =  1415200.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.955625\u001b[0m\n",
      "16 0\n",
      "Loss =  1413438.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.94734375\u001b[0m\n",
      "16 100\n",
      "Loss =  1414111.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.91421875\u001b[0m\n",
      "16 200\n",
      "Loss =  1406885.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.93671875\u001b[0m\n",
      "16 300\n",
      "Loss =  1394598.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.971328125\u001b[0m\n",
      "16 400\n",
      "Loss =  1392176.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.9528125\u001b[0m\n",
      "17 0\n",
      "Loss =  1388428.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.957890625\u001b[0m\n",
      "17 100\n",
      "Loss =  1398059.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.895390625\u001b[0m\n",
      "17 200\n",
      "Loss =  1378440.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.97140625\u001b[0m\n",
      "17 300\n",
      "Loss =  1376454.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.94015625\u001b[0m\n",
      "17 400\n",
      "Loss =  1376725.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.9503125\u001b[0m\n",
      "18 0\n",
      "Loss =  1371635.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9584375\u001b[0m\n",
      "18 100\n",
      "Loss =  1367049.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.950078125\u001b[0m\n",
      "18 200\n",
      "Loss =  1366161.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.936484375\u001b[0m\n",
      "18 300\n",
      "Loss =  1361548.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.950234375\u001b[0m\n",
      "18 400\n",
      "Loss =  1362357.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.923828125\u001b[0m\n",
      "19 0\n",
      "Loss =  1352327.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.9503125\u001b[0m\n",
      "19 100\n",
      "Loss =  1355589.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.94734375\u001b[0m\n",
      "19 200\n",
      "Loss =  1352275.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.945078125\u001b[0m\n",
      "19 300\n",
      "Loss =  1344111.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.9503125\u001b[0m\n",
      "19 400\n",
      "Loss =  1349481.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.928046875\u001b[0m\n",
      "20 0\n",
      "Loss =  1340385.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.94828125\u001b[0m\n",
      "20 100\n",
      "Loss =  1341899.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.933671875\u001b[0m\n",
      "20 200\n",
      "Loss =  1333444.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.953203125\u001b[0m\n",
      "20 300\n",
      "Loss =  1327575.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.965703125\u001b[0m\n",
      "20 400\n",
      "Loss =  1327457.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.95546875\u001b[0m\n",
      "21 0\n",
      "Loss =  1324283.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.960234375\u001b[0m\n",
      "21 100\n",
      "Loss =  1332448.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.933203125\u001b[0m\n",
      "21 200\n",
      "Loss =  1318953.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.95296875\u001b[0m\n",
      "21 300\n",
      "Loss =  1320881.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.93703125\u001b[0m\n",
      "21 400\n",
      "Loss =  1317234.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.964921875\u001b[0m\n",
      "22 0\n",
      "Loss =  1313513.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.96875\u001b[0m\n",
      "22 100\n",
      "Loss =  1314996.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.933359375\u001b[0m\n",
      "22 200\n",
      "Loss =  1315265.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.923046875\u001b[0m\n",
      "22 300\n",
      "Loss =  1305840.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.94875\u001b[0m\n",
      "22 400\n",
      "Loss =  1317349.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.906015625\u001b[0m\n",
      "23 0\n",
      "Loss =  1305347.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.96890625\u001b[0m\n",
      "23 100\n",
      "Loss =  1307751.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9415625\u001b[0m\n",
      "23 200\n",
      "Loss =  1301865.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.93578125\u001b[0m\n",
      "23 300\n",
      "Loss =  1303172.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.962421875\u001b[0m\n",
      "23 400\n",
      "Loss =  1302787.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.930625\u001b[0m\n",
      "24 0\n",
      "Loss =  1296377.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.951796875\u001b[0m\n",
      "24 100\n",
      "Loss =  1298067.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9115625\u001b[0m\n",
      "24 200\n",
      "Loss =  1297101.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.943984375\u001b[0m\n",
      "24 300\n",
      "Loss =  1295225.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.92875\u001b[0m\n",
      "24 400\n",
      "Loss =  1291691.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9415625\u001b[0m\n",
      "25 0\n",
      "Loss =  1287989.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.94875\u001b[0m\n",
      "25 100\n",
      "Loss =  1287366.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.965078125\u001b[0m\n",
      "25 200\n",
      "Loss =  1285438.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.948203125\u001b[0m\n",
      "25 300\n",
      "Loss =  1283122.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.961640625\u001b[0m\n",
      "25 400\n",
      "Loss =  1286540.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.947890625\u001b[0m\n",
      "26 0\n",
      "Loss =  1276894.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.977265625\u001b[0m\n",
      "26 100\n",
      "Loss =  1276877.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.969921875\u001b[0m\n",
      "26 200\n",
      "Loss =  1281457.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.950703125\u001b[0m\n",
      "26 300\n",
      "Loss =  1282389.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.946171875\u001b[0m\n",
      "26 400\n",
      "Loss =  1275195.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.962890625\u001b[0m\n",
      "27 0\n",
      "Loss =  1274343.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.9490625\u001b[0m\n",
      "27 100\n",
      "Loss =  1275123.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.948203125\u001b[0m\n",
      "27 200\n",
      "Loss =  1271850.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.94375\u001b[0m\n",
      "27 300\n",
      "Loss =  1273459.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.956171875\u001b[0m\n",
      "27 400\n",
      "Loss =  1268017.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.96484375\u001b[0m\n",
      "28 0\n",
      "Loss =  1270423.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.941171875\u001b[0m\n",
      "28 100\n",
      "Loss =  1282434.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.934609375\u001b[0m\n",
      "28 200\n",
      "Loss =  1265102.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.973828125\u001b[0m\n",
      "28 300\n",
      "Loss =  1271593.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.94375\u001b[0m\n",
      "28 400\n",
      "Loss =  1269089.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.95\u001b[0m\n",
      "29 0\n",
      "Loss =  1268017.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9340625\u001b[0m\n",
      "29 100\n",
      "Loss =  1265994.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9453125\u001b[0m\n",
      "29 200\n",
      "Loss =  1262294.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9603125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 300\n",
      "Loss =  1260158.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.955625\u001b[0m\n",
      "29 400\n",
      "Loss =  1260571.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.946875\u001b[0m\n",
      "30 0\n",
      "Loss =  1257834.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9603125\u001b[0m\n",
      "30 100\n",
      "Loss =  1259081.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.957890625\u001b[0m\n",
      "30 200\n",
      "Loss =  1260998.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9521875\u001b[0m\n",
      "30 300\n",
      "Loss =  1258213.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.956953125\u001b[0m\n",
      "30 400\n",
      "Loss =  1253292.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.981953125\u001b[0m\n",
      "31 0\n",
      "Loss =  1256974.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.964375\u001b[0m\n",
      "31 100\n",
      "Loss =  1252016.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.972109375\u001b[0m\n",
      "31 200\n",
      "Loss =  1254585.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.971640625\u001b[0m\n",
      "31 300\n",
      "Loss =  1255509.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.953125\u001b[0m\n",
      "31 400\n",
      "Loss =  1254792.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.955703125\u001b[0m\n",
      "32 0\n",
      "Loss =  1256577.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.958125\u001b[0m\n",
      "32 100\n",
      "Loss =  1250155.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.968515625\u001b[0m\n",
      "32 200\n",
      "Loss =  1254167.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.950390625\u001b[0m\n",
      "32 300\n",
      "Loss =  1252723.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9696875\u001b[0m\n",
      "32 400\n",
      "Loss =  1256531.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.94359375\u001b[0m\n",
      "33 0\n",
      "Loss =  1251174.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9590625\u001b[0m\n",
      "33 100\n",
      "Loss =  1247421.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.966328125\u001b[0m\n",
      "33 200\n",
      "Loss =  1247431.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.964296875\u001b[0m\n",
      "33 300\n",
      "Loss =  1248275.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9528125\u001b[0m\n",
      "33 400\n",
      "Loss =  1248442.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.974375\u001b[0m\n",
      "34 0\n",
      "Loss =  1247981.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.96546875\u001b[0m\n",
      "34 100\n",
      "Loss =  1256799.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.93921875\u001b[0m\n",
      "34 200\n",
      "Loss =  1247638.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.952890625\u001b[0m\n",
      "34 300\n",
      "Loss =  1252797.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.95109375\u001b[0m\n",
      "34 400\n",
      "Loss =  1248264.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.959453125\u001b[0m\n",
      "35 0\n",
      "Loss =  1246297.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.96265625\u001b[0m\n",
      "35 100\n",
      "Loss =  1244617.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.960390625\u001b[0m\n",
      "35 200\n",
      "Loss =  1246089.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.962109375\u001b[0m\n",
      "35 300\n",
      "Loss =  1245729.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.952578125\u001b[0m\n",
      "35 400\n",
      "Loss =  1248661.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9315625\u001b[0m\n",
      "36 0\n",
      "Loss =  1245124.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.9625\u001b[0m\n",
      "36 100\n",
      "Loss =  1253197.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.95546875\u001b[0m\n",
      "36 200\n",
      "Loss =  1248003.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.93625\u001b[0m\n",
      "36 300\n",
      "Loss =  1246187.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.9521875\u001b[0m\n",
      "36 400\n",
      "Loss =  1249506.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.94125\u001b[0m\n",
      "37 0\n",
      "Loss =  1247652.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.9465625\u001b[0m\n",
      "37 100\n",
      "Loss =  1241722.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.97140625\u001b[0m\n",
      "37 200\n",
      "Loss =  1244150.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.947890625\u001b[0m\n",
      "37 300\n",
      "Loss =  1239670.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.9596875\u001b[0m\n",
      "37 400\n",
      "Loss =  1241183.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.9565625\u001b[0m\n",
      "38 0\n",
      "Loss =  1236904.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.969375\u001b[0m\n",
      "38 100\n",
      "Loss =  1234803.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.987734375\u001b[0m\n",
      "38 200\n",
      "Loss =  1243275.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.9625\u001b[0m\n",
      "38 300\n",
      "Loss =  1242264.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.94203125\u001b[0m\n",
      "38 400\n",
      "Loss =  1238301.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.968203125\u001b[0m\n",
      "39 0\n",
      "Loss =  1244716.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.94109375\u001b[0m\n",
      "39 100\n",
      "Loss =  1237242.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.96171875\u001b[0m\n",
      "39 200\n",
      "Loss =  1235361.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.964921875\u001b[0m\n",
      "39 300\n",
      "Loss =  1239825.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9509375\u001b[0m\n",
      "39 400\n",
      "Loss =  1237339.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.966953125\u001b[0m\n",
      "40 0\n",
      "Loss =  1238081.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.95609375\u001b[0m\n",
      "40 100\n",
      "Loss =  1237517.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.96640625\u001b[0m\n",
      "40 200\n",
      "Loss =  1237940.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.963828125\u001b[0m\n",
      "40 300\n",
      "Loss =  1244683.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.94078125\u001b[0m\n",
      "40 400\n",
      "Loss =  1231926.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.969375\u001b[0m\n",
      "41 0\n",
      "Loss =  1236109.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.9475\u001b[0m\n",
      "41 100\n",
      "Loss =  1238722.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.95234375\u001b[0m\n",
      "41 200\n",
      "Loss =  1235407.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.947578125\u001b[0m\n",
      "41 300\n",
      "Loss =  1233900.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.965859375\u001b[0m\n",
      "41 400\n",
      "Loss =  1234924.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.964140625\u001b[0m\n",
      "42 0\n",
      "Loss =  1235610.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.9678125\u001b[0m\n",
      "42 100\n",
      "Loss =  1233044.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.95953125\u001b[0m\n",
      "42 200\n",
      "Loss =  1235911.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.956484375\u001b[0m\n",
      "42 300\n",
      "Loss =  1234511.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.967578125\u001b[0m\n",
      "42 400\n",
      "Loss =  1233679.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.9609375\u001b[0m\n",
      "43 0\n",
      "Loss =  1236794.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.961171875\u001b[0m\n",
      "43 100\n",
      "Loss =  1238567.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.93203125\u001b[0m\n",
      "43 200\n",
      "Loss =  1234077.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.95453125\u001b[0m\n",
      "43 300\n",
      "Loss =  1232701.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.9603125\u001b[0m\n",
      "43 400\n",
      "Loss =  1234618.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.95734375\u001b[0m\n",
      "44 0\n",
      "Loss =  1234746.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.948203125\u001b[0m\n",
      "44 100\n",
      "Loss =  1231548.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9615625\u001b[0m\n",
      "44 200\n",
      "Loss =  1233932.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9540625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 300\n",
      "Loss =  1236927.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.959921875\u001b[0m\n",
      "44 400\n",
      "Loss =  1232778.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9684375\u001b[0m\n",
      "45 0\n",
      "Loss =  1234234.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.963359375\u001b[0m\n",
      "45 100\n",
      "Loss =  1233456.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.925390625\u001b[0m\n",
      "45 200\n",
      "Loss =  1227879.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.97015625\u001b[0m\n",
      "45 300\n",
      "Loss =  1234049.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.955625\u001b[0m\n",
      "45 400\n",
      "Loss =  1228185.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.951953125\u001b[0m\n",
      "46 0\n",
      "Loss =  1230845.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.959609375\u001b[0m\n",
      "46 100\n",
      "Loss =  1233387.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.966640625\u001b[0m\n",
      "46 200\n",
      "Loss =  1229577.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.9465625\u001b[0m\n",
      "46 300\n",
      "Loss =  1236185.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.944140625\u001b[0m\n",
      "46 400\n",
      "Loss =  1232711.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.956796875\u001b[0m\n",
      "47 0\n",
      "Loss =  1233507.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.952734375\u001b[0m\n",
      "47 100\n",
      "Loss =  1232111.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.968203125\u001b[0m\n",
      "47 200\n",
      "Loss =  1242434.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.933828125\u001b[0m\n",
      "47 300\n",
      "Loss =  1232328.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.970703125\u001b[0m\n",
      "47 400\n",
      "Loss =  1229446.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.953359375\u001b[0m\n",
      "48 0\n",
      "Loss =  1230394.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.970078125\u001b[0m\n",
      "48 100\n",
      "Loss =  1228179.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.961875\u001b[0m\n",
      "48 200\n",
      "Loss =  1227109.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9796875\u001b[0m\n",
      "48 300\n",
      "Loss =  1225014.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.97609375\u001b[0m\n",
      "48 400\n",
      "Loss =  1233759.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9515625\u001b[0m\n",
      "49 0\n",
      "Loss =  1236319.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.936484375\u001b[0m\n",
      "49 100\n",
      "Loss =  1232157.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.95328125\u001b[0m\n",
      "49 200\n",
      "Loss =  1233557.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.936953125\u001b[0m\n",
      "49 300\n",
      "Loss =  1226571.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.9734375\u001b[0m\n",
      "49 400\n",
      "Loss =  1230617.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.95109375\u001b[0m\n",
      "50 0\n",
      "Loss =  1232003.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.94796875\u001b[0m\n",
      "50 100\n",
      "Loss =  1229453.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9725\u001b[0m\n",
      "50 200\n",
      "Loss =  1229252.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.971640625\u001b[0m\n",
      "50 300\n",
      "Loss =  1233420.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.937265625\u001b[0m\n",
      "50 400\n",
      "Loss =  1228328.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.96953125\u001b[0m\n",
      "51 0\n",
      "Loss =  1231550.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.95625\u001b[0m\n",
      "51 100\n",
      "Loss =  1233790.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.938203125\u001b[0m\n",
      "51 200\n",
      "Loss =  1228352.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96578125\u001b[0m\n",
      "51 300\n",
      "Loss =  1229364.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.9646875\u001b[0m\n",
      "51 400\n",
      "Loss =  1231429.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.9621875\u001b[0m\n",
      "52 0\n",
      "Loss =  1223663.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.978515625\u001b[0m\n",
      "52 100\n",
      "Loss =  1227259.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.9640625\u001b[0m\n",
      "52 200\n",
      "Loss =  1228293.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.964765625\u001b[0m\n",
      "52 300\n",
      "Loss =  1228328.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.95328125\u001b[0m\n",
      "52 400\n",
      "Loss =  1225662.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.966796875\u001b[0m\n",
      "53 0\n",
      "Loss =  1236148.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.95484375\u001b[0m\n",
      "53 100\n",
      "Loss =  1225092.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.958828125\u001b[0m\n",
      "53 200\n",
      "Loss =  1227817.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.95921875\u001b[0m\n",
      "53 300\n",
      "Loss =  1221734.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.97640625\u001b[0m\n",
      "53 400\n",
      "Loss =  1227198.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.957890625\u001b[0m\n",
      "54 0\n",
      "Loss =  1224717.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.975703125\u001b[0m\n",
      "54 100\n",
      "Loss =  1227369.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.94703125\u001b[0m\n",
      "54 200\n",
      "Loss =  1229248.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.949453125\u001b[0m\n",
      "54 300\n",
      "Loss =  1230655.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.95890625\u001b[0m\n",
      "54 400\n",
      "Loss =  1226361.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.956171875\u001b[0m\n",
      "55 0\n",
      "Loss =  1227533.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.963359375\u001b[0m\n",
      "55 100\n",
      "Loss =  1225945.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.9646875\u001b[0m\n",
      "55 200\n",
      "Loss =  1227973.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.94828125\u001b[0m\n",
      "55 300\n",
      "Loss =  1223763.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.955703125\u001b[0m\n",
      "55 400\n",
      "Loss =  1227180.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.965625\u001b[0m\n",
      "56 0\n",
      "Loss =  1223345.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.96828125\u001b[0m\n",
      "56 100\n",
      "Loss =  1227085.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.951640625\u001b[0m\n",
      "56 200\n",
      "Loss =  1227183.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.94390625\u001b[0m\n",
      "56 300\n",
      "Loss =  1232081.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.95484375\u001b[0m\n",
      "56 400\n",
      "Loss =  1226770.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.951953125\u001b[0m\n",
      "57 0\n",
      "Loss =  1224524.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.968359375\u001b[0m\n",
      "57 100\n",
      "Loss =  1228309.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.957265625\u001b[0m\n",
      "57 200\n",
      "Loss =  1224832.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.962578125\u001b[0m\n",
      "57 300\n",
      "Loss =  1223342.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.97328125\u001b[0m\n",
      "57 400\n",
      "Loss =  1224471.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.971875\u001b[0m\n",
      "58 0\n",
      "Loss =  1222276.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.9725\u001b[0m\n",
      "58 100\n",
      "Loss =  1226753.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.95921875\u001b[0m\n",
      "58 200\n",
      "Loss =  1226537.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.978828125\u001b[0m\n",
      "58 300\n",
      "Loss =  1220722.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.96734375\u001b[0m\n",
      "58 400\n",
      "Loss =  1226476.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.953671875\u001b[0m\n",
      "59 0\n",
      "Loss =  1227461.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.948203125\u001b[0m\n",
      "59 100\n",
      "Loss =  1223888.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.94296875\u001b[0m\n",
      "59 200\n",
      "Loss =  1225384.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.962109375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 300\n",
      "Loss =  1226965.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.955390625\u001b[0m\n",
      "59 400\n",
      "Loss =  1220896.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.97046875\u001b[0m\n",
      "60 0\n",
      "Loss =  1227774.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.9596875\u001b[0m\n",
      "60 100\n",
      "Loss =  1222829.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.968125\u001b[0m\n",
      "60 200\n",
      "Loss =  1226085.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.955390625\u001b[0m\n",
      "60 300\n",
      "Loss =  1223827.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.96328125\u001b[0m\n",
      "60 400\n",
      "Loss =  1225785.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.956875\u001b[0m\n",
      "61 0\n",
      "Loss =  1228563.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.949921875\u001b[0m\n",
      "61 100\n",
      "Loss =  1224148.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.962265625\u001b[0m\n",
      "61 200\n",
      "Loss =  1223750.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.955390625\u001b[0m\n",
      "61 300\n",
      "Loss =  1225626.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.9571875\u001b[0m\n",
      "61 400\n",
      "Loss =  1220159.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.9690625\u001b[0m\n",
      "62 0\n",
      "Loss =  1225300.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.950703125\u001b[0m\n",
      "62 100\n",
      "Loss =  1224249.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.96796875\u001b[0m\n",
      "62 200\n",
      "Loss =  1222817.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.972109375\u001b[0m\n",
      "62 300\n",
      "Loss =  1226350.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.957578125\u001b[0m\n",
      "62 400\n",
      "Loss =  1225116.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.9609375\u001b[0m\n",
      "63 0\n",
      "Loss =  1223523.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.961328125\u001b[0m\n",
      "63 100\n",
      "Loss =  1227136.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.9378125\u001b[0m\n",
      "63 200\n",
      "Loss =  1225518.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.9634375\u001b[0m\n",
      "63 300\n",
      "Loss =  1226902.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.95078125\u001b[0m\n",
      "63 400\n",
      "Loss =  1226662.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.955546875\u001b[0m\n",
      "64 0\n",
      "Loss =  1222958.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9590625\u001b[0m\n",
      "64 100\n",
      "Loss =  1219518.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.978359375\u001b[0m\n",
      "64 200\n",
      "Loss =  1226641.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.969921875\u001b[0m\n",
      "64 300\n",
      "Loss =  1221234.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.979453125\u001b[0m\n",
      "64 400\n",
      "Loss =  1220951.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.965625\u001b[0m\n",
      "65 0\n",
      "Loss =  1222109.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.95328125\u001b[0m\n",
      "65 100\n",
      "Loss =  1224475.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.971328125\u001b[0m\n",
      "65 200\n",
      "Loss =  1218539.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.980234375\u001b[0m\n",
      "65 300\n",
      "Loss =  1221671.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.95140625\u001b[0m\n",
      "65 400\n",
      "Loss =  1218614.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.97515625\u001b[0m\n",
      "66 0\n",
      "Loss =  1218369.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9825\u001b[0m\n",
      "66 100\n",
      "Loss =  1228274.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.950390625\u001b[0m\n",
      "66 200\n",
      "Loss =  1218585.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.971953125\u001b[0m\n",
      "66 300\n",
      "Loss =  1220949.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9675\u001b[0m\n",
      "66 400\n",
      "Loss =  1224619.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.977265625\u001b[0m\n",
      "67 0\n",
      "Loss =  1221487.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.96265625\u001b[0m\n",
      "67 100\n",
      "Loss =  1222071.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.975546875\u001b[0m\n",
      "67 200\n",
      "Loss =  1221278.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.968984375\u001b[0m\n",
      "67 300\n",
      "Loss =  1222837.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.954765625\u001b[0m\n",
      "67 400\n",
      "Loss =  1227002.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9684375\u001b[0m\n",
      "68 0\n",
      "Loss =  1223388.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9690625\u001b[0m\n",
      "68 100\n",
      "Loss =  1221518.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9796875\u001b[0m\n",
      "68 200\n",
      "Loss =  1221104.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.958671875\u001b[0m\n",
      "68 300\n",
      "Loss =  1219104.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.977265625\u001b[0m\n",
      "68 400\n",
      "Loss =  1226733.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9615625\u001b[0m\n",
      "69 0\n",
      "Loss =  1221528.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.954453125\u001b[0m\n",
      "69 100\n",
      "Loss =  1225712.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.946171875\u001b[0m\n",
      "69 200\n",
      "Loss =  1223378.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.96078125\u001b[0m\n",
      "69 300\n",
      "Loss =  1224220.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.946953125\u001b[0m\n",
      "69 400\n",
      "Loss =  1219077.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.97265625\u001b[0m\n",
      "70 0\n",
      "Loss =  1222529.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.96390625\u001b[0m\n",
      "70 100\n",
      "Loss =  1226094.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.94484375\u001b[0m\n",
      "70 200\n",
      "Loss =  1222746.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.961640625\u001b[0m\n",
      "70 300\n",
      "Loss =  1221755.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.965703125\u001b[0m\n",
      "70 400\n",
      "Loss =  1221304.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.957109375\u001b[0m\n",
      "71 0\n",
      "Loss =  1219609.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.976875\u001b[0m\n",
      "71 100\n",
      "Loss =  1222484.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.9690625\u001b[0m\n",
      "71 200\n",
      "Loss =  1223444.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.96890625\u001b[0m\n",
      "71 300\n",
      "Loss =  1220720.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.95515625\u001b[0m\n",
      "71 400\n",
      "Loss =  1219901.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.96875\u001b[0m\n",
      "72 0\n",
      "Loss =  1219993.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.96859375\u001b[0m\n",
      "72 100\n",
      "Loss =  1217979.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.967421875\u001b[0m\n",
      "72 200\n",
      "Loss =  1224657.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.956484375\u001b[0m\n",
      "72 300\n",
      "Loss =  1217270.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.983359375\u001b[0m\n",
      "72 400\n",
      "Loss =  1218822.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.9659375\u001b[0m\n",
      "73 0\n",
      "Loss =  1217707.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.9709375\u001b[0m\n",
      "73 100\n",
      "Loss =  1218682.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.963984375\u001b[0m\n",
      "73 200\n",
      "Loss =  1229408.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.949296875\u001b[0m\n",
      "73 300\n",
      "Loss =  1219856.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.977734375\u001b[0m\n",
      "73 400\n",
      "Loss =  1215893.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.980703125\u001b[0m\n",
      "74 0\n",
      "Loss =  1223144.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.94953125\u001b[0m\n",
      "74 100\n",
      "Loss =  1218411.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.972109375\u001b[0m\n",
      "74 200\n",
      "Loss =  1220018.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.97390625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 300\n",
      "Loss =  1221019.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.96796875\u001b[0m\n",
      "74 400\n",
      "Loss =  1220911.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.969921875\u001b[0m\n",
      "75 0\n",
      "Loss =  1220726.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.961796875\u001b[0m\n",
      "75 100\n",
      "Loss =  1222928.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.956640625\u001b[0m\n",
      "75 200\n",
      "Loss =  1221533.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.958125\u001b[0m\n",
      "75 300\n",
      "Loss =  1217712.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.96484375\u001b[0m\n",
      "75 400\n",
      "Loss =  1217225.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.9640625\u001b[0m\n",
      "76 0\n",
      "Loss =  1219475.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.9684375\u001b[0m\n",
      "76 100\n",
      "Loss =  1215218.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.97484375\u001b[0m\n",
      "76 200\n",
      "Loss =  1223907.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.9603125\u001b[0m\n",
      "76 300\n",
      "Loss =  1226356.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.9521875\u001b[0m\n",
      "76 400\n",
      "Loss =  1223720.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.95546875\u001b[0m\n",
      "77 0\n",
      "Loss =  1217727.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.96328125\u001b[0m\n",
      "77 100\n",
      "Loss =  1219005.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.958515625\u001b[0m\n",
      "77 200\n",
      "Loss =  1220496.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9425\u001b[0m\n",
      "77 300\n",
      "Loss =  1217915.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.97828125\u001b[0m\n",
      "77 400\n",
      "Loss =  1218029.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.968046875\u001b[0m\n",
      "78 0\n",
      "Loss =  1218774.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.970625\u001b[0m\n",
      "78 100\n",
      "Loss =  1222101.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.97078125\u001b[0m\n",
      "78 200\n",
      "Loss =  1224397.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.9684375\u001b[0m\n",
      "78 300\n",
      "Loss =  1217193.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.96921875\u001b[0m\n",
      "78 400\n",
      "Loss =  1220793.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.965\u001b[0m\n",
      "79 0\n",
      "Loss =  1217618.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.976171875\u001b[0m\n",
      "79 100\n",
      "Loss =  1222190.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.97546875\u001b[0m\n",
      "79 200\n",
      "Loss =  1218360.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.967109375\u001b[0m\n",
      "79 300\n",
      "Loss =  1220549.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.949609375\u001b[0m\n",
      "79 400\n",
      "Loss =  1220795.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.959375\u001b[0m\n",
      "80 0\n",
      "Loss =  1217385.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.969765625\u001b[0m\n",
      "80 100\n",
      "Loss =  1218030.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.97171875\u001b[0m\n",
      "80 200\n",
      "Loss =  1224236.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.9615625\u001b[0m\n",
      "80 300\n",
      "Loss =  1219631.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.963828125\u001b[0m\n",
      "80 400\n",
      "Loss =  1225797.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.92\u001b[0m\n",
      "81 0\n",
      "Loss =  1217989.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.959296875\u001b[0m\n",
      "81 100\n",
      "Loss =  1221833.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.95953125\u001b[0m\n",
      "81 200\n",
      "Loss =  1217138.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.969765625\u001b[0m\n",
      "81 300\n",
      "Loss =  1216911.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.972421875\u001b[0m\n",
      "81 400\n",
      "Loss =  1223232.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.93984375\u001b[0m\n",
      "82 0\n",
      "Loss =  1219245.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.976484375\u001b[0m\n",
      "82 100\n",
      "Loss =  1217404.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.96203125\u001b[0m\n",
      "82 200\n",
      "Loss =  1218059.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.97375\u001b[0m\n",
      "82 300\n",
      "Loss =  1220397.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.967890625\u001b[0m\n",
      "82 400\n",
      "Loss =  1222899.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.957421875\u001b[0m\n",
      "83 0\n",
      "Loss =  1217808.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.978671875\u001b[0m\n",
      "83 100\n",
      "Loss =  1223615.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.963671875\u001b[0m\n",
      "83 200\n",
      "Loss =  1221351.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.954453125\u001b[0m\n",
      "83 300\n",
      "Loss =  1220452.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.9696875\u001b[0m\n",
      "83 400\n",
      "Loss =  1223514.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.956953125\u001b[0m\n",
      "84 0\n",
      "Loss =  1217689.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.965234375\u001b[0m\n",
      "84 100\n",
      "Loss =  1223197.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.95125\u001b[0m\n",
      "84 200\n",
      "Loss =  1217749.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.97453125\u001b[0m\n",
      "84 300\n",
      "Loss =  1223666.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.96578125\u001b[0m\n",
      "84 400\n",
      "Loss =  1218503.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.968125\u001b[0m\n",
      "85 0\n",
      "Loss =  1222166.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.952109375\u001b[0m\n",
      "85 100\n",
      "Loss =  1220753.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.950390625\u001b[0m\n",
      "85 200\n",
      "Loss =  1214595.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.98390625\u001b[0m\n",
      "85 300\n",
      "Loss =  1218952.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.96875\u001b[0m\n",
      "85 400\n",
      "Loss =  1219755.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.964296875\u001b[0m\n",
      "86 0\n",
      "Loss =  1215038.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.966328125\u001b[0m\n",
      "86 100\n",
      "Loss =  1218837.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.95296875\u001b[0m\n",
      "86 200\n",
      "Loss =  1217187.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.968671875\u001b[0m\n",
      "86 300\n",
      "Loss =  1221120.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.953984375\u001b[0m\n",
      "86 400\n",
      "Loss =  1220768.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9709375\u001b[0m\n",
      "87 0\n",
      "Loss =  1221461.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.954375\u001b[0m\n",
      "87 100\n",
      "Loss =  1220272.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.96796875\u001b[0m\n",
      "87 200\n",
      "Loss =  1215792.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.96640625\u001b[0m\n",
      "87 300\n",
      "Loss =  1220070.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.9609375\u001b[0m\n",
      "87 400\n",
      "Loss =  1221658.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.951640625\u001b[0m\n",
      "88 0\n",
      "Loss =  1219311.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.9684375\u001b[0m\n",
      "88 100\n",
      "Loss =  1220745.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.960625\u001b[0m\n",
      "88 200\n",
      "Loss =  1217580.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.96875\u001b[0m\n",
      "88 300\n",
      "Loss =  1222442.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.945703125\u001b[0m\n",
      "88 400\n",
      "Loss =  1221727.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.959453125\u001b[0m\n",
      "89 0\n",
      "Loss =  1218973.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.97796875\u001b[0m\n",
      "89 100\n",
      "Loss =  1217493.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.9578125\u001b[0m\n",
      "89 200\n",
      "Loss =  1214225.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.987109375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 300\n",
      "Loss =  1220976.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.95703125\u001b[0m\n",
      "89 400\n",
      "Loss =  1222839.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.963125\u001b[0m\n",
      "90 0\n",
      "Loss =  1215805.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.983984375\u001b[0m\n",
      "90 100\n",
      "Loss =  1215164.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.97859375\u001b[0m\n",
      "90 200\n",
      "Loss =  1215815.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.961484375\u001b[0m\n",
      "90 300\n",
      "Loss =  1216241.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.9659375\u001b[0m\n",
      "90 400\n",
      "Loss =  1217716.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.96796875\u001b[0m\n",
      "91 0\n",
      "Loss =  1217077.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.961484375\u001b[0m\n",
      "91 100\n",
      "Loss =  1217459.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.97234375\u001b[0m\n",
      "91 200\n",
      "Loss =  1222367.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.944140625\u001b[0m\n",
      "91 300\n",
      "Loss =  1213138.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.980703125\u001b[0m\n",
      "91 400\n",
      "Loss =  1215327.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.962421875\u001b[0m\n",
      "92 0\n",
      "Loss =  1223249.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.964921875\u001b[0m\n",
      "92 100\n",
      "Loss =  1219250.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.95828125\u001b[0m\n",
      "92 200\n",
      "Loss =  1221385.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.963203125\u001b[0m\n",
      "92 300\n",
      "Loss =  1218764.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.96140625\u001b[0m\n",
      "92 400\n",
      "Loss =  1215519.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.983671875\u001b[0m\n",
      "93 0\n",
      "Loss =  1213464.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.9740625\u001b[0m\n",
      "93 100\n",
      "Loss =  1216348.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.966328125\u001b[0m\n",
      "93 200\n",
      "Loss =  1215307.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.963828125\u001b[0m\n",
      "93 300\n",
      "Loss =  1215649.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.975703125\u001b[0m\n",
      "93 400\n",
      "Loss =  1218393.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.962265625\u001b[0m\n",
      "94 0\n",
      "Loss =  1220167.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.962265625\u001b[0m\n",
      "94 100\n",
      "Loss =  1215338.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.967734375\u001b[0m\n",
      "94 200\n",
      "Loss =  1217685.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.976328125\u001b[0m\n",
      "94 300\n",
      "Loss =  1213957.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.980625\u001b[0m\n",
      "94 400\n",
      "Loss =  1219678.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.9684375\u001b[0m\n",
      "95 0\n",
      "Loss =  1221751.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9534375\u001b[0m\n",
      "95 100\n",
      "Loss =  1216100.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.97234375\u001b[0m\n",
      "95 200\n",
      "Loss =  1225163.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.935625\u001b[0m\n",
      "95 300\n",
      "Loss =  1215276.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.984375\u001b[0m\n",
      "95 400\n",
      "Loss =  1220553.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.961796875\u001b[0m\n",
      "96 0\n",
      "Loss =  1215543.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.973203125\u001b[0m\n",
      "96 100\n",
      "Loss =  1216131.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.958125\u001b[0m\n",
      "96 200\n",
      "Loss =  1215527.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.97125\u001b[0m\n",
      "96 300\n",
      "Loss =  1221626.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.94453125\u001b[0m\n",
      "96 400\n",
      "Loss =  1217662.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.965703125\u001b[0m\n",
      "97 0\n",
      "Loss =  1215452.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.97375\u001b[0m\n",
      "97 100\n",
      "Loss =  1216424.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.973984375\u001b[0m\n",
      "97 200\n",
      "Loss =  1221359.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.94671875\u001b[0m\n",
      "97 300\n",
      "Loss =  1222107.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.950390625\u001b[0m\n",
      "97 400\n",
      "Loss =  1216068.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.96140625\u001b[0m\n",
      "98 0\n",
      "Loss =  1222933.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.96578125\u001b[0m\n",
      "98 100\n",
      "Loss =  1215196.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.959921875\u001b[0m\n",
      "98 200\n",
      "Loss =  1217640.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.970078125\u001b[0m\n",
      "98 300\n",
      "Loss =  1221185.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.96015625\u001b[0m\n",
      "98 400\n",
      "Loss =  1214161.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.970078125\u001b[0m\n",
      "99 0\n",
      "Loss =  1216802.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.965546875\u001b[0m\n",
      "99 100\n",
      "Loss =  1216808.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.971328125\u001b[0m\n",
      "99 200\n",
      "Loss =  1213761.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.981484375\u001b[0m\n",
      "99 300\n",
      "Loss =  1213448.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.978046875\u001b[0m\n",
      "99 400\n",
      "Loss =  1215730.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.965\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.9644)\n"
     ]
    }
   ],
   "source": [
    "eps_scale = 1\n",
    "for lr in [1e-3]:\n",
    "    for l in [1200]:\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        model1 = BNN(train_loader, [784, l, l, 10], act = nn.ReLU(), n_epochs = 100)\n",
    "        model1.train(lr = lr, decay = 1)\n",
    "        #models.append(model)\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "    \n",
    "        for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "            A = example_data/126\n",
    "            b = example_targets\n",
    "        z = model1.BNet(A).detach()\n",
    "        T_pred = torch.argmax(z, dim = 1)\n",
    "        print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72c398",
   "metadata": {},
   "source": [
    "## Bayesian Tanh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f56648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  3821826.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.09921875\u001b[0m\n",
      "0 100\n",
      "Loss =  3700363.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.586484375\u001b[0m\n",
      "0 200\n",
      "Loss =  3606911.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.81421875\u001b[0m\n",
      "0 300\n",
      "Loss =  3556624.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8471875\u001b[0m\n",
      "0 400\n",
      "Loss =  3492768.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.85109375\u001b[0m\n",
      "1 0\n",
      "Loss =  3451876.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8696875\u001b[0m\n",
      "1 100\n",
      "Loss =  3417922.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.825546875\u001b[0m\n",
      "1 200\n",
      "Loss =  3347777.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.853203125\u001b[0m\n",
      "1 300\n",
      "Loss =  3288026.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.865\u001b[0m\n",
      "1 400\n",
      "Loss =  3242793.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.843125\u001b[0m\n",
      "2 0\n",
      "Loss =  3193126.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.874453125\u001b[0m\n",
      "2 100\n",
      "Loss =  3135582.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.89265625\u001b[0m\n",
      "2 200\n",
      "Loss =  3085711.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.88203125\u001b[0m\n",
      "2 300\n",
      "Loss =  3030855.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.911171875\u001b[0m\n",
      "2 400\n",
      "Loss =  2983968.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.87484375\u001b[0m\n",
      "3 0\n",
      "Loss =  2962193.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.8265625\u001b[0m\n",
      "3 100\n",
      "Loss =  2909277.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.881875\u001b[0m\n",
      "3 200\n",
      "Loss =  2852670.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.883671875\u001b[0m\n",
      "3 300\n",
      "Loss =  2819897.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.87984375\u001b[0m\n",
      "3 400\n",
      "Loss =  2769664.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.85453125\u001b[0m\n",
      "4 0\n",
      "Loss =  2733810.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.878515625\u001b[0m\n",
      "4 100\n",
      "Loss =  2689748.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.8809375\u001b[0m\n",
      "4 200\n",
      "Loss =  2653094.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.888203125\u001b[0m\n",
      "4 300\n",
      "Loss =  2618400.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.888359375\u001b[0m\n",
      "4 400\n",
      "Loss =  2583756.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.868984375\u001b[0m\n",
      "5 0\n",
      "Loss =  2552698.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.855859375\u001b[0m\n",
      "5 100\n",
      "Loss =  2507275.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.8984375\u001b[0m\n",
      "5 200\n",
      "Loss =  2490807.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.865625\u001b[0m\n",
      "5 300\n",
      "Loss =  2444481.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.9021875\u001b[0m\n",
      "5 400\n",
      "Loss =  2414024.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.90515625\u001b[0m\n",
      "6 0\n",
      "Loss =  2406703.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.84875\u001b[0m\n",
      "6 100\n",
      "Loss =  2359660.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.9028125\u001b[0m\n",
      "6 200\n",
      "Loss =  2337404.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.8871875\u001b[0m\n",
      "6 300\n",
      "Loss =  2318689.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.868515625\u001b[0m\n",
      "6 400\n",
      "Loss =  2282664.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.8715625\u001b[0m\n",
      "7 0\n",
      "Loss =  2259766.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.90671875\u001b[0m\n",
      "7 100\n",
      "Loss =  2237944.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.903671875\u001b[0m\n",
      "7 200\n",
      "Loss =  2216565.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.89078125\u001b[0m\n",
      "7 300\n",
      "Loss =  2192550.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.893984375\u001b[0m\n",
      "7 400\n",
      "Loss =  2182155.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.889921875\u001b[0m\n",
      "8 0\n",
      "Loss =  2166962.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.872265625\u001b[0m\n",
      "8 100\n",
      "Loss =  2154226.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.849140625\u001b[0m\n",
      "8 200\n",
      "Loss =  2131493.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.901015625\u001b[0m\n",
      "8 300\n",
      "Loss =  2107345.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.91390625\u001b[0m\n",
      "8 400\n",
      "Loss =  2110389.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.87875\u001b[0m\n",
      "9 0\n",
      "Loss =  2085451.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.87734375\u001b[0m\n",
      "9 100\n",
      "Loss =  2061221.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.884296875\u001b[0m\n",
      "9 200\n",
      "Loss =  2051712.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.908046875\u001b[0m\n",
      "9 300\n",
      "Loss =  2034554.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.8859375\u001b[0m\n",
      "9 400\n",
      "Loss =  2030910.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.862734375\u001b[0m\n",
      "10 0\n",
      "Loss =  2003879.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.917734375\u001b[0m\n",
      "10 100\n",
      "Loss =  1996247.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.912265625\u001b[0m\n",
      "10 200\n",
      "Loss =  1992052.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.869453125\u001b[0m\n",
      "10 300\n",
      "Loss =  1982396.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.84015625\u001b[0m\n",
      "10 400\n",
      "Loss =  1961027.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.88671875\u001b[0m\n",
      "11 0\n",
      "Loss =  1951446.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.890546875\u001b[0m\n",
      "11 100\n",
      "Loss =  1959335.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.83625\u001b[0m\n",
      "11 200\n",
      "Loss =  1932681.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.89578125\u001b[0m\n",
      "11 300\n",
      "Loss =  1925508.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.89203125\u001b[0m\n",
      "11 400\n",
      "Loss =  1910488.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.895078125\u001b[0m\n",
      "12 0\n",
      "Loss =  1907239.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.8628125\u001b[0m\n",
      "12 100\n",
      "Loss =  1891138.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.877734375\u001b[0m\n",
      "12 200\n",
      "Loss =  1888432.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.87828125\u001b[0m\n",
      "12 300\n",
      "Loss =  1874902.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.87078125\u001b[0m\n",
      "12 400\n",
      "Loss =  1871909.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.863828125\u001b[0m\n",
      "13 0\n",
      "Loss =  1867735.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.8415625\u001b[0m\n",
      "13 100\n",
      "Loss =  1864560.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.84546875\u001b[0m\n",
      "13 200\n",
      "Loss =  1842822.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.8640625\u001b[0m\n",
      "13 300\n",
      "Loss =  1853471.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.843984375\u001b[0m\n",
      "13 400\n",
      "Loss =  1826620.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.885\u001b[0m\n",
      "14 0\n",
      "Loss =  1812825.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.90875\u001b[0m\n",
      "14 100\n",
      "Loss =  1819828.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.87453125\u001b[0m\n",
      "14 200\n",
      "Loss =  1815872.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.870390625\u001b[0m\n",
      "14 300\n",
      "Loss =  1820808.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.814140625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 400\n",
      "Loss =  1787217.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.90453125\u001b[0m\n",
      "15 0\n",
      "Loss =  1786762.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.884609375\u001b[0m\n",
      "15 100\n",
      "Loss =  1778784.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.865546875\u001b[0m\n",
      "15 200\n",
      "Loss =  1775342.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.88375\u001b[0m\n",
      "15 300\n",
      "Loss =  1757997.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.9103125\u001b[0m\n",
      "15 400\n",
      "Loss =  1750557.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.88546875\u001b[0m\n",
      "16 0\n",
      "Loss =  1767658.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.83453125\u001b[0m\n",
      "16 100\n",
      "Loss =  1756009.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.85859375\u001b[0m\n",
      "16 200\n",
      "Loss =  1751610.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.848671875\u001b[0m\n",
      "16 300\n",
      "Loss =  1735550.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.871796875\u001b[0m\n",
      "16 400\n",
      "Loss =  1733316.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.88140625\u001b[0m\n",
      "17 0\n",
      "Loss =  1724317.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.9046875\u001b[0m\n",
      "17 100\n",
      "Loss =  1710717.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.871171875\u001b[0m\n",
      "17 200\n",
      "Loss =  1722649.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.8609375\u001b[0m\n",
      "17 300\n",
      "Loss =  1702548.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.87859375\u001b[0m\n",
      "17 400\n",
      "Loss =  1692829.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.91796875\u001b[0m\n",
      "18 0\n",
      "Loss =  1706439.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.872265625\u001b[0m\n",
      "18 100\n",
      "Loss =  1678291.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.89890625\u001b[0m\n",
      "18 200\n",
      "Loss =  1677816.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.897109375\u001b[0m\n",
      "18 300\n",
      "Loss =  1675946.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.884921875\u001b[0m\n",
      "18 400\n",
      "Loss =  1688975.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.836796875\u001b[0m\n",
      "19 0\n",
      "Loss =  1673341.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.85109375\u001b[0m\n",
      "19 100\n",
      "Loss =  1668439.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.858828125\u001b[0m\n",
      "19 200\n",
      "Loss =  1663397.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.8684375\u001b[0m\n",
      "19 300\n",
      "Loss =  1651352.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.902578125\u001b[0m\n",
      "19 400\n",
      "Loss =  1643867.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.88125\u001b[0m\n",
      "20 0\n",
      "Loss =  1644024.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.88875\u001b[0m\n",
      "20 100\n",
      "Loss =  1631413.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.890546875\u001b[0m\n",
      "20 200\n",
      "Loss =  1623689.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.893984375\u001b[0m\n",
      "20 300\n",
      "Loss =  1627247.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.891875\u001b[0m\n",
      "20 400\n",
      "Loss =  1634380.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.894609375\u001b[0m\n",
      "21 0\n",
      "Loss =  1624168.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.880625\u001b[0m\n",
      "21 100\n",
      "Loss =  1607456.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.898125\u001b[0m\n",
      "21 200\n",
      "Loss =  1608723.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.89875\u001b[0m\n",
      "21 300\n",
      "Loss =  1598214.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.893984375\u001b[0m\n",
      "21 400\n",
      "Loss =  1608860.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.85375\u001b[0m\n",
      "22 0\n",
      "Loss =  1603703.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.866171875\u001b[0m\n",
      "22 100\n",
      "Loss =  1597529.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.893828125\u001b[0m\n",
      "22 200\n",
      "Loss =  1587720.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.894609375\u001b[0m\n",
      "22 300\n",
      "Loss =  1588596.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.87640625\u001b[0m\n",
      "22 400\n",
      "Loss =  1580733.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.879921875\u001b[0m\n",
      "23 0\n",
      "Loss =  1592060.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.872734375\u001b[0m\n",
      "23 100\n",
      "Loss =  1588918.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.85671875\u001b[0m\n",
      "23 200\n",
      "Loss =  1568267.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.90703125\u001b[0m\n",
      "23 300\n",
      "Loss =  1560109.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.8959375\u001b[0m\n",
      "23 400\n",
      "Loss =  1559670.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.895234375\u001b[0m\n",
      "24 0\n",
      "Loss =  1577061.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.873984375\u001b[0m\n",
      "24 100\n",
      "Loss =  1565170.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.879765625\u001b[0m\n",
      "24 200\n",
      "Loss =  1553649.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.884453125\u001b[0m\n",
      "24 300\n",
      "Loss =  1568994.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.855078125\u001b[0m\n",
      "24 400\n",
      "Loss =  1537130.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9090625\u001b[0m\n",
      "25 0\n",
      "Loss =  1541954.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.899375\u001b[0m\n",
      "25 100\n",
      "Loss =  1541721.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.87765625\u001b[0m\n",
      "25 200\n",
      "Loss =  1535668.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.896640625\u001b[0m\n",
      "25 300\n",
      "Loss =  1551663.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.854765625\u001b[0m\n",
      "25 400\n",
      "Loss =  1530193.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.902109375\u001b[0m\n",
      "26 0\n",
      "Loss =  1537759.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.86015625\u001b[0m\n",
      "26 100\n",
      "Loss =  1530286.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.838671875\u001b[0m\n",
      "26 200\n",
      "Loss =  1538700.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.880546875\u001b[0m\n",
      "26 300\n",
      "Loss =  1514729.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.895390625\u001b[0m\n",
      "26 400\n",
      "Loss =  1517334.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.893515625\u001b[0m\n",
      "27 0\n",
      "Loss =  1512482.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.913984375\u001b[0m\n",
      "27 100\n",
      "Loss =  1502898.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.90796875\u001b[0m\n",
      "27 200\n",
      "Loss =  1520673.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.825390625\u001b[0m\n",
      "27 300\n",
      "Loss =  1503369.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.90375\u001b[0m\n",
      "27 400\n",
      "Loss =  1499630.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.888125\u001b[0m\n",
      "28 0\n",
      "Loss =  1499621.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.885234375\u001b[0m\n",
      "28 100\n",
      "Loss =  1493531.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.887890625\u001b[0m\n",
      "28 200\n",
      "Loss =  1499982.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.8928125\u001b[0m\n",
      "28 300\n",
      "Loss =  1489408.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.897578125\u001b[0m\n",
      "28 400\n",
      "Loss =  1487872.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.879609375\u001b[0m\n",
      "29 0\n",
      "Loss =  1488009.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.8978125\u001b[0m\n",
      "29 100\n",
      "Loss =  1476981.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.879921875\u001b[0m\n",
      "29 200\n",
      "Loss =  1467782.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.934921875\u001b[0m\n",
      "29 300\n",
      "Loss =  1483603.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.88703125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 400\n",
      "Loss =  1491404.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.88734375\u001b[0m\n",
      "30 0\n",
      "Loss =  1467869.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.891875\u001b[0m\n",
      "30 100\n",
      "Loss =  1467744.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.89390625\u001b[0m\n",
      "30 200\n",
      "Loss =  1470261.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.87375\u001b[0m\n",
      "30 300\n",
      "Loss =  1475143.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.8809375\u001b[0m\n",
      "30 400\n",
      "Loss =  1469669.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.8925\u001b[0m\n",
      "31 0\n",
      "Loss =  1449488.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.929921875\u001b[0m\n",
      "31 100\n",
      "Loss =  1452941.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.922578125\u001b[0m\n",
      "31 200\n",
      "Loss =  1457478.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.902265625\u001b[0m\n",
      "31 300\n",
      "Loss =  1452533.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.916015625\u001b[0m\n",
      "31 400\n",
      "Loss =  1449462.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.879375\u001b[0m\n",
      "32 0\n",
      "Loss =  1460937.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.86046875\u001b[0m\n",
      "32 100\n",
      "Loss =  1454725.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.8646875\u001b[0m\n",
      "32 200\n",
      "Loss =  1454216.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.889453125\u001b[0m\n",
      "32 300\n",
      "Loss =  1440172.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.90265625\u001b[0m\n",
      "32 400\n",
      "Loss =  1445013.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.882421875\u001b[0m\n",
      "33 0\n",
      "Loss =  1448453.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.884375\u001b[0m\n",
      "33 100\n",
      "Loss =  1435660.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.896875\u001b[0m\n",
      "33 200\n",
      "Loss =  1444324.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.91046875\u001b[0m\n",
      "33 300\n",
      "Loss =  1442128.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.8946875\u001b[0m\n",
      "33 400\n",
      "Loss =  1428596.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.893203125\u001b[0m\n",
      "34 0\n",
      "Loss =  1437140.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.901484375\u001b[0m\n",
      "34 100\n",
      "Loss =  1426821.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.920390625\u001b[0m\n",
      "34 200\n",
      "Loss =  1445972.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.824453125\u001b[0m\n",
      "34 300\n",
      "Loss =  1428723.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.888125\u001b[0m\n",
      "34 400\n",
      "Loss =  1421096.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.88703125\u001b[0m\n",
      "35 0\n",
      "Loss =  1422073.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.88953125\u001b[0m\n",
      "35 100\n",
      "Loss =  1420818.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.89046875\u001b[0m\n",
      "35 200\n",
      "Loss =  1413924.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9040625\u001b[0m\n",
      "35 300\n",
      "Loss =  1419594.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.887421875\u001b[0m\n",
      "35 400\n",
      "Loss =  1411942.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.896953125\u001b[0m\n",
      "36 0\n",
      "Loss =  1406732.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.909765625\u001b[0m\n",
      "36 100\n",
      "Loss =  1411424.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.886171875\u001b[0m\n",
      "36 200\n",
      "Loss =  1422236.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.872421875\u001b[0m\n",
      "36 300\n",
      "Loss =  1395056.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.91234375\u001b[0m\n",
      "36 400\n",
      "Loss =  1398722.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.91109375\u001b[0m\n",
      "37 0\n",
      "Loss =  1391073.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.896875\u001b[0m\n",
      "37 100\n",
      "Loss =  1410008.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.89609375\u001b[0m\n",
      "37 200\n",
      "Loss =  1390411.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.928515625\u001b[0m\n",
      "37 300\n",
      "Loss =  1402486.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.888828125\u001b[0m\n",
      "37 400\n",
      "Loss =  1390595.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.905078125\u001b[0m\n",
      "38 0\n",
      "Loss =  1390218.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.891171875\u001b[0m\n",
      "38 100\n",
      "Loss =  1404831.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.8875\u001b[0m\n",
      "38 200\n",
      "Loss =  1391447.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.917890625\u001b[0m\n",
      "38 300\n",
      "Loss =  1397884.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.84515625\u001b[0m\n",
      "38 400\n",
      "Loss =  1387768.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.88921875\u001b[0m\n",
      "39 0\n",
      "Loss =  1383262.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.89234375\u001b[0m\n",
      "39 100\n",
      "Loss =  1389991.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9003125\u001b[0m\n",
      "39 200\n",
      "Loss =  1379418.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.90125\u001b[0m\n",
      "39 300\n",
      "Loss =  1384184.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.8865625\u001b[0m\n",
      "39 400\n",
      "Loss =  1384118.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.896640625\u001b[0m\n",
      "40 0\n",
      "Loss =  1383599.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.90390625\u001b[0m\n",
      "40 100\n",
      "Loss =  1378174.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.8821875\u001b[0m\n",
      "40 200\n",
      "Loss =  1379332.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.916640625\u001b[0m\n",
      "40 300\n",
      "Loss =  1377914.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.8896875\u001b[0m\n",
      "40 400\n",
      "Loss =  1373924.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.89390625\u001b[0m\n",
      "41 0\n",
      "Loss =  1357040.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.95125\u001b[0m\n",
      "41 100\n",
      "Loss =  1375751.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.87484375\u001b[0m\n",
      "41 200\n",
      "Loss =  1370316.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.9146875\u001b[0m\n",
      "41 300\n",
      "Loss =  1363456.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.907109375\u001b[0m\n",
      "41 400\n",
      "Loss =  1371594.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.864765625\u001b[0m\n",
      "42 0\n",
      "Loss =  1355901.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.935625\u001b[0m\n",
      "42 100\n",
      "Loss =  1352929.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.928984375\u001b[0m\n",
      "42 200\n",
      "Loss =  1356637.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.923515625\u001b[0m\n",
      "42 300\n",
      "Loss =  1362905.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.90875\u001b[0m\n",
      "42 400\n",
      "Loss =  1356386.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.909140625\u001b[0m\n",
      "43 0\n",
      "Loss =  1365710.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.911953125\u001b[0m\n",
      "43 100\n",
      "Loss =  1350605.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.91921875\u001b[0m\n",
      "43 200\n",
      "Loss =  1356362.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.906875\u001b[0m\n",
      "43 300\n",
      "Loss =  1380833.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.875859375\u001b[0m\n",
      "43 400\n",
      "Loss =  1348235.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.906484375\u001b[0m\n",
      "44 0\n",
      "Loss =  1352475.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.898203125\u001b[0m\n",
      "44 100\n",
      "Loss =  1344340.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.895\u001b[0m\n",
      "44 200\n",
      "Loss =  1350392.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.917578125\u001b[0m\n",
      "44 300\n",
      "Loss =  1355577.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.880234375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 400\n",
      "Loss =  1345481.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.917109375\u001b[0m\n",
      "45 0\n",
      "Loss =  1340200.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.920859375\u001b[0m\n",
      "45 100\n",
      "Loss =  1342558.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.907421875\u001b[0m\n",
      "45 200\n",
      "Loss =  1341352.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.921953125\u001b[0m\n",
      "45 300\n",
      "Loss =  1345408.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.89015625\u001b[0m\n",
      "45 400\n",
      "Loss =  1346642.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.88859375\u001b[0m\n",
      "46 0\n",
      "Loss =  1341105.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.905703125\u001b[0m\n",
      "46 100\n",
      "Loss =  1346209.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.8840625\u001b[0m\n",
      "46 200\n",
      "Loss =  1335165.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.898359375\u001b[0m\n",
      "46 300\n",
      "Loss =  1347424.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.89609375\u001b[0m\n",
      "46 400\n",
      "Loss =  1332568.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.917578125\u001b[0m\n",
      "47 0\n",
      "Loss =  1323781.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.9153125\u001b[0m\n",
      "47 100\n",
      "Loss =  1343936.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.906328125\u001b[0m\n",
      "47 200\n",
      "Loss =  1349413.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.87140625\u001b[0m\n",
      "47 300\n",
      "Loss =  1332697.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.89890625\u001b[0m\n",
      "47 400\n",
      "Loss =  1323365.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.93609375\u001b[0m\n",
      "48 0\n",
      "Loss =  1331453.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.903359375\u001b[0m\n",
      "48 100\n",
      "Loss =  1323791.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9334375\u001b[0m\n",
      "48 200\n",
      "Loss =  1333836.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.895625\u001b[0m\n",
      "48 300\n",
      "Loss =  1328554.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.89671875\u001b[0m\n",
      "48 400\n",
      "Loss =  1328655.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9121875\u001b[0m\n",
      "49 0\n",
      "Loss =  1317286.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.90875\u001b[0m\n",
      "49 100\n",
      "Loss =  1319279.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.9046875\u001b[0m\n",
      "49 200\n",
      "Loss =  1329958.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.90515625\u001b[0m\n",
      "49 300\n",
      "Loss =  1323682.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.90515625\u001b[0m\n",
      "49 400\n",
      "Loss =  1351508.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.871015625\u001b[0m\n",
      "50 0\n",
      "Loss =  1337547.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.869453125\u001b[0m\n",
      "50 100\n",
      "Loss =  1326595.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9040625\u001b[0m\n",
      "50 200\n",
      "Loss =  1320414.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.903359375\u001b[0m\n",
      "50 300\n",
      "Loss =  1325145.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.90421875\u001b[0m\n",
      "50 400\n",
      "Loss =  1326672.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.928671875\u001b[0m\n",
      "51 0\n",
      "Loss =  1328850.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.908671875\u001b[0m\n",
      "51 100\n",
      "Loss =  1318567.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.908046875\u001b[0m\n",
      "51 200\n",
      "Loss =  1327856.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.906484375\u001b[0m\n",
      "51 300\n",
      "Loss =  1328156.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.8578125\u001b[0m\n",
      "51 400\n",
      "Loss =  1314886.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.911171875\u001b[0m\n",
      "52 0\n",
      "Loss =  1319245.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.90109375\u001b[0m\n",
      "52 100\n",
      "Loss =  1308287.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.936015625\u001b[0m\n",
      "52 200\n",
      "Loss =  1309156.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.930859375\u001b[0m\n",
      "52 300\n",
      "Loss =  1325858.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.8965625\u001b[0m\n",
      "52 400\n",
      "Loss =  1320937.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.89328125\u001b[0m\n",
      "53 0\n",
      "Loss =  1320975.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.908046875\u001b[0m\n",
      "53 100\n",
      "Loss =  1320434.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.876875\u001b[0m\n",
      "53 200\n",
      "Loss =  1319459.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.87921875\u001b[0m\n",
      "53 300\n",
      "Loss =  1324404.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.893203125\u001b[0m\n",
      "53 400\n",
      "Loss =  1299881.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.94078125\u001b[0m\n",
      "54 0\n",
      "Loss =  1304451.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.89421875\u001b[0m\n",
      "54 100\n",
      "Loss =  1327187.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.8815625\u001b[0m\n",
      "54 200\n",
      "Loss =  1303904.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.91578125\u001b[0m\n",
      "54 300\n",
      "Loss =  1301690.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.93578125\u001b[0m\n",
      "54 400\n",
      "Loss =  1302396.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.922421875\u001b[0m\n",
      "55 0\n",
      "Loss =  1302589.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.913359375\u001b[0m\n",
      "55 100\n",
      "Loss =  1312623.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.891953125\u001b[0m\n",
      "55 200\n",
      "Loss =  1310392.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.874296875\u001b[0m\n",
      "55 300\n",
      "Loss =  1299525.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.925078125\u001b[0m\n",
      "55 400\n",
      "Loss =  1308386.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.896640625\u001b[0m\n",
      "56 0\n",
      "Loss =  1312306.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.89296875\u001b[0m\n",
      "56 100\n",
      "Loss =  1302553.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.89453125\u001b[0m\n",
      "56 200\n",
      "Loss =  1308703.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.904765625\u001b[0m\n",
      "56 300\n",
      "Loss =  1317481.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.8990625\u001b[0m\n",
      "56 400\n",
      "Loss =  1303118.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.911796875\u001b[0m\n",
      "57 0\n",
      "Loss =  1304164.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.891328125\u001b[0m\n",
      "57 100\n",
      "Loss =  1288790.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.931796875\u001b[0m\n",
      "57 200\n",
      "Loss =  1310786.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.9084375\u001b[0m\n",
      "57 300\n",
      "Loss =  1304806.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.881484375\u001b[0m\n",
      "57 400\n",
      "Loss =  1304105.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.887265625\u001b[0m\n",
      "58 0\n",
      "Loss =  1303110.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.889296875\u001b[0m\n",
      "58 100\n",
      "Loss =  1302012.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.89203125\u001b[0m\n",
      "58 200\n",
      "Loss =  1296111.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.887734375\u001b[0m\n",
      "58 300\n",
      "Loss =  1294898.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.907421875\u001b[0m\n",
      "58 400\n",
      "Loss =  1306139.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.894453125\u001b[0m\n",
      "59 0\n",
      "Loss =  1299430.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.900546875\u001b[0m\n",
      "59 100\n",
      "Loss =  1302580.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.88\u001b[0m\n",
      "59 200\n",
      "Loss =  1290122.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.92078125\u001b[0m\n",
      "59 300\n",
      "Loss =  1314952.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.883828125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 400\n",
      "Loss =  1283957.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.895234375\u001b[0m\n",
      "60 0\n",
      "Loss =  1293910.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.90703125\u001b[0m\n",
      "60 100\n",
      "Loss =  1289231.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.91921875\u001b[0m\n",
      "60 200\n",
      "Loss =  1293044.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.92421875\u001b[0m\n",
      "60 300\n",
      "Loss =  1297872.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.890546875\u001b[0m\n",
      "60 400\n",
      "Loss =  1287544.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.92703125\u001b[0m\n",
      "61 0\n",
      "Loss =  1292797.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.885390625\u001b[0m\n",
      "61 100\n",
      "Loss =  1298364.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.915546875\u001b[0m\n",
      "61 200\n",
      "Loss =  1298768.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.898515625\u001b[0m\n",
      "61 300\n",
      "Loss =  1296658.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.91953125\u001b[0m\n",
      "61 400\n",
      "Loss =  1305816.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.863984375\u001b[0m\n",
      "62 0\n",
      "Loss =  1293171.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.917734375\u001b[0m\n",
      "62 100\n",
      "Loss =  1295296.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.89203125\u001b[0m\n",
      "62 200\n",
      "Loss =  1288478.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.9121875\u001b[0m\n",
      "62 300\n",
      "Loss =  1292117.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.923203125\u001b[0m\n",
      "62 400\n",
      "Loss =  1286352.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.906328125\u001b[0m\n",
      "63 0\n",
      "Loss =  1282311.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.925625\u001b[0m\n",
      "63 100\n",
      "Loss =  1294996.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.911875\u001b[0m\n",
      "63 200\n",
      "Loss =  1280999.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.910546875\u001b[0m\n",
      "63 300\n",
      "Loss =  1294452.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.882890625\u001b[0m\n",
      "63 400\n",
      "Loss =  1276218.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.925390625\u001b[0m\n",
      "64 0\n",
      "Loss =  1280688.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9103125\u001b[0m\n",
      "64 100\n",
      "Loss =  1296004.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.886484375\u001b[0m\n",
      "64 200\n",
      "Loss =  1287663.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.902578125\u001b[0m\n",
      "64 300\n",
      "Loss =  1279074.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.933203125\u001b[0m\n",
      "64 400\n",
      "Loss =  1284027.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.899375\u001b[0m\n",
      "65 0\n",
      "Loss =  1287515.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.89703125\u001b[0m\n",
      "65 100\n",
      "Loss =  1285293.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.91796875\u001b[0m\n",
      "65 200\n",
      "Loss =  1273264.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.953515625\u001b[0m\n",
      "65 300\n",
      "Loss =  1282400.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.924140625\u001b[0m\n",
      "65 400\n",
      "Loss =  1279252.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.933203125\u001b[0m\n",
      "66 0\n",
      "Loss =  1275038.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.91546875\u001b[0m\n",
      "66 100\n",
      "Loss =  1279458.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.896328125\u001b[0m\n",
      "66 200\n",
      "Loss =  1283315.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.90046875\u001b[0m\n",
      "66 300\n",
      "Loss =  1288356.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.87703125\u001b[0m\n",
      "66 400\n",
      "Loss =  1293309.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.886796875\u001b[0m\n",
      "67 0\n",
      "Loss =  1291474.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.90984375\u001b[0m\n",
      "67 100\n",
      "Loss =  1283828.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9025\u001b[0m\n",
      "67 200\n",
      "Loss =  1284186.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9040625\u001b[0m\n",
      "67 300\n",
      "Loss =  1286686.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.896953125\u001b[0m\n",
      "67 400\n",
      "Loss =  1284214.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.89640625\u001b[0m\n",
      "68 0\n",
      "Loss =  1283955.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.88640625\u001b[0m\n",
      "68 100\n",
      "Loss =  1281720.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9128125\u001b[0m\n",
      "68 200\n",
      "Loss =  1284271.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.90578125\u001b[0m\n",
      "68 300\n",
      "Loss =  1297618.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.876328125\u001b[0m\n",
      "68 400\n",
      "Loss =  1283067.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.901484375\u001b[0m\n",
      "69 0\n",
      "Loss =  1274033.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.895703125\u001b[0m\n",
      "69 100\n",
      "Loss =  1278803.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.900234375\u001b[0m\n",
      "69 200\n",
      "Loss =  1279942.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.9240625\u001b[0m\n",
      "69 300\n",
      "Loss =  1279137.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.898046875\u001b[0m\n",
      "69 400\n",
      "Loss =  1280617.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.8953125\u001b[0m\n",
      "70 0\n",
      "Loss =  1276072.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.926640625\u001b[0m\n",
      "70 100\n",
      "Loss =  1272011.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.903515625\u001b[0m\n",
      "70 200\n",
      "Loss =  1277688.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.92328125\u001b[0m\n",
      "70 300\n",
      "Loss =  1275713.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.90515625\u001b[0m\n",
      "70 400\n",
      "Loss =  1278211.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.90609375\u001b[0m\n",
      "71 0\n",
      "Loss =  1280073.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.923984375\u001b[0m\n",
      "71 100\n",
      "Loss =  1269302.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.91640625\u001b[0m\n",
      "71 200\n",
      "Loss =  1275678.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.90953125\u001b[0m\n",
      "71 300\n",
      "Loss =  1269660.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.93875\u001b[0m\n",
      "71 400\n",
      "Loss =  1273102.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.94359375\u001b[0m\n",
      "72 0\n",
      "Loss =  1280879.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.937265625\u001b[0m\n",
      "72 100\n",
      "Loss =  1271842.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.935625\u001b[0m\n",
      "72 200\n",
      "Loss =  1274776.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.90390625\u001b[0m\n",
      "72 300\n",
      "Loss =  1284879.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.900625\u001b[0m\n",
      "72 400\n",
      "Loss =  1273650.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.891484375\u001b[0m\n",
      "73 0\n",
      "Loss =  1273964.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.908515625\u001b[0m\n",
      "73 100\n",
      "Loss =  1270896.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.906484375\u001b[0m\n",
      "73 200\n",
      "Loss =  1279761.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.91328125\u001b[0m\n",
      "73 300\n",
      "Loss =  1280676.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.89328125\u001b[0m\n",
      "73 400\n",
      "Loss =  1271235.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.9178125\u001b[0m\n",
      "74 0\n",
      "Loss =  1269946.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.923046875\u001b[0m\n",
      "74 100\n",
      "Loss =  1265774.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.91796875\u001b[0m\n",
      "74 200\n",
      "Loss =  1265317.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.921875\u001b[0m\n",
      "74 300\n",
      "Loss =  1280371.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.88328125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 400\n",
      "Loss =  1266429.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.91671875\u001b[0m\n",
      "75 0\n",
      "Loss =  1287222.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.874921875\u001b[0m\n",
      "75 100\n",
      "Loss =  1267202.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.915703125\u001b[0m\n",
      "75 200\n",
      "Loss =  1273639.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.942265625\u001b[0m\n",
      "75 300\n",
      "Loss =  1264306.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.93203125\u001b[0m\n",
      "75 400\n",
      "Loss =  1279996.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.90875\u001b[0m\n",
      "76 0\n",
      "Loss =  1266117.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.9175\u001b[0m\n",
      "76 100\n",
      "Loss =  1276065.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.8803125\u001b[0m\n",
      "76 200\n",
      "Loss =  1261814.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.93828125\u001b[0m\n",
      "76 300\n",
      "Loss =  1265052.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.923515625\u001b[0m\n",
      "76 400\n",
      "Loss =  1267779.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.90046875\u001b[0m\n",
      "77 0\n",
      "Loss =  1291976.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.911953125\u001b[0m\n",
      "77 100\n",
      "Loss =  1299307.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.891484375\u001b[0m\n",
      "77 200\n",
      "Loss =  1266669.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.914765625\u001b[0m\n",
      "77 300\n",
      "Loss =  1269075.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.914375\u001b[0m\n",
      "77 400\n",
      "Loss =  1268693.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9084375\u001b[0m\n",
      "78 0\n",
      "Loss =  1259090.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.9265625\u001b[0m\n",
      "78 100\n",
      "Loss =  1274319.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.9203125\u001b[0m\n",
      "78 200\n",
      "Loss =  1273424.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.8940625\u001b[0m\n",
      "78 300\n",
      "Loss =  1280709.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.89296875\u001b[0m\n",
      "78 400\n",
      "Loss =  1267403.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.91671875\u001b[0m\n",
      "79 0\n",
      "Loss =  1266125.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.90390625\u001b[0m\n",
      "79 100\n",
      "Loss =  1275032.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.90546875\u001b[0m\n",
      "79 200\n",
      "Loss =  1266829.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.885859375\u001b[0m\n",
      "79 300\n",
      "Loss =  1275669.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.893828125\u001b[0m\n",
      "79 400\n",
      "Loss =  1268418.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9159375\u001b[0m\n",
      "80 0\n",
      "Loss =  1275902.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.891484375\u001b[0m\n",
      "80 100\n",
      "Loss =  1266468.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.919453125\u001b[0m\n",
      "80 200\n",
      "Loss =  1271095.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.89703125\u001b[0m\n",
      "80 300\n",
      "Loss =  1256456.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.9359375\u001b[0m\n",
      "80 400\n",
      "Loss =  1260609.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.93\u001b[0m\n",
      "81 0\n",
      "Loss =  1267293.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.900546875\u001b[0m\n",
      "81 100\n",
      "Loss =  1263832.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.90203125\u001b[0m\n",
      "81 200\n",
      "Loss =  1260858.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.901796875\u001b[0m\n",
      "81 300\n",
      "Loss =  1269212.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.918828125\u001b[0m\n",
      "81 400\n",
      "Loss =  1261969.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.901484375\u001b[0m\n",
      "82 0\n",
      "Loss =  1268616.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.906796875\u001b[0m\n",
      "82 100\n",
      "Loss =  1261252.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.921484375\u001b[0m\n",
      "82 200\n",
      "Loss =  1266210.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.903671875\u001b[0m\n",
      "82 300\n",
      "Loss =  1266164.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.920703125\u001b[0m\n",
      "82 400\n",
      "Loss =  1290487.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.89765625\u001b[0m\n",
      "83 0\n",
      "Loss =  1275289.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.903203125\u001b[0m\n",
      "83 100\n",
      "Loss =  1257446.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.943828125\u001b[0m\n",
      "83 200\n",
      "Loss =  1267539.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.904765625\u001b[0m\n",
      "83 300\n",
      "Loss =  1274019.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.8771875\u001b[0m\n",
      "83 400\n",
      "Loss =  1267612.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.89671875\u001b[0m\n",
      "84 0\n",
      "Loss =  1279378.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.887578125\u001b[0m\n",
      "84 100\n",
      "Loss =  1259599.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.89734375\u001b[0m\n",
      "84 200\n",
      "Loss =  1282409.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.869765625\u001b[0m\n",
      "84 300\n",
      "Loss =  1259733.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.91109375\u001b[0m\n",
      "84 400\n",
      "Loss =  1261689.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.926640625\u001b[0m\n",
      "85 0\n",
      "Loss =  1260869.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.898984375\u001b[0m\n",
      "85 100\n",
      "Loss =  1265502.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.89359375\u001b[0m\n",
      "85 200\n",
      "Loss =  1258448.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.92328125\u001b[0m\n",
      "85 300\n",
      "Loss =  1263662.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.897421875\u001b[0m\n",
      "85 400\n",
      "Loss =  1264817.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.897578125\u001b[0m\n",
      "86 0\n",
      "Loss =  1256671.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.928671875\u001b[0m\n",
      "86 100\n",
      "Loss =  1261707.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.92359375\u001b[0m\n",
      "86 200\n",
      "Loss =  1264920.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.903828125\u001b[0m\n",
      "86 300\n",
      "Loss =  1272405.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.89890625\u001b[0m\n",
      "86 400\n",
      "Loss =  1261045.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.93640625\u001b[0m\n",
      "87 0\n",
      "Loss =  1270856.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.901484375\u001b[0m\n",
      "87 100\n",
      "Loss =  1261975.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.92234375\u001b[0m\n",
      "87 200\n",
      "Loss =  1268283.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.901015625\u001b[0m\n",
      "87 300\n",
      "Loss =  1276197.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.91515625\u001b[0m\n",
      "87 400\n",
      "Loss =  1266392.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.9065625\u001b[0m\n",
      "88 0\n",
      "Loss =  1261016.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.92890625\u001b[0m\n",
      "88 100\n",
      "Loss =  1268963.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.897890625\u001b[0m\n",
      "88 200\n",
      "Loss =  1263861.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.897421875\u001b[0m\n",
      "88 300\n",
      "Loss =  1260478.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.9153125\u001b[0m\n",
      "88 400\n",
      "Loss =  1263026.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.910703125\u001b[0m\n",
      "89 0\n",
      "Loss =  1271977.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.929453125\u001b[0m\n",
      "89 100\n",
      "Loss =  1266393.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.9171875\u001b[0m\n",
      "89 200\n",
      "Loss =  1278441.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.88421875\u001b[0m\n",
      "89 300\n",
      "Loss =  1264739.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.896015625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 400\n",
      "Loss =  1262065.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.92875\u001b[0m\n",
      "90 0\n",
      "Loss =  1262777.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.909453125\u001b[0m\n",
      "90 100\n",
      "Loss =  1262041.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.9121875\u001b[0m\n",
      "90 200\n",
      "Loss =  1260350.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.925390625\u001b[0m\n",
      "90 300\n",
      "Loss =  1260515.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.9140625\u001b[0m\n",
      "90 400\n",
      "Loss =  1257221.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.91390625\u001b[0m\n",
      "91 0\n",
      "Loss =  1255835.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.9346875\u001b[0m\n",
      "91 100\n",
      "Loss =  1253669.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.918828125\u001b[0m\n",
      "91 200\n",
      "Loss =  1255392.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.912265625\u001b[0m\n",
      "91 300\n",
      "Loss =  1270825.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.91515625\u001b[0m\n",
      "91 400\n",
      "Loss =  1264192.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.91484375\u001b[0m\n",
      "92 0\n",
      "Loss =  1260655.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.9078125\u001b[0m\n",
      "92 100\n",
      "Loss =  1257377.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.921171875\u001b[0m\n",
      "92 200\n",
      "Loss =  1262103.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.92828125\u001b[0m\n",
      "92 300\n",
      "Loss =  1268118.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.910703125\u001b[0m\n",
      "92 400\n",
      "Loss =  1259888.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.902421875\u001b[0m\n",
      "93 0\n",
      "Loss =  1261316.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.906875\u001b[0m\n",
      "93 100\n",
      "Loss =  1257365.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.908515625\u001b[0m\n",
      "93 200\n",
      "Loss =  1270001.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.889765625\u001b[0m\n",
      "93 300\n",
      "Loss =  1261237.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.88828125\u001b[0m\n",
      "93 400\n",
      "Loss =  1256711.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.9178125\u001b[0m\n",
      "94 0\n",
      "Loss =  1262898.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.899921875\u001b[0m\n",
      "94 100\n",
      "Loss =  1260494.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.89390625\u001b[0m\n",
      "94 200\n",
      "Loss =  1258295.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.932734375\u001b[0m\n",
      "94 300\n",
      "Loss =  1251334.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.95171875\u001b[0m\n",
      "94 400\n",
      "Loss =  1267637.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.910703125\u001b[0m\n",
      "95 0\n",
      "Loss =  1253124.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9159375\u001b[0m\n",
      "95 100\n",
      "Loss =  1254983.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9271875\u001b[0m\n",
      "95 200\n",
      "Loss =  1261263.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.91859375\u001b[0m\n",
      "95 300\n",
      "Loss =  1254725.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.913984375\u001b[0m\n",
      "95 400\n",
      "Loss =  1267504.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.8975\u001b[0m\n",
      "96 0\n",
      "Loss =  1256461.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.91390625\u001b[0m\n",
      "96 100\n",
      "Loss =  1267019.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.8959375\u001b[0m\n",
      "96 200\n",
      "Loss =  1257390.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.918203125\u001b[0m\n",
      "96 300\n",
      "Loss =  1260120.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.91234375\u001b[0m\n",
      "96 400\n",
      "Loss =  1251422.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.92734375\u001b[0m\n",
      "97 0\n",
      "Loss =  1254193.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.924609375\u001b[0m\n",
      "97 100\n",
      "Loss =  1281563.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.88875\u001b[0m\n",
      "97 200\n",
      "Loss =  1262824.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.922421875\u001b[0m\n",
      "97 300\n",
      "Loss =  1255896.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.927265625\u001b[0m\n",
      "97 400\n",
      "Loss =  1272513.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.884140625\u001b[0m\n",
      "98 0\n",
      "Loss =  1269962.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.884921875\u001b[0m\n",
      "98 100\n",
      "Loss =  1258190.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.91875\u001b[0m\n",
      "98 200\n",
      "Loss =  1251695.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.936015625\u001b[0m\n",
      "98 300\n",
      "Loss =  1265271.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.90703125\u001b[0m\n",
      "98 400\n",
      "Loss =  1255515.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.9346875\u001b[0m\n",
      "99 0\n",
      "Loss =  1250438.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.928046875\u001b[0m\n",
      "99 100\n",
      "Loss =  1254235.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.91484375\u001b[0m\n",
      "99 200\n",
      "Loss =  1258367.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.9328125\u001b[0m\n",
      "99 300\n",
      "Loss =  1256725.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.92296875\u001b[0m\n",
      "99 400\n",
      "Loss =  1269074.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.89203125\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0y/hx4crw9178xfvr_01vxxcmkh0000gn/T/ipykernel_75297/3503948103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m126\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mT_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "eps_scale = 1\n",
    "for lr in [1e-3]:\n",
    "    for l in [1200]:\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        model2 = BNN(train_loader, [784, l, l, 10], act = nn.Tanh(), n_epochs = 100)\n",
    "        model2.train(lr = lr, decay = 1)\n",
    "        #models.append(model)\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8294bcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9287)\n"
     ]
    }
   ],
   "source": [
    "        for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "            A = example_data/126\n",
    "            b = example_targets\n",
    "        z = model2.BNet(A).detach()\n",
    "        T_pred = torch.argmax(z, dim = 1)\n",
    "        print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6338f",
   "metadata": {},
   "source": [
    "## Vanila NN SGD-ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d635b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  3823568.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.104921875\u001b[0m\n",
      "0 100\n",
      "Loss =  3704993.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.339453125\u001b[0m\n",
      "0 200\n",
      "Loss =  3567624.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.734453125\u001b[0m\n",
      "0 300\n",
      "Loss =  3481899.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.728203125\u001b[0m\n",
      "0 400\n",
      "Loss =  3391570.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.814765625\u001b[0m\n",
      "1 0\n",
      "Loss =  3345900.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79734375\u001b[0m\n",
      "1 100\n",
      "Loss =  3283108.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79546875\u001b[0m\n",
      "1 200\n",
      "Loss =  3194635.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.855234375\u001b[0m\n",
      "1 300\n",
      "Loss =  3120741.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8571875\u001b[0m\n",
      "1 400\n",
      "Loss =  3052463.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.869765625\u001b[0m\n",
      "2 0\n",
      "Loss =  3006507.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.856328125\u001b[0m\n",
      "2 100\n",
      "Loss =  2942416.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.878125\u001b[0m\n",
      "2 200\n",
      "Loss =  2870736.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.905078125\u001b[0m\n",
      "2 300\n",
      "Loss =  2807153.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.914765625\u001b[0m\n",
      "2 400\n",
      "Loss =  2745357.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.905078125\u001b[0m\n",
      "3 0\n",
      "Loss =  2706608.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.8571875\u001b[0m\n",
      "3 100\n",
      "Loss =  2644451.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.93015625\u001b[0m\n",
      "3 200\n",
      "Loss =  2589776.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.92796875\u001b[0m\n",
      "3 300\n",
      "Loss =  2537682.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.91609375\u001b[0m\n",
      "3 400\n",
      "Loss =  2485291.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.906328125\u001b[0m\n",
      "4 0\n",
      "Loss =  2448040.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.900234375\u001b[0m\n",
      "4 100\n",
      "Loss =  2400772.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.900078125\u001b[0m\n",
      "4 200\n",
      "Loss =  2347656.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.9225\u001b[0m\n",
      "4 300\n",
      "Loss =  2324777.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.8634375\u001b[0m\n",
      "4 400\n",
      "Loss =  2267086.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.884765625\u001b[0m\n",
      "5 0\n",
      "Loss =  2235307.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.898671875\u001b[0m\n",
      "5 100\n",
      "Loss =  2196713.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.894765625\u001b[0m\n",
      "5 200\n",
      "Loss =  2152163.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.897421875\u001b[0m\n",
      "5 300\n",
      "Loss =  2117713.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.9103125\u001b[0m\n",
      "5 400\n",
      "Loss =  2072061.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.95515625\u001b[0m\n",
      "6 0\n",
      "Loss =  2070262.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.903203125\u001b[0m\n",
      "6 100\n",
      "Loss =  2024249.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.94859375\u001b[0m\n",
      "6 200\n",
      "Loss =  1989639.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.947734375\u001b[0m\n",
      "6 300\n",
      "Loss =  1958955.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.94765625\u001b[0m\n",
      "6 400\n",
      "Loss =  1941769.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.9159375\u001b[0m\n",
      "7 0\n",
      "Loss =  1915162.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.928125\u001b[0m\n",
      "7 100\n",
      "Loss =  1905317.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.8796875\u001b[0m\n",
      "7 200\n",
      "Loss =  1870387.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.92109375\u001b[0m\n",
      "7 300\n",
      "Loss =  1844877.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.92578125\u001b[0m\n",
      "7 400\n",
      "Loss =  1819932.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.95796875\u001b[0m\n",
      "8 0\n",
      "Loss =  1810784.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.897421875\u001b[0m\n",
      "8 100\n",
      "Loss =  1788304.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.926328125\u001b[0m\n",
      "8 200\n",
      "Loss =  1768036.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.922265625\u001b[0m\n",
      "8 300\n",
      "Loss =  1748249.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.932421875\u001b[0m\n",
      "8 400\n",
      "Loss =  1734427.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.89015625\u001b[0m\n",
      "9 0\n",
      "Loss =  1720811.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.93625\u001b[0m\n",
      "9 100\n",
      "Loss =  1709859.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.913828125\u001b[0m\n",
      "9 200\n",
      "Loss =  1685920.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.95453125\u001b[0m\n",
      "9 300\n",
      "Loss =  1673070.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.94234375\u001b[0m\n",
      "9 400\n",
      "Loss =  1662291.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.915390625\u001b[0m\n",
      "10 0\n",
      "Loss =  1652688.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.93765625\u001b[0m\n",
      "10 100\n",
      "Loss =  1636407.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.926796875\u001b[0m\n",
      "10 200\n",
      "Loss =  1622422.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.939921875\u001b[0m\n",
      "10 300\n",
      "Loss =  1613711.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.949765625\u001b[0m\n",
      "10 400\n",
      "Loss =  1597434.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.93953125\u001b[0m\n",
      "11 0\n",
      "Loss =  1599632.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.90375\u001b[0m\n",
      "11 100\n",
      "Loss =  1585388.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.915625\u001b[0m\n",
      "11 200\n",
      "Loss =  1576665.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.9165625\u001b[0m\n",
      "11 300\n",
      "Loss =  1557891.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.93359375\u001b[0m\n",
      "11 400\n",
      "Loss =  1551495.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.94484375\u001b[0m\n",
      "12 0\n",
      "Loss =  1543952.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9396875\u001b[0m\n",
      "12 100\n",
      "Loss =  1542015.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.910859375\u001b[0m\n",
      "12 200\n",
      "Loss =  1522485.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.959453125\u001b[0m\n",
      "12 300\n",
      "Loss =  1517548.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9475\u001b[0m\n",
      "12 400\n",
      "Loss =  1515227.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.91765625\u001b[0m\n",
      "13 0\n",
      "Loss =  1503967.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.94921875\u001b[0m\n",
      "13 100\n",
      "Loss =  1497986.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.930625\u001b[0m\n",
      "13 200\n",
      "Loss =  1494022.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.923515625\u001b[0m\n",
      "13 300\n",
      "Loss =  1477090.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.947890625\u001b[0m\n",
      "13 400\n",
      "Loss =  1476592.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.92390625\u001b[0m\n",
      "14 0\n",
      "Loss =  1475526.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.88625\u001b[0m\n",
      "14 100\n",
      "Loss =  1467764.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.933984375\u001b[0m\n",
      "14 200\n",
      "Loss =  1458511.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9371875\u001b[0m\n",
      "14 300\n",
      "Loss =  1446772.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.93953125\u001b[0m\n",
      "14 400\n",
      "Loss =  1446591.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.920625\u001b[0m\n",
      "15 0\n",
      "Loss =  1435785.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.95640625\u001b[0m\n",
      "15 100\n",
      "Loss =  1429620.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.963046875\u001b[0m\n",
      "15 200\n",
      "Loss =  1433183.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.953125\u001b[0m\n",
      "15 300\n",
      "Loss =  1422559.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.954375\u001b[0m\n",
      "15 400\n",
      "Loss =  1421911.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.93203125\u001b[0m\n",
      "16 0\n",
      "Loss =  1419426.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.92046875\u001b[0m\n",
      "16 100\n",
      "Loss =  1412008.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.905703125\u001b[0m\n",
      "16 200\n",
      "Loss =  1399886.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.94625\u001b[0m\n",
      "16 300\n",
      "Loss =  1398644.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.928671875\u001b[0m\n",
      "16 400\n",
      "Loss =  1392292.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.9640625\u001b[0m\n",
      "17 0\n",
      "Loss =  1396048.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.92171875\u001b[0m\n",
      "17 100\n",
      "Loss =  1385660.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.946953125\u001b[0m\n",
      "17 200\n",
      "Loss =  1378702.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.961328125\u001b[0m\n",
      "17 300\n",
      "Loss =  1381159.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.944453125\u001b[0m\n",
      "17 400\n",
      "Loss =  1373947.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.94734375\u001b[0m\n",
      "18 0\n",
      "Loss =  1367421.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.943671875\u001b[0m\n",
      "18 100\n",
      "Loss =  1366841.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9409375\u001b[0m\n",
      "18 200\n",
      "Loss =  1366481.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9378125\u001b[0m\n",
      "18 300\n",
      "Loss =  1367707.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.939296875\u001b[0m\n",
      "18 400\n",
      "Loss =  1362198.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.926015625\u001b[0m\n",
      "19 0\n",
      "Loss =  1357280.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.93875\u001b[0m\n",
      "19 100\n",
      "Loss =  1352441.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.936796875\u001b[0m\n",
      "19 200\n",
      "Loss =  1347404.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.950390625\u001b[0m\n",
      "19 300\n",
      "Loss =  1346752.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.938125\u001b[0m\n",
      "19 400\n",
      "Loss =  1343008.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.93453125\u001b[0m\n",
      "20 0\n",
      "Loss =  1334788.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.96453125\u001b[0m\n",
      "20 100\n",
      "Loss =  1331553.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.9625\u001b[0m\n",
      "20 200\n",
      "Loss =  1328617.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.96109375\u001b[0m\n",
      "20 300\n",
      "Loss =  1332095.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.954765625\u001b[0m\n",
      "20 400\n",
      "Loss =  1327416.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.9559375\u001b[0m\n",
      "21 0\n",
      "Loss =  1323739.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.94359375\u001b[0m\n",
      "21 100\n",
      "Loss =  1316634.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.979921875\u001b[0m\n",
      "21 200\n",
      "Loss =  1318373.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.970703125\u001b[0m\n",
      "21 300\n",
      "Loss =  1320225.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.939296875\u001b[0m\n",
      "21 400\n",
      "Loss =  1312343.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.961796875\u001b[0m\n",
      "22 0\n",
      "Loss =  1313691.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.94015625\u001b[0m\n",
      "22 100\n",
      "Loss =  1310833.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9440625\u001b[0m\n",
      "22 200\n",
      "Loss =  1305558.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.95890625\u001b[0m\n",
      "22 300\n",
      "Loss =  1310844.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9371875\u001b[0m\n",
      "22 400\n",
      "Loss =  1312078.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.91625\u001b[0m\n",
      "23 0\n",
      "Loss =  1302286.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9459375\u001b[0m\n",
      "23 100\n",
      "Loss =  1302004.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.953515625\u001b[0m\n",
      "23 200\n",
      "Loss =  1306596.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9415625\u001b[0m\n",
      "23 300\n",
      "Loss =  1307551.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9371875\u001b[0m\n",
      "23 400\n",
      "Loss =  1298533.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.94109375\u001b[0m\n",
      "24 0\n",
      "Loss =  1301400.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.950390625\u001b[0m\n",
      "24 100\n",
      "Loss =  1297678.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.938125\u001b[0m\n",
      "24 200\n",
      "Loss =  1288414.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.96109375\u001b[0m\n",
      "24 300\n",
      "Loss =  1287018.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.957890625\u001b[0m\n",
      "24 400\n",
      "Loss =  1289325.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9525\u001b[0m\n",
      "25 0\n",
      "Loss =  1291475.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.9446875\u001b[0m\n",
      "25 100\n",
      "Loss =  1285700.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.945859375\u001b[0m\n",
      "25 200\n",
      "Loss =  1283489.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.954609375\u001b[0m\n",
      "25 300\n",
      "Loss =  1284942.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.956328125\u001b[0m\n",
      "25 400\n",
      "Loss =  1284418.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.9253125\u001b[0m\n",
      "26 0\n",
      "Loss =  1276404.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.965390625\u001b[0m\n",
      "26 100\n",
      "Loss =  1283326.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.97046875\u001b[0m\n",
      "26 200\n",
      "Loss =  1275811.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.964296875\u001b[0m\n",
      "26 300\n",
      "Loss =  1278005.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.949140625\u001b[0m\n",
      "26 400\n",
      "Loss =  1270566.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.98125\u001b[0m\n",
      "27 0\n",
      "Loss =  1276037.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.948359375\u001b[0m\n",
      "27 100\n",
      "Loss =  1269991.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.973984375\u001b[0m\n",
      "27 200\n",
      "Loss =  1273475.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.941015625\u001b[0m\n",
      "27 300\n",
      "Loss =  1268974.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.955078125\u001b[0m\n",
      "27 400\n",
      "Loss =  1276722.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.926015625\u001b[0m\n",
      "28 0\n",
      "Loss =  1272765.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.9525\u001b[0m\n",
      "28 100\n",
      "Loss =  1268987.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.960234375\u001b[0m\n",
      "28 200\n",
      "Loss =  1266452.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.957578125\u001b[0m\n",
      "28 300\n",
      "Loss =  1274774.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.929296875\u001b[0m\n",
      "28 400\n",
      "Loss =  1271197.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.927890625\u001b[0m\n",
      "29 0\n",
      "Loss =  1267449.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.957421875\u001b[0m\n",
      "29 100\n",
      "Loss =  1269044.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.928203125\u001b[0m\n",
      "29 200\n",
      "Loss =  1263321.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.955859375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 300\n",
      "Loss =  1262371.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.955\u001b[0m\n",
      "29 400\n",
      "Loss =  1256992.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.970390625\u001b[0m\n",
      "30 0\n",
      "Loss =  1256911.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.970546875\u001b[0m\n",
      "30 100\n",
      "Loss =  1262088.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9403125\u001b[0m\n",
      "30 200\n",
      "Loss =  1264517.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.93546875\u001b[0m\n",
      "30 300\n",
      "Loss =  1253716.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.975703125\u001b[0m\n",
      "30 400\n",
      "Loss =  1259334.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.95171875\u001b[0m\n",
      "31 0\n",
      "Loss =  1251734.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.965078125\u001b[0m\n",
      "31 100\n",
      "Loss =  1256441.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.9521875\u001b[0m\n",
      "31 200\n",
      "Loss =  1257767.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.95390625\u001b[0m\n",
      "31 300\n",
      "Loss =  1251435.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.963203125\u001b[0m\n",
      "31 400\n",
      "Loss =  1258712.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.951171875\u001b[0m\n",
      "32 0\n",
      "Loss =  1261219.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9546875\u001b[0m\n",
      "32 100\n",
      "Loss =  1252498.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.951640625\u001b[0m\n",
      "32 200\n",
      "Loss =  1249101.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.96296875\u001b[0m\n",
      "32 300\n",
      "Loss =  1253265.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.95453125\u001b[0m\n",
      "32 400\n",
      "Loss =  1254562.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.94984375\u001b[0m\n",
      "33 0\n",
      "Loss =  1257873.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.939375\u001b[0m\n",
      "33 100\n",
      "Loss =  1245500.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.96078125\u001b[0m\n",
      "33 200\n",
      "Loss =  1255346.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.936640625\u001b[0m\n",
      "33 300\n",
      "Loss =  1248261.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.952421875\u001b[0m\n",
      "33 400\n",
      "Loss =  1246700.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9496875\u001b[0m\n",
      "34 0\n",
      "Loss =  1247534.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.943359375\u001b[0m\n",
      "34 100\n",
      "Loss =  1246447.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.959609375\u001b[0m\n",
      "34 200\n",
      "Loss =  1243328.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.977890625\u001b[0m\n",
      "34 300\n",
      "Loss =  1241791.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.982109375\u001b[0m\n",
      "34 400\n",
      "Loss =  1243148.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.9703125\u001b[0m\n",
      "35 0\n",
      "Loss =  1246100.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.96953125\u001b[0m\n",
      "35 100\n",
      "Loss =  1248052.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9428125\u001b[0m\n",
      "35 200\n",
      "Loss =  1245800.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.94015625\u001b[0m\n",
      "35 300\n",
      "Loss =  1243681.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.947890625\u001b[0m\n",
      "35 400\n",
      "Loss =  1243421.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.947421875\u001b[0m\n",
      "36 0\n",
      "Loss =  1240590.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.96796875\u001b[0m\n",
      "36 100\n",
      "Loss =  1249888.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.92921875\u001b[0m\n",
      "36 200\n",
      "Loss =  1247292.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.95046875\u001b[0m\n",
      "36 300\n",
      "Loss =  1242411.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.95953125\u001b[0m\n",
      "36 400\n",
      "Loss =  1247546.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.925546875\u001b[0m\n",
      "37 0\n",
      "Loss =  1236788.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.977421875\u001b[0m\n",
      "37 100\n",
      "Loss =  1247016.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.941953125\u001b[0m\n",
      "37 200\n",
      "Loss =  1242228.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.961875\u001b[0m\n",
      "37 300\n",
      "Loss =  1239700.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.94921875\u001b[0m\n",
      "37 400\n",
      "Loss =  1237956.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.974921875\u001b[0m\n",
      "38 0\n",
      "Loss =  1239852.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.96046875\u001b[0m\n",
      "38 100\n",
      "Loss =  1241427.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.94640625\u001b[0m\n",
      "38 200\n",
      "Loss =  1244378.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.943671875\u001b[0m\n",
      "38 300\n",
      "Loss =  1245916.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.94703125\u001b[0m\n",
      "38 400\n",
      "Loss =  1250705.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.925625\u001b[0m\n",
      "39 0\n",
      "Loss =  1235362.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9609375\u001b[0m\n",
      "39 100\n",
      "Loss =  1238924.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9659375\u001b[0m\n",
      "39 200\n",
      "Loss =  1241599.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.962734375\u001b[0m\n",
      "39 300\n",
      "Loss =  1234337.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9725\u001b[0m\n",
      "39 400\n",
      "Loss =  1233693.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.960234375\u001b[0m\n",
      "40 0\n",
      "Loss =  1234927.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.984375\u001b[0m\n",
      "40 100\n",
      "Loss =  1242968.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.94796875\u001b[0m\n",
      "40 200\n",
      "Loss =  1234330.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.98234375\u001b[0m\n",
      "40 300\n",
      "Loss =  1234771.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.95765625\u001b[0m\n",
      "40 400\n",
      "Loss =  1232607.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.980234375\u001b[0m\n",
      "41 0\n",
      "Loss =  1237219.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.954140625\u001b[0m\n",
      "41 100\n",
      "Loss =  1232982.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.955625\u001b[0m\n",
      "41 200\n",
      "Loss =  1236482.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.956796875\u001b[0m\n",
      "41 300\n",
      "Loss =  1233029.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.9603125\u001b[0m\n",
      "41 400\n",
      "Loss =  1229899.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.973515625\u001b[0m\n",
      "42 0\n",
      "Loss =  1244468.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.930390625\u001b[0m\n",
      "42 100\n",
      "Loss =  1240859.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.945078125\u001b[0m\n",
      "42 200\n",
      "Loss =  1233731.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.9559375\u001b[0m\n",
      "42 300\n",
      "Loss =  1230619.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.974609375\u001b[0m\n",
      "42 400\n",
      "Loss =  1231979.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.967421875\u001b[0m\n",
      "43 0\n",
      "Loss =  1234749.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.973515625\u001b[0m\n",
      "43 100\n",
      "Loss =  1231803.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.95703125\u001b[0m\n",
      "43 200\n",
      "Loss =  1234077.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.95140625\u001b[0m\n",
      "43 300\n",
      "Loss =  1235129.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.95015625\u001b[0m\n",
      "43 400\n",
      "Loss =  1233535.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.94796875\u001b[0m\n",
      "44 0\n",
      "Loss =  1229688.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9590625\u001b[0m\n",
      "44 100\n",
      "Loss =  1230580.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.966640625\u001b[0m\n",
      "44 200\n",
      "Loss =  1233956.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.949453125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 300\n",
      "Loss =  1231777.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.967734375\u001b[0m\n",
      "44 400\n",
      "Loss =  1232850.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.961171875\u001b[0m\n",
      "45 0\n",
      "Loss =  1237256.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.946796875\u001b[0m\n",
      "45 100\n",
      "Loss =  1228113.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.9715625\u001b[0m\n",
      "45 200\n",
      "Loss =  1234403.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.955546875\u001b[0m\n",
      "45 300\n",
      "Loss =  1231743.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.963671875\u001b[0m\n",
      "45 400\n",
      "Loss =  1228711.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.95640625\u001b[0m\n",
      "46 0\n",
      "Loss =  1229031.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.980546875\u001b[0m\n",
      "46 100\n",
      "Loss =  1235066.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.960625\u001b[0m\n",
      "46 200\n",
      "Loss =  1226522.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.97078125\u001b[0m\n",
      "46 300\n",
      "Loss =  1233724.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.9571875\u001b[0m\n",
      "46 400\n",
      "Loss =  1230974.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.941328125\u001b[0m\n",
      "47 0\n",
      "Loss =  1235645.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.9475\u001b[0m\n",
      "47 100\n",
      "Loss =  1226515.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.980546875\u001b[0m\n",
      "47 200\n",
      "Loss =  1229936.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.95484375\u001b[0m\n",
      "47 300\n",
      "Loss =  1231603.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.95640625\u001b[0m\n",
      "47 400\n",
      "Loss =  1228539.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.963671875\u001b[0m\n",
      "48 0\n",
      "Loss =  1235574.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.95\u001b[0m\n",
      "48 100\n",
      "Loss =  1228105.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9575\u001b[0m\n",
      "48 200\n",
      "Loss =  1230704.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.948515625\u001b[0m\n",
      "48 300\n",
      "Loss =  1231846.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.953203125\u001b[0m\n",
      "48 400\n",
      "Loss =  1241952.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.946640625\u001b[0m\n",
      "49 0\n",
      "Loss =  1225971.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.97484375\u001b[0m\n",
      "49 100\n",
      "Loss =  1230601.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.95953125\u001b[0m\n",
      "49 200\n",
      "Loss =  1230323.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.956171875\u001b[0m\n",
      "49 300\n",
      "Loss =  1223389.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.98984375\u001b[0m\n",
      "49 400\n",
      "Loss =  1238874.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.935390625\u001b[0m\n",
      "50 0\n",
      "Loss =  1230799.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.948359375\u001b[0m\n",
      "50 100\n",
      "Loss =  1233989.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.95140625\u001b[0m\n",
      "50 200\n",
      "Loss =  1233781.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.933046875\u001b[0m\n",
      "50 300\n",
      "Loss =  1225621.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9615625\u001b[0m\n",
      "50 400\n",
      "Loss =  1226769.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9690625\u001b[0m\n",
      "51 0\n",
      "Loss =  1225646.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96921875\u001b[0m\n",
      "51 100\n",
      "Loss =  1228927.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.9528125\u001b[0m\n",
      "51 200\n",
      "Loss =  1228328.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96375\u001b[0m\n",
      "51 300\n",
      "Loss =  1226011.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.975390625\u001b[0m\n",
      "51 400\n",
      "Loss =  1226616.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96921875\u001b[0m\n",
      "52 0\n",
      "Loss =  1233750.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.949375\u001b[0m\n",
      "52 100\n",
      "Loss =  1224919.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.981796875\u001b[0m\n",
      "52 200\n",
      "Loss =  1225019.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.983125\u001b[0m\n",
      "52 300\n",
      "Loss =  1231521.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.945703125\u001b[0m\n",
      "52 400\n",
      "Loss =  1229851.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.93015625\u001b[0m\n",
      "53 0\n",
      "Loss =  1230080.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.94265625\u001b[0m\n",
      "53 100\n",
      "Loss =  1223483.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.966796875\u001b[0m\n",
      "53 200\n",
      "Loss =  1225500.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.975\u001b[0m\n",
      "53 300\n",
      "Loss =  1225224.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.956484375\u001b[0m\n",
      "53 400\n",
      "Loss =  1223900.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.9559375\u001b[0m\n",
      "54 0\n",
      "Loss =  1223255.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.974765625\u001b[0m\n",
      "54 100\n",
      "Loss =  1224886.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.95625\u001b[0m\n",
      "54 200\n",
      "Loss =  1228350.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.961875\u001b[0m\n",
      "54 300\n",
      "Loss =  1221934.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.965546875\u001b[0m\n",
      "54 400\n",
      "Loss =  1221325.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.971015625\u001b[0m\n",
      "55 0\n",
      "Loss =  1223686.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.968359375\u001b[0m\n",
      "55 100\n",
      "Loss =  1225034.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.965859375\u001b[0m\n",
      "55 200\n",
      "Loss =  1226717.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.943515625\u001b[0m\n",
      "55 300\n",
      "Loss =  1230182.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.957109375\u001b[0m\n",
      "55 400\n",
      "Loss =  1222999.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.966328125\u001b[0m\n",
      "56 0\n",
      "Loss =  1230808.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.949921875\u001b[0m\n",
      "56 100\n",
      "Loss =  1225847.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.95984375\u001b[0m\n",
      "56 200\n",
      "Loss =  1221664.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.966640625\u001b[0m\n",
      "56 300\n",
      "Loss =  1229423.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.94953125\u001b[0m\n",
      "56 400\n",
      "Loss =  1224046.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.96703125\u001b[0m\n",
      "57 0\n",
      "Loss =  1227124.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.943125\u001b[0m\n",
      "57 100\n",
      "Loss =  1228474.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.9528125\u001b[0m\n",
      "57 200\n",
      "Loss =  1226308.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.941015625\u001b[0m\n",
      "57 300\n",
      "Loss =  1223011.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.970546875\u001b[0m\n",
      "57 400\n",
      "Loss =  1224145.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.97\u001b[0m\n",
      "58 0\n",
      "Loss =  1223570.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.962578125\u001b[0m\n",
      "58 100\n",
      "Loss =  1222397.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.96765625\u001b[0m\n",
      "58 200\n",
      "Loss =  1225147.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.961328125\u001b[0m\n",
      "58 300\n",
      "Loss =  1226842.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.959453125\u001b[0m\n",
      "58 400\n",
      "Loss =  1228221.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.959453125\u001b[0m\n",
      "59 0\n",
      "Loss =  1225717.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.964375\u001b[0m\n",
      "59 100\n",
      "Loss =  1226276.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.956875\u001b[0m\n",
      "59 200\n",
      "Loss =  1223153.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.97046875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 300\n",
      "Loss =  1223099.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.965390625\u001b[0m\n",
      "59 400\n",
      "Loss =  1225003.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.96171875\u001b[0m\n",
      "60 0\n",
      "Loss =  1220467.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.98359375\u001b[0m\n",
      "60 100\n",
      "Loss =  1221741.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.974296875\u001b[0m\n",
      "60 200\n",
      "Loss =  1223072.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.971015625\u001b[0m\n",
      "60 300\n",
      "Loss =  1225051.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.9625\u001b[0m\n",
      "60 400\n",
      "Loss =  1219819.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.97125\u001b[0m\n",
      "61 0\n",
      "Loss =  1223060.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.942734375\u001b[0m\n",
      "61 100\n",
      "Loss =  1226503.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.955\u001b[0m\n",
      "61 200\n",
      "Loss =  1228575.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.956171875\u001b[0m\n",
      "61 300\n",
      "Loss =  1223601.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.94953125\u001b[0m\n",
      "61 400\n",
      "Loss =  1221834.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.96546875\u001b[0m\n",
      "62 0\n",
      "Loss =  1223143.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.965078125\u001b[0m\n",
      "62 100\n",
      "Loss =  1222554.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.955703125\u001b[0m\n",
      "62 200\n",
      "Loss =  1223437.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.968046875\u001b[0m\n",
      "62 300\n",
      "Loss =  1220790.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.9634375\u001b[0m\n",
      "62 400\n",
      "Loss =  1229253.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.95640625\u001b[0m\n",
      "63 0\n",
      "Loss =  1225567.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.960234375\u001b[0m\n",
      "63 100\n",
      "Loss =  1221412.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.966015625\u001b[0m\n",
      "63 200\n",
      "Loss =  1232993.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.965\u001b[0m\n",
      "63 300\n",
      "Loss =  1218727.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.989375\u001b[0m\n",
      "63 400\n",
      "Loss =  1223549.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.963515625\u001b[0m\n",
      "64 0\n",
      "Loss =  1224502.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9603125\u001b[0m\n",
      "64 100\n",
      "Loss =  1227824.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.936875\u001b[0m\n",
      "64 200\n",
      "Loss =  1222185.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9615625\u001b[0m\n",
      "64 300\n",
      "Loss =  1224207.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.97046875\u001b[0m\n",
      "64 400\n",
      "Loss =  1220854.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.97296875\u001b[0m\n",
      "65 0\n",
      "Loss =  1223416.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.95390625\u001b[0m\n",
      "65 100\n",
      "Loss =  1219425.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.98078125\u001b[0m\n",
      "65 200\n",
      "Loss =  1218822.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.98171875\u001b[0m\n",
      "65 300\n",
      "Loss =  1222352.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.97359375\u001b[0m\n",
      "65 400\n",
      "Loss =  1222505.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.947890625\u001b[0m\n",
      "66 0\n",
      "Loss =  1222180.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.95859375\u001b[0m\n",
      "66 100\n",
      "Loss =  1219525.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9665625\u001b[0m\n",
      "66 200\n",
      "Loss =  1221442.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.961953125\u001b[0m\n",
      "66 300\n",
      "Loss =  1219317.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9715625\u001b[0m\n",
      "66 400\n",
      "Loss =  1219522.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.97625\u001b[0m\n",
      "67 0\n",
      "Loss =  1225768.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.94109375\u001b[0m\n",
      "67 100\n",
      "Loss =  1221403.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.976171875\u001b[0m\n",
      "67 200\n",
      "Loss =  1228654.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.939140625\u001b[0m\n",
      "67 300\n",
      "Loss =  1221087.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.974140625\u001b[0m\n",
      "67 400\n",
      "Loss =  1221576.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.96390625\u001b[0m\n",
      "68 0\n",
      "Loss =  1228151.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.957265625\u001b[0m\n",
      "68 100\n",
      "Loss =  1229376.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.945625\u001b[0m\n",
      "68 200\n",
      "Loss =  1220274.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9728125\u001b[0m\n",
      "68 300\n",
      "Loss =  1227936.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.94015625\u001b[0m\n",
      "68 400\n",
      "Loss =  1223816.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.964921875\u001b[0m\n",
      "69 0\n",
      "Loss =  1221080.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.97078125\u001b[0m\n",
      "69 100\n",
      "Loss =  1229455.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.944609375\u001b[0m\n",
      "69 200\n",
      "Loss =  1216502.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.977734375\u001b[0m\n",
      "69 300\n",
      "Loss =  1219731.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.96328125\u001b[0m\n",
      "69 400\n",
      "Loss =  1221894.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.95703125\u001b[0m\n",
      "70 0\n",
      "Loss =  1221067.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.9659375\u001b[0m\n",
      "70 100\n",
      "Loss =  1223957.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.96203125\u001b[0m\n",
      "70 200\n",
      "Loss =  1219385.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.9646875\u001b[0m\n",
      "70 300\n",
      "Loss =  1217497.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.970703125\u001b[0m\n",
      "70 400\n",
      "Loss =  1220779.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.976953125\u001b[0m\n",
      "71 0\n",
      "Loss =  1221587.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.963515625\u001b[0m\n",
      "71 100\n",
      "Loss =  1222490.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.970078125\u001b[0m\n",
      "71 200\n",
      "Loss =  1222270.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.978125\u001b[0m\n",
      "71 300\n",
      "Loss =  1223106.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.957890625\u001b[0m\n",
      "71 400\n",
      "Loss =  1218154.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.971953125\u001b[0m\n",
      "72 0\n",
      "Loss =  1220105.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.965234375\u001b[0m\n",
      "72 100\n",
      "Loss =  1221828.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.9528125\u001b[0m\n",
      "72 200\n",
      "Loss =  1221781.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.95640625\u001b[0m\n",
      "72 300\n",
      "Loss =  1222959.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.970859375\u001b[0m\n",
      "72 400\n",
      "Loss =  1220063.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.9625\u001b[0m\n",
      "73 0\n",
      "Loss =  1231110.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.9321875\u001b[0m\n",
      "73 100\n",
      "Loss =  1218265.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.971171875\u001b[0m\n",
      "73 200\n",
      "Loss =  1222920.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.960078125\u001b[0m\n",
      "73 300\n",
      "Loss =  1221172.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.939453125\u001b[0m\n",
      "73 400\n",
      "Loss =  1219536.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.957890625\u001b[0m\n",
      "74 0\n",
      "Loss =  1221825.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.959296875\u001b[0m\n",
      "74 100\n",
      "Loss =  1224139.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.93171875\u001b[0m\n",
      "74 200\n",
      "Loss =  1220418.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.966875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 300\n",
      "Loss =  1220447.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.969765625\u001b[0m\n",
      "74 400\n",
      "Loss =  1220086.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.983828125\u001b[0m\n",
      "75 0\n",
      "Loss =  1222549.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.962734375\u001b[0m\n",
      "75 100\n",
      "Loss =  1219724.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.963046875\u001b[0m\n",
      "75 200\n",
      "Loss =  1221202.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.959765625\u001b[0m\n",
      "75 300\n",
      "Loss =  1220367.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.968671875\u001b[0m\n",
      "75 400\n",
      "Loss =  1221105.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.958046875\u001b[0m\n",
      "76 0\n",
      "Loss =  1218872.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.971171875\u001b[0m\n",
      "76 100\n",
      "Loss =  1221608.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.966953125\u001b[0m\n",
      "76 200\n",
      "Loss =  1220692.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.954453125\u001b[0m\n",
      "76 300\n",
      "Loss =  1230845.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.937109375\u001b[0m\n",
      "76 400\n",
      "Loss =  1225289.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.94828125\u001b[0m\n",
      "77 0\n",
      "Loss =  1217506.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.967734375\u001b[0m\n",
      "77 100\n",
      "Loss =  1224057.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.951015625\u001b[0m\n",
      "77 200\n",
      "Loss =  1221168.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9696875\u001b[0m\n",
      "77 300\n",
      "Loss =  1221120.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.956328125\u001b[0m\n",
      "77 400\n",
      "Loss =  1222010.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.969765625\u001b[0m\n",
      "78 0\n",
      "Loss =  1218255.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.97234375\u001b[0m\n",
      "78 100\n",
      "Loss =  1219123.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.963515625\u001b[0m\n",
      "78 200\n",
      "Loss =  1221098.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.957890625\u001b[0m\n",
      "78 300\n",
      "Loss =  1219350.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.964375\u001b[0m\n",
      "78 400\n",
      "Loss =  1224106.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.95140625\u001b[0m\n",
      "79 0\n",
      "Loss =  1221377.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.96671875\u001b[0m\n",
      "79 100\n",
      "Loss =  1226052.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.96109375\u001b[0m\n",
      "79 200\n",
      "Loss =  1219704.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9721875\u001b[0m\n",
      "79 300\n",
      "Loss =  1225842.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.95078125\u001b[0m\n",
      "79 400\n",
      "Loss =  1226138.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.954609375\u001b[0m\n",
      "80 0\n",
      "Loss =  1218710.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.970859375\u001b[0m\n",
      "80 100\n",
      "Loss =  1220427.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.966171875\u001b[0m\n",
      "80 200\n",
      "Loss =  1217268.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.96046875\u001b[0m\n",
      "80 300\n",
      "Loss =  1218705.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.9740625\u001b[0m\n",
      "80 400\n",
      "Loss =  1218595.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.967109375\u001b[0m\n",
      "81 0\n",
      "Loss =  1218791.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.9734375\u001b[0m\n",
      "81 100\n",
      "Loss =  1220991.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.964375\u001b[0m\n",
      "81 200\n",
      "Loss =  1217935.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.976953125\u001b[0m\n",
      "81 300\n",
      "Loss =  1220339.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.95890625\u001b[0m\n",
      "81 400\n",
      "Loss =  1217507.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.969609375\u001b[0m\n",
      "82 0\n",
      "Loss =  1218997.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.954375\u001b[0m\n",
      "82 100\n",
      "Loss =  1218186.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.964140625\u001b[0m\n",
      "82 200\n",
      "Loss =  1222368.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.962109375\u001b[0m\n",
      "82 300\n",
      "Loss =  1216590.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.975546875\u001b[0m\n",
      "82 400\n",
      "Loss =  1220409.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.96140625\u001b[0m\n",
      "83 0\n",
      "Loss =  1219944.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.95625\u001b[0m\n",
      "83 100\n",
      "Loss =  1218381.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.962578125\u001b[0m\n",
      "83 200\n",
      "Loss =  1219872.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.9546875\u001b[0m\n",
      "83 300\n",
      "Loss =  1220951.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.96234375\u001b[0m\n",
      "83 400\n",
      "Loss =  1216633.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.971484375\u001b[0m\n",
      "84 0\n",
      "Loss =  1219362.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.958515625\u001b[0m\n",
      "84 100\n",
      "Loss =  1218678.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.967265625\u001b[0m\n",
      "84 200\n",
      "Loss =  1218747.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.9759375\u001b[0m\n",
      "84 300\n",
      "Loss =  1220550.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.945703125\u001b[0m\n",
      "84 400\n",
      "Loss =  1219274.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.956171875\u001b[0m\n",
      "85 0\n",
      "Loss =  1217013.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.973046875\u001b[0m\n",
      "85 100\n",
      "Loss =  1215986.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.973359375\u001b[0m\n",
      "85 200\n",
      "Loss =  1218111.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9640625\u001b[0m\n",
      "85 300\n",
      "Loss =  1215356.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.972265625\u001b[0m\n",
      "85 400\n",
      "Loss =  1221205.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.960390625\u001b[0m\n",
      "86 0\n",
      "Loss =  1228898.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.951953125\u001b[0m\n",
      "86 100\n",
      "Loss =  1219035.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.95140625\u001b[0m\n",
      "86 200\n",
      "Loss =  1217210.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.950703125\u001b[0m\n",
      "86 300\n",
      "Loss =  1216402.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.97515625\u001b[0m\n",
      "86 400\n",
      "Loss =  1218440.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.97296875\u001b[0m\n",
      "87 0\n",
      "Loss =  1218864.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.96703125\u001b[0m\n",
      "87 100\n",
      "Loss =  1220977.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.969765625\u001b[0m\n",
      "87 200\n",
      "Loss =  1221244.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.9653125\u001b[0m\n",
      "87 300\n",
      "Loss =  1216108.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.963359375\u001b[0m\n",
      "87 400\n",
      "Loss =  1218474.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.957578125\u001b[0m\n",
      "88 0\n",
      "Loss =  1223418.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.9459375\u001b[0m\n",
      "88 100\n",
      "Loss =  1218845.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.973203125\u001b[0m\n",
      "88 200\n",
      "Loss =  1219375.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.950390625\u001b[0m\n",
      "88 300\n",
      "Loss =  1216772.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.96875\u001b[0m\n",
      "88 400\n",
      "Loss =  1220733.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.964453125\u001b[0m\n",
      "89 0\n",
      "Loss =  1215160.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.980234375\u001b[0m\n",
      "89 100\n",
      "Loss =  1221367.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.96875\u001b[0m\n",
      "89 200\n",
      "Loss =  1221499.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.966171875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 300\n",
      "Loss =  1217743.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.98015625\u001b[0m\n",
      "89 400\n",
      "Loss =  1216419.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.964453125\u001b[0m\n",
      "90 0\n",
      "Loss =  1221129.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.964140625\u001b[0m\n",
      "90 100\n",
      "Loss =  1223906.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.941640625\u001b[0m\n",
      "90 200\n",
      "Loss =  1218365.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.959296875\u001b[0m\n",
      "90 300\n",
      "Loss =  1221234.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.940546875\u001b[0m\n",
      "90 400\n",
      "Loss =  1221185.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.95875\u001b[0m\n",
      "91 0\n",
      "Loss =  1220444.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.95625\u001b[0m\n",
      "91 100\n",
      "Loss =  1215212.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.975625\u001b[0m\n",
      "91 200\n",
      "Loss =  1215982.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.968671875\u001b[0m\n",
      "91 300\n",
      "Loss =  1221720.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.9578125\u001b[0m\n",
      "91 400\n",
      "Loss =  1219229.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.948671875\u001b[0m\n",
      "92 0\n",
      "Loss =  1218051.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.967421875\u001b[0m\n",
      "92 100\n",
      "Loss =  1218922.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.96203125\u001b[0m\n",
      "92 200\n",
      "Loss =  1218614.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.971171875\u001b[0m\n",
      "92 300\n",
      "Loss =  1220448.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.9359375\u001b[0m\n",
      "92 400\n",
      "Loss =  1217668.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.96828125\u001b[0m\n",
      "93 0\n",
      "Loss =  1216634.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.965859375\u001b[0m\n",
      "93 100\n",
      "Loss =  1216764.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.964140625\u001b[0m\n",
      "93 200\n",
      "Loss =  1219802.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.959921875\u001b[0m\n",
      "93 300\n",
      "Loss =  1220893.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.974765625\u001b[0m\n",
      "93 400\n",
      "Loss =  1218760.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.966484375\u001b[0m\n",
      "94 0\n",
      "Loss =  1214483.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.97640625\u001b[0m\n",
      "94 100\n",
      "Loss =  1218804.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.969375\u001b[0m\n",
      "94 200\n",
      "Loss =  1221706.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.95625\u001b[0m\n",
      "94 300\n",
      "Loss =  1214598.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.98421875\u001b[0m\n",
      "94 400\n",
      "Loss =  1218522.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.955546875\u001b[0m\n",
      "95 0\n",
      "Loss =  1216196.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.981484375\u001b[0m\n",
      "95 100\n",
      "Loss =  1215472.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.978203125\u001b[0m\n",
      "95 200\n",
      "Loss =  1224135.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.95375\u001b[0m\n",
      "95 300\n",
      "Loss =  1221604.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.966484375\u001b[0m\n",
      "95 400\n",
      "Loss =  1220184.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9678125\u001b[0m\n",
      "96 0\n",
      "Loss =  1218357.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.976015625\u001b[0m\n",
      "96 100\n",
      "Loss =  1217722.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.97390625\u001b[0m\n",
      "96 200\n",
      "Loss =  1213799.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.966015625\u001b[0m\n",
      "96 300\n",
      "Loss =  1217301.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.9671875\u001b[0m\n",
      "96 400\n",
      "Loss =  1215425.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.978125\u001b[0m\n",
      "97 0\n",
      "Loss =  1217564.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.960703125\u001b[0m\n",
      "97 100\n",
      "Loss =  1218499.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.96390625\u001b[0m\n",
      "97 200\n",
      "Loss =  1217675.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.96375\u001b[0m\n",
      "97 300\n",
      "Loss =  1222793.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.954765625\u001b[0m\n",
      "97 400\n",
      "Loss =  1221838.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.963046875\u001b[0m\n",
      "98 0\n",
      "Loss =  1219526.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.962578125\u001b[0m\n",
      "98 100\n",
      "Loss =  1213658.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.983046875\u001b[0m\n",
      "98 200\n",
      "Loss =  1214461.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.96765625\u001b[0m\n",
      "98 300\n",
      "Loss =  1214407.125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.968046875\u001b[0m\n",
      "98 400\n",
      "Loss =  1220366.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.959140625\u001b[0m\n",
      "99 0\n",
      "Loss =  1216342.875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.97\u001b[0m\n",
      "99 100\n",
      "Loss =  1215111.625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.9796875\u001b[0m\n",
      "99 200\n",
      "Loss =  1215973.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.97203125\u001b[0m\n",
      "99 300\n",
      "Loss =  1219008.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.962578125\u001b[0m\n",
      "99 400\n",
      "Loss =  1216834.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.975546875\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.9638)\n"
     ]
    }
   ],
   "source": [
    "eps_scale = 1\n",
    "for lr in [1e-3]:\n",
    "    for l in [1200]:\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        model3 = BNN(train_loader, [784, l, l, 10], act = nn.ReLU(), n_epochs = 100)\n",
    "        model3.train(lr = lr, decay = 1)\n",
    "        #models.append(model)\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "    \n",
    "        for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "            A = example_data/126\n",
    "            b = example_targets\n",
    "        z = model3.BNet(A).detach()\n",
    "        T_pred = torch.argmax(z, dim = 1)\n",
    "        print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965c932",
   "metadata": {},
   "source": [
    "### Vanila NN SGD - Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a794c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  142145.546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.140625\u001b[0m\n",
      "0 100\n",
      "Loss =  36042.83984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8359375\u001b[0m\n",
      "0 200\n",
      "Loss =  29460.9921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8984375\u001b[0m\n",
      "0 300\n",
      "Loss =  19961.017578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.921875\u001b[0m\n",
      "0 400\n",
      "Loss =  15868.3310546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.9375\u001b[0m\n",
      "1 0\n",
      "Loss =  17136.10546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.921875\u001b[0m\n",
      "1 100\n",
      "Loss =  13690.3837890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.96875\u001b[0m\n",
      "1 200\n",
      "Loss =  23475.15234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.90625\u001b[0m\n",
      "1 300\n",
      "Loss =  22389.474609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.9140625\u001b[0m\n",
      "1 400\n",
      "Loss =  17722.5234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.921875\u001b[0m\n",
      "2 0\n",
      "Loss =  26850.240234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.875\u001b[0m\n",
      "2 100\n",
      "Loss =  20184.193359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.921875\u001b[0m\n",
      "2 200\n",
      "Loss =  25869.16015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.875\u001b[0m\n",
      "2 300\n",
      "Loss =  33892.69921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.8515625\u001b[0m\n",
      "2 400\n",
      "Loss =  16379.3671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 2 is 0.9453125\u001b[0m\n",
      "3 0\n",
      "Loss =  17235.509765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.9296875\u001b[0m\n",
      "3 100\n",
      "Loss =  21682.701171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.921875\u001b[0m\n",
      "3 200\n",
      "Loss =  19817.90234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.921875\u001b[0m\n",
      "3 300\n",
      "Loss =  19891.4375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.9140625\u001b[0m\n",
      "3 400\n",
      "Loss =  16087.0634765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 3 is 0.9140625\u001b[0m\n",
      "4 0\n",
      "Loss =  17266.353515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.921875\u001b[0m\n",
      "4 100\n",
      "Loss =  19916.341796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.9453125\u001b[0m\n",
      "4 200\n",
      "Loss =  11303.654296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.953125\u001b[0m\n",
      "4 300\n",
      "Loss =  27508.3671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.90625\u001b[0m\n",
      "4 400\n",
      "Loss =  12314.1357421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 4 is 0.953125\u001b[0m\n",
      "5 0\n",
      "Loss =  21172.8671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.9296875\u001b[0m\n",
      "5 100\n",
      "Loss =  31868.68359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.890625\u001b[0m\n",
      "5 200\n",
      "Loss =  22786.8515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.8828125\u001b[0m\n",
      "5 300\n",
      "Loss =  19988.19921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.921875\u001b[0m\n",
      "5 400\n",
      "Loss =  18406.15625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 5 is 0.9453125\u001b[0m\n",
      "6 0\n",
      "Loss =  27398.888671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.890625\u001b[0m\n",
      "6 100\n",
      "Loss =  17877.927734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.90625\u001b[0m\n",
      "6 200\n",
      "Loss =  19850.7890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.90625\u001b[0m\n",
      "6 300\n",
      "Loss =  16993.859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.9140625\u001b[0m\n",
      "6 400\n",
      "Loss =  37898.06640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 6 is 0.8515625\u001b[0m\n",
      "7 0\n",
      "Loss =  13905.271484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.9453125\u001b[0m\n",
      "7 100\n",
      "Loss =  26686.001953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.921875\u001b[0m\n",
      "7 200\n",
      "Loss =  19925.607421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.921875\u001b[0m\n",
      "7 300\n",
      "Loss =  17597.671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.921875\u001b[0m\n",
      "7 400\n",
      "Loss =  15711.546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 7 is 0.9296875\u001b[0m\n",
      "8 0\n",
      "Loss =  20910.525390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.890625\u001b[0m\n",
      "8 100\n",
      "Loss =  17181.130859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.9375\u001b[0m\n",
      "8 200\n",
      "Loss =  20203.701171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.890625\u001b[0m\n",
      "8 300\n",
      "Loss =  18203.720703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.9296875\u001b[0m\n",
      "8 400\n",
      "Loss =  25554.529296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 8 is 0.890625\u001b[0m\n",
      "9 0\n",
      "Loss =  16819.966796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.9375\u001b[0m\n",
      "9 100\n",
      "Loss =  13992.0654296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.9375\u001b[0m\n",
      "9 200\n",
      "Loss =  26663.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.890625\u001b[0m\n",
      "9 300\n",
      "Loss =  17959.328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.9296875\u001b[0m\n",
      "9 400\n",
      "Loss =  20026.2265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 9 is 0.875\u001b[0m\n",
      "10 0\n",
      "Loss =  21534.98828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.8828125\u001b[0m\n",
      "10 100\n",
      "Loss =  14558.78515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.9140625\u001b[0m\n",
      "10 200\n",
      "Loss =  21456.14453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.9140625\u001b[0m\n",
      "10 300\n",
      "Loss =  20541.587890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.90625\u001b[0m\n",
      "10 400\n",
      "Loss =  18735.46875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 10 is 0.90625\u001b[0m\n",
      "11 0\n",
      "Loss =  20435.85546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.9296875\u001b[0m\n",
      "11 100\n",
      "Loss =  16427.3359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.921875\u001b[0m\n",
      "11 200\n",
      "Loss =  10546.5927734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.9453125\u001b[0m\n",
      "11 300\n",
      "Loss =  9287.69140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.953125\u001b[0m\n",
      "11 400\n",
      "Loss =  15985.9619140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 11 is 0.9375\u001b[0m\n",
      "12 0\n",
      "Loss =  13708.982421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.953125\u001b[0m\n",
      "12 100\n",
      "Loss =  17632.5625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9140625\u001b[0m\n",
      "12 200\n",
      "Loss =  17186.27734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9375\u001b[0m\n",
      "12 300\n",
      "Loss =  14252.291015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9296875\u001b[0m\n",
      "12 400\n",
      "Loss =  18784.587890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 12 is 0.9296875\u001b[0m\n",
      "13 0\n",
      "Loss =  27611.5546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.8828125\u001b[0m\n",
      "13 100\n",
      "Loss =  14623.14453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.9453125\u001b[0m\n",
      "13 200\n",
      "Loss =  20258.369140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.9296875\u001b[0m\n",
      "13 300\n",
      "Loss =  22432.77734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.8984375\u001b[0m\n",
      "13 400\n",
      "Loss =  17368.7578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 13 is 0.9296875\u001b[0m\n",
      "14 0\n",
      "Loss =  22566.58203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9296875\u001b[0m\n",
      "14 100\n",
      "Loss =  18566.869140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 200\n",
      "Loss =  12734.31640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.9375\u001b[0m\n",
      "14 300\n",
      "Loss =  27663.771484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.90625\u001b[0m\n",
      "14 400\n",
      "Loss =  19151.3515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 14 is 0.8984375\u001b[0m\n",
      "15 0\n",
      "Loss =  19416.1796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.9140625\u001b[0m\n",
      "15 100\n",
      "Loss =  18323.306640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.9140625\u001b[0m\n",
      "15 200\n",
      "Loss =  15649.755859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.9296875\u001b[0m\n",
      "15 300\n",
      "Loss =  20058.01953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.921875\u001b[0m\n",
      "15 400\n",
      "Loss =  12637.228515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 15 is 0.953125\u001b[0m\n",
      "16 0\n",
      "Loss =  13411.9716796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.9375\u001b[0m\n",
      "16 100\n",
      "Loss =  16084.16015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.9296875\u001b[0m\n",
      "16 200\n",
      "Loss =  31557.32421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.8515625\u001b[0m\n",
      "16 300\n",
      "Loss =  21763.90625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.90625\u001b[0m\n",
      "16 400\n",
      "Loss =  20772.8203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 16 is 0.9296875\u001b[0m\n",
      "17 0\n",
      "Loss =  18493.408203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.90625\u001b[0m\n",
      "17 100\n",
      "Loss =  18020.0859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.890625\u001b[0m\n",
      "17 200\n",
      "Loss =  21909.30859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.9140625\u001b[0m\n",
      "17 300\n",
      "Loss =  13531.1640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.953125\u001b[0m\n",
      "17 400\n",
      "Loss =  24170.22265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 17 is 0.8828125\u001b[0m\n",
      "18 0\n",
      "Loss =  18291.38671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9296875\u001b[0m\n",
      "18 100\n",
      "Loss =  20373.595703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9375\u001b[0m\n",
      "18 200\n",
      "Loss =  7442.0849609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.984375\u001b[0m\n",
      "18 300\n",
      "Loss =  11122.5693359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.96875\u001b[0m\n",
      "18 400\n",
      "Loss =  11060.3232421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 18 is 0.9375\u001b[0m\n",
      "19 0\n",
      "Loss =  24989.357421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.8828125\u001b[0m\n",
      "19 100\n",
      "Loss =  15876.607421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.921875\u001b[0m\n",
      "19 200\n",
      "Loss =  14044.2802734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.953125\u001b[0m\n",
      "19 300\n",
      "Loss =  12604.158203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.9453125\u001b[0m\n",
      "19 400\n",
      "Loss =  13884.072265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 19 is 0.9453125\u001b[0m\n",
      "20 0\n",
      "Loss =  15928.251953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.921875\u001b[0m\n",
      "20 100\n",
      "Loss =  17653.259765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.9375\u001b[0m\n",
      "20 200\n",
      "Loss =  17261.599609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.9453125\u001b[0m\n",
      "20 300\n",
      "Loss =  18223.02734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.9453125\u001b[0m\n",
      "20 400\n",
      "Loss =  10215.0361328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 20 is 0.953125\u001b[0m\n",
      "21 0\n",
      "Loss =  17339.185546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.921875\u001b[0m\n",
      "21 100\n",
      "Loss =  13462.583984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.9375\u001b[0m\n",
      "21 200\n",
      "Loss =  9873.623046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.9765625\u001b[0m\n",
      "21 300\n",
      "Loss =  13740.85546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.921875\u001b[0m\n",
      "21 400\n",
      "Loss =  12678.833984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 21 is 0.9375\u001b[0m\n",
      "22 0\n",
      "Loss =  9333.0458984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9765625\u001b[0m\n",
      "22 100\n",
      "Loss =  10044.9970703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9765625\u001b[0m\n",
      "22 200\n",
      "Loss =  15246.5087890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9609375\u001b[0m\n",
      "22 300\n",
      "Loss =  16545.82421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9375\u001b[0m\n",
      "22 400\n",
      "Loss =  15029.4208984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 22 is 0.9453125\u001b[0m\n",
      "23 0\n",
      "Loss =  15308.853515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.90625\u001b[0m\n",
      "23 100\n",
      "Loss =  15227.7265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9375\u001b[0m\n",
      "23 200\n",
      "Loss =  17375.494140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.90625\u001b[0m\n",
      "23 300\n",
      "Loss =  12808.8984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.96875\u001b[0m\n",
      "23 400\n",
      "Loss =  11571.1416015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 23 is 0.9609375\u001b[0m\n",
      "24 0\n",
      "Loss =  16961.55078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.953125\u001b[0m\n",
      "24 100\n",
      "Loss =  28925.1015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9140625\u001b[0m\n",
      "24 200\n",
      "Loss =  14604.1884765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.921875\u001b[0m\n",
      "24 300\n",
      "Loss =  15064.91796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9296875\u001b[0m\n",
      "24 400\n",
      "Loss =  11956.51953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 24 is 0.9609375\u001b[0m\n",
      "25 0\n",
      "Loss =  13828.7978515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.96875\u001b[0m\n",
      "25 100\n",
      "Loss =  22426.912109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.921875\u001b[0m\n",
      "25 200\n",
      "Loss =  13031.9765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.9609375\u001b[0m\n",
      "25 300\n",
      "Loss =  14149.08984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.921875\u001b[0m\n",
      "25 400\n",
      "Loss =  13808.671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 25 is 0.9140625\u001b[0m\n",
      "26 0\n",
      "Loss =  12775.6533203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.9375\u001b[0m\n",
      "26 100\n",
      "Loss =  13876.7470703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.9375\u001b[0m\n",
      "26 200\n",
      "Loss =  8167.33935546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.9765625\u001b[0m\n",
      "26 300\n",
      "Loss =  13793.970703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.921875\u001b[0m\n",
      "26 400\n",
      "Loss =  17135.880859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 26 is 0.9140625\u001b[0m\n",
      "27 0\n",
      "Loss =  18652.861328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.953125\u001b[0m\n",
      "27 100\n",
      "Loss =  20429.765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.9296875\u001b[0m\n",
      "27 200\n",
      "Loss =  16064.986328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.9375\u001b[0m\n",
      "27 300\n",
      "Loss =  13599.6728515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.9609375\u001b[0m\n",
      "27 400\n",
      "Loss =  17791.34375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 27 is 0.96875\u001b[0m\n",
      "28 0\n",
      "Loss =  10476.1015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.953125\u001b[0m\n",
      "28 100\n",
      "Loss =  12828.376953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.9375\u001b[0m\n",
      "28 200\n",
      "Loss =  16557.015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.9296875\u001b[0m\n",
      "28 300\n",
      "Loss =  12266.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.9375\u001b[0m\n",
      "28 400\n",
      "Loss =  12123.6884765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 28 is 0.953125\u001b[0m\n",
      "29 0\n",
      "Loss =  16899.314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9296875\u001b[0m\n",
      "29 100\n",
      "Loss =  17376.0546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9375\u001b[0m\n",
      "29 200\n",
      "Loss =  15642.9375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9375\u001b[0m\n",
      "29 300\n",
      "Loss =  13937.783203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9609375\u001b[0m\n",
      "29 400\n",
      "Loss =  14467.4658203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 29 is 0.9375\u001b[0m\n",
      "30 0\n",
      "Loss =  12625.810546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9609375\u001b[0m\n",
      "30 100\n",
      "Loss =  12184.3740234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.96875\u001b[0m\n",
      "30 200\n",
      "Loss =  8137.34375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9765625\u001b[0m\n",
      "30 300\n",
      "Loss =  17898.48046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9140625\u001b[0m\n",
      "30 400\n",
      "Loss =  14872.416015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 30 is 0.9140625\u001b[0m\n",
      "31 0\n",
      "Loss =  19715.728515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.921875\u001b[0m\n",
      "31 100\n",
      "Loss =  10853.224609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.9765625\u001b[0m\n",
      "31 200\n",
      "Loss =  19154.70703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.9296875\u001b[0m\n",
      "31 300\n",
      "Loss =  10154.236328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.953125\u001b[0m\n",
      "31 400\n",
      "Loss =  12560.716796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 31 is 0.9453125\u001b[0m\n",
      "32 0\n",
      "Loss =  15135.390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9140625\u001b[0m\n",
      "32 100\n",
      "Loss =  13598.3798828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9453125\u001b[0m\n",
      "32 200\n",
      "Loss =  16640.9375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9296875\u001b[0m\n",
      "32 300\n",
      "Loss =  13186.234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9296875\u001b[0m\n",
      "32 400\n",
      "Loss =  9230.6953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 32 is 0.9609375\u001b[0m\n",
      "33 0\n",
      "Loss =  13294.9990234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9296875\u001b[0m\n",
      "33 100\n",
      "Loss =  16912.134765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.921875\u001b[0m\n",
      "33 200\n",
      "Loss =  17862.412109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9375\u001b[0m\n",
      "33 300\n",
      "Loss =  12077.5947265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9609375\u001b[0m\n",
      "33 400\n",
      "Loss =  12171.6748046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 33 is 0.9609375\u001b[0m\n",
      "34 0\n",
      "Loss =  8364.1953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.96875\u001b[0m\n",
      "34 100\n",
      "Loss =  11564.833984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.9453125\u001b[0m\n",
      "34 200\n",
      "Loss =  14723.529296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.953125\u001b[0m\n",
      "34 300\n",
      "Loss =  9579.232421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.953125\u001b[0m\n",
      "34 400\n",
      "Loss =  12872.9140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 34 is 0.9609375\u001b[0m\n",
      "35 0\n",
      "Loss =  16082.0126953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9375\u001b[0m\n",
      "35 100\n",
      "Loss =  15663.349609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9453125\u001b[0m\n",
      "35 200\n",
      "Loss =  14915.01953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9609375\u001b[0m\n",
      "35 300\n",
      "Loss =  15168.1982421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.9296875\u001b[0m\n",
      "35 400\n",
      "Loss =  13740.9736328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 35 is 0.953125\u001b[0m\n",
      "36 0\n",
      "Loss =  10641.9453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.953125\u001b[0m\n",
      "36 100\n",
      "Loss =  11525.533203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.9375\u001b[0m\n",
      "36 200\n",
      "Loss =  10296.0458984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.96875\u001b[0m\n",
      "36 300\n",
      "Loss =  7969.236328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.984375\u001b[0m\n",
      "36 400\n",
      "Loss =  8232.2548828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 36 is 0.96875\u001b[0m\n",
      "37 0\n",
      "Loss =  13491.3046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.953125\u001b[0m\n",
      "37 100\n",
      "Loss =  10818.708984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.9453125\u001b[0m\n",
      "37 200\n",
      "Loss =  12395.009765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.96875\u001b[0m\n",
      "37 300\n",
      "Loss =  9176.4912109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.96875\u001b[0m\n",
      "37 400\n",
      "Loss =  18638.4140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 37 is 0.9453125\u001b[0m\n",
      "38 0\n",
      "Loss =  10456.7255859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.9765625\u001b[0m\n",
      "38 100\n",
      "Loss =  11418.458984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.9609375\u001b[0m\n",
      "38 200\n",
      "Loss =  10440.8623046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.9765625\u001b[0m\n",
      "38 300\n",
      "Loss =  12029.537109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.9609375\u001b[0m\n",
      "38 400\n",
      "Loss =  13877.4716796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 38 is 0.96875\u001b[0m\n",
      "39 0\n",
      "Loss =  17601.5546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.90625\u001b[0m\n",
      "39 100\n",
      "Loss =  14124.541015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.921875\u001b[0m\n",
      "39 200\n",
      "Loss =  14767.3486328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.921875\u001b[0m\n",
      "39 300\n",
      "Loss =  11722.8359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.9609375\u001b[0m\n",
      "39 400\n",
      "Loss =  13877.9794921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 39 is 0.953125\u001b[0m\n",
      "40 0\n",
      "Loss =  10464.435546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.96875\u001b[0m\n",
      "40 100\n",
      "Loss =  11917.55078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.9453125\u001b[0m\n",
      "40 200\n",
      "Loss =  16162.8740234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.9609375\u001b[0m\n",
      "40 300\n",
      "Loss =  17694.771484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.8984375\u001b[0m\n",
      "40 400\n",
      "Loss =  8104.052734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 40 is 0.984375\u001b[0m\n",
      "41 0\n",
      "Loss =  14540.4873046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.9609375\u001b[0m\n",
      "41 100\n",
      "Loss =  10533.8798828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.953125\u001b[0m\n",
      "41 200\n",
      "Loss =  12371.669921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.96875\u001b[0m\n",
      "41 300\n",
      "Loss =  7235.16015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.984375\u001b[0m\n",
      "41 400\n",
      "Loss =  14430.5771484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 41 is 0.9375\u001b[0m\n",
      "42 0\n",
      "Loss =  7189.0830078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.984375\u001b[0m\n",
      "42 100\n",
      "Loss =  11295.0078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.96875\u001b[0m\n",
      "42 200\n",
      "Loss =  12278.0234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.9453125\u001b[0m\n",
      "42 300\n",
      "Loss =  8072.0986328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.984375\u001b[0m\n",
      "42 400\n",
      "Loss =  11512.4609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 42 is 0.96875\u001b[0m\n",
      "43 0\n",
      "Loss =  9542.4150390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.96875\u001b[0m\n",
      "43 100\n",
      "Loss =  10105.482421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.9765625\u001b[0m\n",
      "43 200\n",
      "Loss =  21200.6015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.921875\u001b[0m\n",
      "43 300\n",
      "Loss =  9266.248046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.9765625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 400\n",
      "Loss =  11564.2587890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 43 is 0.96875\u001b[0m\n",
      "44 0\n",
      "Loss =  16918.921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9453125\u001b[0m\n",
      "44 100\n",
      "Loss =  15289.892578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.9453125\u001b[0m\n",
      "44 200\n",
      "Loss =  9998.740234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.96875\u001b[0m\n",
      "44 300\n",
      "Loss =  8782.552734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.96875\u001b[0m\n",
      "44 400\n",
      "Loss =  15603.150390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 44 is 0.953125\u001b[0m\n",
      "45 0\n",
      "Loss =  9136.0361328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.9609375\u001b[0m\n",
      "45 100\n",
      "Loss =  9787.0546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.96875\u001b[0m\n",
      "45 200\n",
      "Loss =  14651.6513671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.953125\u001b[0m\n",
      "45 300\n",
      "Loss =  13344.16015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.9375\u001b[0m\n",
      "45 400\n",
      "Loss =  13264.443359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 45 is 0.9375\u001b[0m\n",
      "46 0\n",
      "Loss =  8563.9794921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.984375\u001b[0m\n",
      "46 100\n",
      "Loss =  10214.373046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.9609375\u001b[0m\n",
      "46 200\n",
      "Loss =  10609.509765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.96875\u001b[0m\n",
      "46 300\n",
      "Loss =  8340.2919921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.9765625\u001b[0m\n",
      "46 400\n",
      "Loss =  10107.54296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 46 is 0.9765625\u001b[0m\n",
      "47 0\n",
      "Loss =  10263.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.96875\u001b[0m\n",
      "47 100\n",
      "Loss =  14296.2509765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.9453125\u001b[0m\n",
      "47 200\n",
      "Loss =  10895.689453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.953125\u001b[0m\n",
      "47 300\n",
      "Loss =  9391.63671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.96875\u001b[0m\n",
      "47 400\n",
      "Loss =  9953.7177734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 47 is 0.9765625\u001b[0m\n",
      "48 0\n",
      "Loss =  10067.1064453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9609375\u001b[0m\n",
      "48 100\n",
      "Loss =  15411.92578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.953125\u001b[0m\n",
      "48 200\n",
      "Loss =  6853.4384765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9921875\u001b[0m\n",
      "48 300\n",
      "Loss =  8288.51171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.984375\u001b[0m\n",
      "48 400\n",
      "Loss =  10246.5224609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 48 is 0.9765625\u001b[0m\n",
      "49 0\n",
      "Loss =  7538.89453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.9921875\u001b[0m\n",
      "49 100\n",
      "Loss =  9938.541015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.953125\u001b[0m\n",
      "49 200\n",
      "Loss =  14774.4814453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.9609375\u001b[0m\n",
      "49 300\n",
      "Loss =  10670.798828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.96875\u001b[0m\n",
      "49 400\n",
      "Loss =  10667.765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 49 is 0.9765625\u001b[0m\n",
      "50 0\n",
      "Loss =  15857.1708984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9453125\u001b[0m\n",
      "50 100\n",
      "Loss =  11064.048828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9609375\u001b[0m\n",
      "50 200\n",
      "Loss =  11413.720703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.953125\u001b[0m\n",
      "50 300\n",
      "Loss =  8122.1259765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9921875\u001b[0m\n",
      "50 400\n",
      "Loss =  8562.9462890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 50 is 0.9765625\u001b[0m\n",
      "51 0\n",
      "Loss =  9759.0673828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96875\u001b[0m\n",
      "51 100\n",
      "Loss =  9823.603515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.9765625\u001b[0m\n",
      "51 200\n",
      "Loss =  6538.14599609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.984375\u001b[0m\n",
      "51 300\n",
      "Loss =  14547.2392578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.96875\u001b[0m\n",
      "51 400\n",
      "Loss =  6934.939453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 51 is 0.984375\u001b[0m\n",
      "52 0\n",
      "Loss =  12725.828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.9453125\u001b[0m\n",
      "52 100\n",
      "Loss =  12723.169921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.9609375\u001b[0m\n",
      "52 200\n",
      "Loss =  17056.794921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.921875\u001b[0m\n",
      "52 300\n",
      "Loss =  10917.51953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.9453125\u001b[0m\n",
      "52 400\n",
      "Loss =  11941.84375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 52 is 0.9609375\u001b[0m\n",
      "53 0\n",
      "Loss =  8582.0400390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.9765625\u001b[0m\n",
      "53 100\n",
      "Loss =  8332.9453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.96875\u001b[0m\n",
      "53 200\n",
      "Loss =  8748.583984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.96875\u001b[0m\n",
      "53 300\n",
      "Loss =  13450.3994140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.9453125\u001b[0m\n",
      "53 400\n",
      "Loss =  9524.388671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 53 is 0.9765625\u001b[0m\n",
      "54 0\n",
      "Loss =  7165.38427734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.984375\u001b[0m\n",
      "54 100\n",
      "Loss =  8917.169921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.984375\u001b[0m\n",
      "54 200\n",
      "Loss =  10568.263671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.9765625\u001b[0m\n",
      "54 300\n",
      "Loss =  8393.720703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.96875\u001b[0m\n",
      "54 400\n",
      "Loss =  6635.3662109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 54 is 0.984375\u001b[0m\n",
      "55 0\n",
      "Loss =  12186.26953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.9609375\u001b[0m\n",
      "55 100\n",
      "Loss =  12178.4892578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.96875\u001b[0m\n",
      "55 200\n",
      "Loss =  13334.3310546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.9453125\u001b[0m\n",
      "55 300\n",
      "Loss =  10502.3115234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.984375\u001b[0m\n",
      "55 400\n",
      "Loss =  10246.03125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 55 is 0.96875\u001b[0m\n",
      "56 0\n",
      "Loss =  8934.96875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.984375\u001b[0m\n",
      "56 100\n",
      "Loss =  9308.888671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.984375\u001b[0m\n",
      "56 200\n",
      "Loss =  10350.89453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.953125\u001b[0m\n",
      "56 300\n",
      "Loss =  8566.123046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.9609375\u001b[0m\n",
      "56 400\n",
      "Loss =  11362.984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 56 is 0.9765625\u001b[0m\n",
      "57 0\n",
      "Loss =  7531.869140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.984375\u001b[0m\n",
      "57 100\n",
      "Loss =  6866.333984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.984375\u001b[0m\n",
      "57 200\n",
      "Loss =  7407.8828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.96875\u001b[0m\n",
      "57 300\n",
      "Loss =  11742.7060546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.9453125\u001b[0m\n",
      "57 400\n",
      "Loss =  9401.7333984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 57 is 0.984375\u001b[0m\n",
      "58 0\n",
      "Loss =  6867.5029296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.984375\u001b[0m\n",
      "58 100\n",
      "Loss =  8911.359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.9765625\u001b[0m\n",
      "58 200\n",
      "Loss =  7471.4130859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.9921875\u001b[0m\n",
      "58 300\n",
      "Loss =  7712.896484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.9921875\u001b[0m\n",
      "58 400\n",
      "Loss =  9292.177734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 58 is 0.984375\u001b[0m\n",
      "59 0\n",
      "Loss =  12228.4951171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.9453125\u001b[0m\n",
      "59 100\n",
      "Loss =  12786.474609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.953125\u001b[0m\n",
      "59 200\n",
      "Loss =  14490.189453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.953125\u001b[0m\n",
      "59 300\n",
      "Loss =  8372.8681640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.9765625\u001b[0m\n",
      "59 400\n",
      "Loss =  8048.19580078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 59 is 0.984375\u001b[0m\n",
      "60 0\n",
      "Loss =  7403.98291015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.9921875\u001b[0m\n",
      "60 100\n",
      "Loss =  11176.29296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.96875\u001b[0m\n",
      "60 200\n",
      "Loss =  10372.4755859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.9765625\u001b[0m\n",
      "60 300\n",
      "Loss =  17651.234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.921875\u001b[0m\n",
      "60 400\n",
      "Loss =  17655.755859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 60 is 0.9375\u001b[0m\n",
      "61 0\n",
      "Loss =  9226.078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.9765625\u001b[0m\n",
      "61 100\n",
      "Loss =  18445.666015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.953125\u001b[0m\n",
      "61 200\n",
      "Loss =  12332.017578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.96875\u001b[0m\n",
      "61 300\n",
      "Loss =  13167.8046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.9453125\u001b[0m\n",
      "61 400\n",
      "Loss =  15397.748046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 61 is 0.9609375\u001b[0m\n",
      "62 0\n",
      "Loss =  5686.29541015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 1.0\u001b[0m\n",
      "62 100\n",
      "Loss =  8358.6787109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.984375\u001b[0m\n",
      "62 200\n",
      "Loss =  11256.34375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.953125\u001b[0m\n",
      "62 300\n",
      "Loss =  8578.7333984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.9765625\u001b[0m\n",
      "62 400\n",
      "Loss =  8053.64697265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 62 is 0.9921875\u001b[0m\n",
      "63 0\n",
      "Loss =  8972.13671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.96875\u001b[0m\n",
      "63 100\n",
      "Loss =  9627.140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.984375\u001b[0m\n",
      "63 200\n",
      "Loss =  7774.05517578125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.9765625\u001b[0m\n",
      "63 300\n",
      "Loss =  10878.677734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.953125\u001b[0m\n",
      "63 400\n",
      "Loss =  8382.958984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 63 is 0.9765625\u001b[0m\n",
      "64 0\n",
      "Loss =  5998.4404296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9921875\u001b[0m\n",
      "64 100\n",
      "Loss =  8437.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.96875\u001b[0m\n",
      "64 200\n",
      "Loss =  10341.2138671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.96875\u001b[0m\n",
      "64 300\n",
      "Loss =  8116.982421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.9921875\u001b[0m\n",
      "64 400\n",
      "Loss =  7657.3583984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 64 is 0.984375\u001b[0m\n",
      "65 0\n",
      "Loss =  9364.0419921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.96875\u001b[0m\n",
      "65 100\n",
      "Loss =  8984.296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.9609375\u001b[0m\n",
      "65 200\n",
      "Loss =  5922.67724609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.9921875\u001b[0m\n",
      "65 300\n",
      "Loss =  9243.822265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.9765625\u001b[0m\n",
      "65 400\n",
      "Loss =  9055.609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 65 is 0.9765625\u001b[0m\n",
      "66 0\n",
      "Loss =  6154.55126953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9921875\u001b[0m\n",
      "66 100\n",
      "Loss =  8733.658203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.984375\u001b[0m\n",
      "66 200\n",
      "Loss =  7763.568359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9765625\u001b[0m\n",
      "66 300\n",
      "Loss =  9096.162109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.96875\u001b[0m\n",
      "66 400\n",
      "Loss =  8190.498046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 66 is 0.9765625\u001b[0m\n",
      "67 0\n",
      "Loss =  8492.08203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9765625\u001b[0m\n",
      "67 100\n",
      "Loss =  10203.591796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9609375\u001b[0m\n",
      "67 200\n",
      "Loss =  8428.6953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.9609375\u001b[0m\n",
      "67 300\n",
      "Loss =  11160.8291015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.96875\u001b[0m\n",
      "67 400\n",
      "Loss =  16276.7421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 67 is 0.953125\u001b[0m\n",
      "68 0\n",
      "Loss =  7077.1220703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.984375\u001b[0m\n",
      "68 100\n",
      "Loss =  7275.732421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9921875\u001b[0m\n",
      "68 200\n",
      "Loss =  10800.7119140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9453125\u001b[0m\n",
      "68 300\n",
      "Loss =  11746.3583984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.9609375\u001b[0m\n",
      "68 400\n",
      "Loss =  7846.087890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 68 is 0.96875\u001b[0m\n",
      "69 0\n",
      "Loss =  8628.1484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.9609375\u001b[0m\n",
      "69 100\n",
      "Loss =  7811.681640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.9921875\u001b[0m\n",
      "69 200\n",
      "Loss =  10980.3974609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.9609375\u001b[0m\n",
      "69 300\n",
      "Loss =  5896.76611328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 1.0\u001b[0m\n",
      "69 400\n",
      "Loss =  8146.35205078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 69 is 0.984375\u001b[0m\n",
      "70 0\n",
      "Loss =  8199.4736328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.9921875\u001b[0m\n",
      "70 100\n",
      "Loss =  7086.294921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.984375\u001b[0m\n",
      "70 200\n",
      "Loss =  9768.1015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.9765625\u001b[0m\n",
      "70 300\n",
      "Loss =  11163.48046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.9765625\u001b[0m\n",
      "70 400\n",
      "Loss =  7732.4482421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 70 is 0.984375\u001b[0m\n",
      "71 0\n",
      "Loss =  10632.171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.9609375\u001b[0m\n",
      "71 100\n",
      "Loss =  7000.146484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.9765625\u001b[0m\n",
      "71 200\n",
      "Loss =  13539.544921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.9609375\u001b[0m\n",
      "71 300\n",
      "Loss =  6144.5546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.9921875\u001b[0m\n",
      "71 400\n",
      "Loss =  10313.552734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 71 is 0.96875\u001b[0m\n",
      "72 0\n",
      "Loss =  9221.32421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.96875\u001b[0m\n",
      "72 100\n",
      "Loss =  11912.6953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.96875\u001b[0m\n",
      "72 200\n",
      "Loss =  6756.05859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 1.0\u001b[0m\n",
      "72 300\n",
      "Loss =  7850.75439453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.984375\u001b[0m\n",
      "72 400\n",
      "Loss =  9540.9453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 72 is 0.9765625\u001b[0m\n",
      "73 0\n",
      "Loss =  11282.40625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.96875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 100\n",
      "Loss =  9395.703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.96875\u001b[0m\n",
      "73 200\n",
      "Loss =  7253.9189453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.9921875\u001b[0m\n",
      "73 300\n",
      "Loss =  6872.185546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.9921875\u001b[0m\n",
      "73 400\n",
      "Loss =  10194.453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 73 is 0.953125\u001b[0m\n",
      "74 0\n",
      "Loss =  9640.263671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.984375\u001b[0m\n",
      "74 100\n",
      "Loss =  9934.34765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.9609375\u001b[0m\n",
      "74 200\n",
      "Loss =  12977.595703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.9765625\u001b[0m\n",
      "74 300\n",
      "Loss =  10591.099609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.9609375\u001b[0m\n",
      "74 400\n",
      "Loss =  6425.1884765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 74 is 0.984375\u001b[0m\n",
      "75 0\n",
      "Loss =  8067.8388671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.9765625\u001b[0m\n",
      "75 100\n",
      "Loss =  9348.85546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.9609375\u001b[0m\n",
      "75 200\n",
      "Loss =  6953.232421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.9921875\u001b[0m\n",
      "75 300\n",
      "Loss =  7601.20654296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.984375\u001b[0m\n",
      "75 400\n",
      "Loss =  10123.384765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 75 is 0.984375\u001b[0m\n",
      "76 0\n",
      "Loss =  7563.978515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.984375\u001b[0m\n",
      "76 100\n",
      "Loss =  5994.3505859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 1.0\u001b[0m\n",
      "76 200\n",
      "Loss =  7971.16455078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.9921875\u001b[0m\n",
      "76 300\n",
      "Loss =  9014.0390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.984375\u001b[0m\n",
      "76 400\n",
      "Loss =  11709.0791015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 76 is 0.953125\u001b[0m\n",
      "77 0\n",
      "Loss =  6935.89453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.984375\u001b[0m\n",
      "77 100\n",
      "Loss =  8505.078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.984375\u001b[0m\n",
      "77 200\n",
      "Loss =  6749.70703125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9765625\u001b[0m\n",
      "77 300\n",
      "Loss =  8929.1015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9765625\u001b[0m\n",
      "77 400\n",
      "Loss =  8073.4296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 77 is 0.9765625\u001b[0m\n",
      "78 0\n",
      "Loss =  6160.830078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.984375\u001b[0m\n",
      "78 100\n",
      "Loss =  10150.337890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.9765625\u001b[0m\n",
      "78 200\n",
      "Loss =  10724.6455078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.9453125\u001b[0m\n",
      "78 300\n",
      "Loss =  9551.03515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.96875\u001b[0m\n",
      "78 400\n",
      "Loss =  14298.427734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 78 is 0.96875\u001b[0m\n",
      "79 0\n",
      "Loss =  6317.455078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 1.0\u001b[0m\n",
      "79 100\n",
      "Loss =  9679.962890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9765625\u001b[0m\n",
      "79 200\n",
      "Loss =  14275.908203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9453125\u001b[0m\n",
      "79 300\n",
      "Loss =  9635.466796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9609375\u001b[0m\n",
      "79 400\n",
      "Loss =  6491.58935546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 79 is 0.9921875\u001b[0m\n",
      "80 0\n",
      "Loss =  5291.6669921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 1.0\u001b[0m\n",
      "80 100\n",
      "Loss =  7115.84912109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.9921875\u001b[0m\n",
      "80 200\n",
      "Loss =  6976.7880859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.984375\u001b[0m\n",
      "80 300\n",
      "Loss =  12423.943359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.9609375\u001b[0m\n",
      "80 400\n",
      "Loss =  8823.154296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 80 is 0.96875\u001b[0m\n",
      "81 0\n",
      "Loss =  7928.47412109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.9765625\u001b[0m\n",
      "81 100\n",
      "Loss =  11571.287109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.96875\u001b[0m\n",
      "81 200\n",
      "Loss =  7558.431640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.984375\u001b[0m\n",
      "81 300\n",
      "Loss =  8752.9765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 0.96875\u001b[0m\n",
      "81 400\n",
      "Loss =  5546.79931640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 81 is 1.0\u001b[0m\n",
      "82 0\n",
      "Loss =  12286.1337890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.984375\u001b[0m\n",
      "82 100\n",
      "Loss =  7707.5986328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.9765625\u001b[0m\n",
      "82 200\n",
      "Loss =  8385.978515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.96875\u001b[0m\n",
      "82 300\n",
      "Loss =  9319.296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.984375\u001b[0m\n",
      "82 400\n",
      "Loss =  9284.5185546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 82 is 0.9609375\u001b[0m\n",
      "83 0\n",
      "Loss =  11837.4296875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.9609375\u001b[0m\n",
      "83 100\n",
      "Loss =  5582.48291015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 1.0\u001b[0m\n",
      "83 200\n",
      "Loss =  9009.46484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.9765625\u001b[0m\n",
      "83 300\n",
      "Loss =  6066.5166015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 1.0\u001b[0m\n",
      "83 400\n",
      "Loss =  9451.6796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 83 is 0.9609375\u001b[0m\n",
      "84 0\n",
      "Loss =  6104.44482421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.9921875\u001b[0m\n",
      "84 100\n",
      "Loss =  6834.79833984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.984375\u001b[0m\n",
      "84 200\n",
      "Loss =  6670.97509765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.984375\u001b[0m\n",
      "84 300\n",
      "Loss =  9293.7919921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.9609375\u001b[0m\n",
      "84 400\n",
      "Loss =  8935.560546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 84 is 0.984375\u001b[0m\n",
      "85 0\n",
      "Loss =  7211.3740234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9765625\u001b[0m\n",
      "85 100\n",
      "Loss =  8666.03515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9765625\u001b[0m\n",
      "85 200\n",
      "Loss =  9692.34765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9765625\u001b[0m\n",
      "85 300\n",
      "Loss =  9415.5625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9765625\u001b[0m\n",
      "85 400\n",
      "Loss =  9076.0380859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 85 is 0.9765625\u001b[0m\n",
      "86 0\n",
      "Loss =  11606.25390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9765625\u001b[0m\n",
      "86 100\n",
      "Loss =  9427.1513671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9765625\u001b[0m\n",
      "86 200\n",
      "Loss =  6892.248046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9921875\u001b[0m\n",
      "86 300\n",
      "Loss =  6291.41455078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9921875\u001b[0m\n",
      "86 400\n",
      "Loss =  9544.8447265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 86 is 0.9765625\u001b[0m\n",
      "87 0\n",
      "Loss =  7214.11669921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.984375\u001b[0m\n",
      "87 100\n",
      "Loss =  7608.4453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.9765625\u001b[0m\n",
      "87 200\n",
      "Loss =  8318.880859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.984375\u001b[0m\n",
      "87 300\n",
      "Loss =  10479.37109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.96875\u001b[0m\n",
      "87 400\n",
      "Loss =  8708.138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 87 is 0.984375\u001b[0m\n",
      "88 0\n",
      "Loss =  9363.26953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.9609375\u001b[0m\n",
      "88 100\n",
      "Loss =  6431.1806640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 1.0\u001b[0m\n",
      "88 200\n",
      "Loss =  8127.8955078125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.984375\u001b[0m\n",
      "88 300\n",
      "Loss =  6032.6298828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.9921875\u001b[0m\n",
      "88 400\n",
      "Loss =  7714.859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 88 is 0.984375\u001b[0m\n",
      "89 0\n",
      "Loss =  8430.501953125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.984375\u001b[0m\n",
      "89 100\n",
      "Loss =  8177.505859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.9765625\u001b[0m\n",
      "89 200\n",
      "Loss =  7862.16650390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.984375\u001b[0m\n",
      "89 300\n",
      "Loss =  7706.005859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.9765625\u001b[0m\n",
      "89 400\n",
      "Loss =  9971.86328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 89 is 0.96875\u001b[0m\n",
      "90 0\n",
      "Loss =  6784.11181640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.9921875\u001b[0m\n",
      "90 100\n",
      "Loss =  7112.2822265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.9921875\u001b[0m\n",
      "90 200\n",
      "Loss =  9035.044921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.96875\u001b[0m\n",
      "90 300\n",
      "Loss =  10427.7734375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.984375\u001b[0m\n",
      "90 400\n",
      "Loss =  11678.9384765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 90 is 0.96875\u001b[0m\n",
      "91 0\n",
      "Loss =  14766.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.953125\u001b[0m\n",
      "91 100\n",
      "Loss =  7729.9521484375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.984375\u001b[0m\n",
      "91 200\n",
      "Loss =  7403.4541015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.96875\u001b[0m\n",
      "91 300\n",
      "Loss =  8539.23828125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.96875\u001b[0m\n",
      "91 400\n",
      "Loss =  12238.91015625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 91 is 0.9609375\u001b[0m\n",
      "92 0\n",
      "Loss =  5538.9208984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 1.0\u001b[0m\n",
      "92 100\n",
      "Loss =  12890.263671875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.953125\u001b[0m\n",
      "92 200\n",
      "Loss =  8364.9453125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.9921875\u001b[0m\n",
      "92 300\n",
      "Loss =  6140.306640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.9921875\u001b[0m\n",
      "92 400\n",
      "Loss =  9832.744140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 92 is 0.9609375\u001b[0m\n",
      "93 0\n",
      "Loss =  7194.78466796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.984375\u001b[0m\n",
      "93 100\n",
      "Loss =  12313.236328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.9453125\u001b[0m\n",
      "93 200\n",
      "Loss =  11593.8203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.96875\u001b[0m\n",
      "93 300\n",
      "Loss =  7907.9912109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.984375\u001b[0m\n",
      "93 400\n",
      "Loss =  10408.583984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 93 is 0.9765625\u001b[0m\n",
      "94 0\n",
      "Loss =  8536.958984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.9765625\u001b[0m\n",
      "94 100\n",
      "Loss =  7584.982421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.984375\u001b[0m\n",
      "94 200\n",
      "Loss =  6639.1162109375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.984375\u001b[0m\n",
      "94 300\n",
      "Loss =  7771.82861328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.984375\u001b[0m\n",
      "94 400\n",
      "Loss =  9867.123046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 94 is 0.9609375\u001b[0m\n",
      "95 0\n",
      "Loss =  8215.15234375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9765625\u001b[0m\n",
      "95 100\n",
      "Loss =  7991.869140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.9765625\u001b[0m\n",
      "95 200\n",
      "Loss =  9709.2724609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.953125\u001b[0m\n",
      "95 300\n",
      "Loss =  9492.5546875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.96875\u001b[0m\n",
      "95 400\n",
      "Loss =  8146.7265625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 95 is 0.96875\u001b[0m\n",
      "96 0\n",
      "Loss =  6682.1669921875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.984375\u001b[0m\n",
      "96 100\n",
      "Loss =  9577.59765625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.9765625\u001b[0m\n",
      "96 200\n",
      "Loss =  6426.6533203125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 1.0\u001b[0m\n",
      "96 300\n",
      "Loss =  8573.083984375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.9765625\u001b[0m\n",
      "96 400\n",
      "Loss =  6719.619140625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 96 is 0.984375\u001b[0m\n",
      "97 0\n",
      "Loss =  5633.2255859375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.9921875\u001b[0m\n",
      "97 100\n",
      "Loss =  7237.12353515625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.9765625\u001b[0m\n",
      "97 200\n",
      "Loss =  9297.0498046875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.96875\u001b[0m\n",
      "97 300\n",
      "Loss =  8743.806640625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.9765625\u001b[0m\n",
      "97 400\n",
      "Loss =  7437.61328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 97 is 0.9765625\u001b[0m\n",
      "98 0\n",
      "Loss =  6813.50732421875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.984375\u001b[0m\n",
      "98 100\n",
      "Loss =  10400.2236328125\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.9765625\u001b[0m\n",
      "98 200\n",
      "Loss =  8374.01171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.96875\u001b[0m\n",
      "98 300\n",
      "Loss =  6139.1025390625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.9921875\u001b[0m\n",
      "98 400\n",
      "Loss =  9884.693359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 98 is 0.953125\u001b[0m\n",
      "99 0\n",
      "Loss =  7645.3837890625\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.984375\u001b[0m\n",
      "99 100\n",
      "Loss =  6687.93359375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.9921875\u001b[0m\n",
      "99 200\n",
      "Loss =  6791.16796875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.984375\u001b[0m\n",
      "99 300\n",
      "Loss =  5213.53076171875\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 1.0\u001b[0m\n",
      "99 400\n",
      "Loss =  9494.609375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 99 is 0.96875\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.9731)\n"
     ]
    }
   ],
   "source": [
    "eps_scale = 0\n",
    "for lr in [1e-3]:\n",
    "    for l in [1200]:\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        model4 = BNN(train_loader, [784, l, l, 10], act = nn.Tanh(), n_epochs = 100)\n",
    "        model4.train(lr = lr, decay = 1)\n",
    "        #models.append(model)\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "    \n",
    "        for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "            A = example_data/126\n",
    "            b = example_targets\n",
    "        z = model4.BNet(A).detach()\n",
    "        T_pred = torch.argmax(z, dim = 1)\n",
    "        print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f31b93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdc652d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.genfromtxt(\"result1.txt\", dtype = float, delimiter = ',')\n",
    "B = np.genfromtxt(\"result2.txt\", dtype = float, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2d83e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACubElEQVR4nOydd3zTZf7A309G994TOmjZpewhUxRQcE/0xL3x5Byn5zjRc+vpz3Vy6LlRcQ9EhorsvTcU6N57jyTP748nSdM0bVMoQ5v369VXku98kibP5/lsIaXEhQsXLlx0PzSnewAuXLhw4eL04BIALly4cNFNcQkAFy5cuOimuASACxcuXHRTXALAhQsXLropLgHgwoULF90UpwSAEGKaEOKgECJNCPGwg/3XCiF2mf/WCSEGdXSuECJICLFcCHHY/BjYNW/JhQsXLlw4Q4cCQAihBd4CzgP6ATOFEP3sDjsGTJBSpgD/AuY7ce7DwK9SyiTgV/NrFy5cuHBxinBGAxgBpEkpj0opG4HPgYtsD5BSrpNSlplfbgBinDj3IuBD8/MPgYuP+124cOHChYtOo3PimGggy+Z1NjCyneNvBn524txwKWUegJQyTwgR5uhiQojbgNsAvL29h/bp08eJIbdN0dEMTBgJT0g4oeu4cOHCxR+FrVu3FkspQ+23OyMAhINtDutHCCEmoQTA2M6e2xZSyvmYTUrDhg2TW7Zs6czprZh3xS3UaCu4//MvT+g6Lly4cPFHQQiR4Wi7MyagbCDW5nUMkOvgBinAu8BFUsoSJ84tEEJEms+NBAqdGIsLFy5cuOginBEAm4EkIUS8EMINuBr4wfYAIUQP4BvgOinlISfP/QG43vz8euD7438bLly4cOGis3RoApJSGoQQs4GlgBZ4T0q5Vwhxh3n/POCfQDDwHyEEgEFKOaytc82Xfh74QghxM5AJXNHF7629d4XBaEKndaVBuHDhovvijA8AKeViYLHdtnk2z28BbnH2XPP2EmByZwbblTQYXALAxcmlqamJ7Oxs6uvrT/dQXHQTPDw8iImJQa/XO3W8UwLgz0h9fT3e7j6nexgu/sRkZ2fj6+tLXFwcZs3YhYuThpSSkpISsrOziY+Pd+qcbroEljTUVZ7uQbj4k1NfX09wcLBr8ndxShBCEBwc3CmNs/sJAHMQalONSwC4OPm4Jn8Xp5LOft+6nQCwfEAGlwbgwoWLbk63EwCYeyA31JZ1cKALF398tFotqampDBo0iCFDhrBu3ToA0tPTEULwxhtvWI+dPXs2H3zwAQA33HAD0dHRNDQ0AFBcXExcXFyn7v3777/j7+/P4MGD6dOnDw888ECH50ycOBH7ZM+4uDiKi4tbXHfGjBmdGosLx3Q/ASAEIKmtK+nwUBcu/uh4enqyY8cOdu7cyXPPPcc//vEP676wsDBee+01GhsbHZ6r1Wp57733Tuj+48aNY/v27Wzfvp1Fixaxdu3aE7qei66l2wkAASChvq78NI/EhYtTS2VlJYGBzVXXQ0NDmTx5Mh9++KHD4+fMmcOrr76KwWA44Xt7enqSmppKTk4OAMuWLWP06NEMGTKEK664gurq6hO+h4vO033DQBtcJiAXp44nf9zLvtyu9Tv1i/LjiQv6t3tMXV0dqamp1NfXk5eXx2+//dZi/8MPP8x5553HTTfd1OrcHj16MHbsWD7++GMuuOCCExprWVkZhw8fZvz48RQXF/P000/zyy+/4O3tzQsvvMArr7zCP//5zxO6h4vO000FgKS+weUEdvHnx2ICAli/fj2zZs1iz5491v3x8fGMGDGCTz/91OH5jzzyCBdeeCHTp08/rvuvXr2alJQUDh48yMMPP0xERASLFi1i3759nHXWWQA0NjYyevToNq/hKLLFFV3VNXQ7ASDMBUobG6tO80hcdCc6WqmfCkaPHk1xcTFFRUUttj/yyCNcfvnljB8/vtU5vXr1IjU1lS+++MLhNd966y3eeecdABYvXkxUVFSL/ePGjWPRokUcOnSIsWPHcskllyCl5Nxzz+Wzzz5zatzBwcGUlZUREhICQGlpqfW5ixOj2/kALDQaXDZHF92LAwcOYDQaCQ4ObrG9T58+9OvXj0WLFjk879FHH+Xll192uO/uu+9mx44d7Nixo9Xkb0tycjL/+Mc/eOGFFxg1ahRr164lLS0NgNraWg4dOtTmuRMnTuTjjz8GwGg08sknnzBp0qR236sL5+h2GoBC0mioOd2DcOHipGPxAYAqFfDhhx+i1WpbHffoo48yePBgh9fo378/Q4YMYdu2bSc0ljvuuIOXX36Z6upqPvjgA2bOnGkNM3366adJTk4GYPr06dZaNqNHj+bdd9/lzjvvZNCgQUgpmTZtGn/5y19OaCwuFELKTvVnOa10RUOYd6+4nQpNAQFnN3Lz7a1q1Llw0WXs37+fvn37nu5huOhmOPreCSG2SimH2R/b/UxA5jjQJlPt6R6JCxcuXJxWup0AEGgAE43GhtM9FBcuXLg4rXQ7AaCRGlRDGJcAcOHCRfem+wkAod6ywWQ8zSNx4cKFi9NL9xMAqAgIg/HE09v/8Oz6Er6943SPwoULF6cJpwSAEGKaEOKgECJNCPGwg/19hBDrhRANQogHbLb3FkLssPmrFELMMe+bK4TIsdl3fpe9q/beCxYNwHQqbndmc/R32O849tuFCxd/fjoUAEIILfAWcB7QD5gphOhnd1gp8FegRbaIlPKglDJVSpkKDAVqgW9tDnnVst/cO/iko7EKAKylobstjVVgqDvdo3BxEjld5aCXLl1Kamoqqamp+Pj40Lt3b1JTU5k1a1anxj937tw2k9BcnDjOaAAjgDQp5VEpZSPwOXCR7QFSykIp5WagqZ3rTAaOSCkzjnu0XYBFADSZNNDUzUNBG6rBZACXOexPy+kqBz116lRrhvCwYcNYsGABO3bs4KOPPjqu67k4OTgjAKKBLJvX2eZtneVqwL74x2whxC4hxHtCiEBHJ3U1Fh9Ak9SqCbA702Cuh+TSAroFp7MctIU777yTYcOG0b9/f5544gnr9ri4OJ544gmGDBnCwIEDOXDggHXfvn37mDhxIgkJCbz++utdNhYXzpWCcFR2r1O2EyGEG3Ah8A+bzW8D/zJf61/Av4FWNWmFELcBt4EqT3uiCHMUUJPUQGM1EH7C1/zD0mgWgIYGcPc9vWP5s/Pzw5C/u2uvGTEQznu+3UPOlHLQFp555hmCgoIwGo1MnjyZXbt2kZKSAkBISAjbtm3jP//5Dy+//DLvvvsuoGoYrVixgqqqKnr37s2dd95pLRXh4sRwRgPIBmJtXscAuZ28z3nANillgWWDlLJASmmUUpqAd1CmplZIKedLKYdJKYeFhoZ28ratsZiAjEYtdPeS0BYNqMmlAfxZsZiADhw4wJIlS5g1axa25V+cKQf90ksvYeqioIkvvviCIUOGMHjwYPbu3cu+ffus+y699FIAhg4dSnp6unX79OnTcXd3JyQkhLCwMAoKCuwv6+I4cUYD2AwkCSHigRyUKeeaTt5nJnbmHyFEpJQyz/zyEmBPq7NOAtYwUKlxmYAsJbEN9ad3HN2BDlbqp4LTUQ7almPHjvHyyy+zefNmAgMDueGGG6ivb/7uubu7A8r3YGt2smx3tM/FidGhBiClNACzgaXAfuALKeVeIcQdQog7AIQQEUKIbOA+4DEhRLYQws+8zws4F/jG7tIvCiF2CyF2AZOAv3XZu2oHrfktm0yaZhNId8WlAXQrTmc5aFA+CG9vb/z9/SkoKODnn38+vjfiostwqhy0OURzsd22eTbP81GmIUfn1gLBDrZf16mRdhGWhjAmUzfXAAwNYDIHbbk0gD8tZ1I56EGDBjF48GD69+9PQkKCtSOYi9NHtysH/fOVc9kntrAvsZx3LrkJzfDWzq9uQU0xvJSons/6ARImnN7x/AlxlYN2cTpwlYNuB700ADo0Bj1NtRWnezinjwablpguDcCFi25JtxMAWtkIQo/OoKOhrhsLAFv/h0sAuHDRLel2AkBnagKhx82opbq+GwsAW/9Hk0sAuHDRHel+AkA2ItChM2ipb+jGAqCFBuCKAnLhojvS7QSAVhpA6NEbNdTa2sG7G7ZJcC4NwIWLbkm3EwA62QhCh86oob6xOwsAlwbgwkV3p/sJAJoQ6NEZBQ2GblwNtNHlA+gOPPPMM/Tv35+UlBRSU1PZuHEjAAaDgUceeYSkpCRr2eZnnnnGep6ljHT//v0ZNGgQr7zySqfLQXzwwQeEhoaSmppKnz59ePXVVzs8Jy4ujuLi4hbbfHx8Wl139uzZnRqLC8c4lQj2Z0JragKhQ2ukewsAiwag0bk0gD8p69evZ9GiRWzbtg13d3eKi4utpZ8fe+wx8vPz2b17Nx4eHlRVVfHvf//beq6lhhBAYWEh11xzDRUVFTz55JOdGsNVV13Fm2++SUlJCb179+byyy8nNja24xNdnBK6oQagwkC1JmgwduOVb2MV6DxB762ygl386cjLyyMkJMRaSyckJISoqChqa2t55513eOONN/Dw8ADA19eXuXPnOrxOWFgY8+fP58033+R4E0eDg4Pp1asXeXmq/Ncnn3zCiBEjSE1N5fbbb8dodPXoPh10Ow1AhwGBDo1J0mjqxhNfQzW4+4DQuGoBnQJe2PQCB0oPdHxgJ+gT1IeHRjzU5v4pU6bw1FNPkZyczDnnnMNVV13FhAkTSEtLo0ePHvj6Ol8CPCEhAZPJRGFhIeHhnS+hnpmZSX19PSkpKezfv5+FCxeydu1a9Ho9d911FwsWLOh0tzAXJ0630wAEAiG0SgDI7iwAqsDNB3QerkSwPyk+Pj5s3bqV+fPnExoaylVXXWVt+WjL+++/T2pqKrGxsWRlZbW+kJnjWf0vXLjQWvvn3nvvxcPDg19//ZWtW7cyfPhwUlNT+fXXXzl69GinriuEozYlLjpLt9MAEAINGjQmEw3SqNoharvfx0CjWQMwNLo0gFNAeyv1k4lWq2XixIlMnDiRgQMH8uGHH3LllVeSmZlJVVUVvr6+3Hjjjdx4440MGDCgTVPM0aNH0Wq1hIWFtdj+6KOP8tNPPwFYfQa2WHwA69evZ/r06Zx33nlIKbn++ut57rnnnHoPnp6eNDY24ubmBkBpaSkhISGd+BRctEW30wAQAq3QIIA6tM018bsbDdXg7gd6lwbwZ+XgwYMcPnzY+nrHjh307NkTLy8vbr75ZmbPnm2tx280GtvsDVxUVMQdd9zB7NmzW628n3nmGWs56PYYPXo01113Ha+99hqTJ0/mq6++orCwEFATekZG263CJ0yYwCeffAKo6qZffPEFkyZN6vD9u+iY7rf0NQsAgHpLUxjPU9KO+MyisQp8IsBkdGkAf1Kqq6u55557KC8vR6fT0atXL+bPnw+oifvxxx9nwIAB+Pr64unpyfXXX2+t6W8pI93U1IROp+O6667jvvvuO6HxPPTQQwwZMoRHHnmEp59+milTpmAymdDr9bz11lv07NkTgJSUFDQa9Ru98soree2117j99tt5/fXXkVIya9Ysh81rXHSeblcO+ugll7IiYDDltRsxDdvPg7N+hPB+XTTCPxCvD4GoVKgtgcYauOWX0z2iPx2uctAuTgeuctDtIUBrbgrTILXdtytYY7XZCezpMgG5cNFN6X4CANCZ7ZiNJk3LuvjdiYYqcPdVPgBXJrALF92SbicABMLq+GiUuu6pAZiM0FTr0gBcuOjmOCUAhBDThBAHhRBpQoiHHezvI4RYL4RoEEI8YLcv3dz8fYcQYovN9iAhxHIhxGHz46nxxAqBzhzI0Ci7aV9gi9Bz9wWdu8sJ7MJFN6VDASCE0AJvAecB/YCZQgh7r2kp8Ffg5TYuM0lKmWrnhHgY+FVKmQT8an598hECPcrxbTB2Ux+ARei5+4DepQG4cNFdcUYDGAGkSSmPSikbgc+Bi2wPkFIWSik3A02duPdFwIfm5x8CF3fi3OPHRgAYjW7d0wdgEXqWTGCXBuDCRbfEGQEQDdjmh2ebtzmLBJYJIbYKIW6z2R4upcwDMD+GOTpZCHGbEGKLEGJLUVFRJ27bBkKgR5W1lUb3bqoBmIWeu6/SAKQRjJ2R3S7+KJyuctCW8hKpqam4ubkxcOBAUlNTefjhzin6N9xwA1999VWnznHhPM4kgjkqutGZ5IGzpJS5QogwYLkQ4oCUcpWzJ0sp5wPzQeUBdOK+jhHgJs1fZKNb9/QBWASARQMAZQbS6k/fmFx0OaezHLSlvASoGv8rVqxwlW84A3FGA8gGbAt4xwC5zt5ASplrfiwEvkWZlAAKhBCRAObHQmeveSIIBG5CCQBh1HdPDaDRzgcArlDQPyFnUjloCxdffDFDhw6lf//+1qxkUIXrHn30UQYNGsSoUaMoKCiw7lu1ahVjxowhISHBpQ10Mc5oAJuBJCFEPJADXA1c48zFhRDegEZKWWV+PgV4yrz7B+B64Hnz4/edHPtxo5cGNT6Drnv6ABrsfADgagpzksl/9lka9ndtOWj3vn2IeOSRNvefSeWgLbz33nsEBQVRV1fH8OHDueyyywgODqampoZRo0bxzDPP8Pe//5133nmHxx57DFCCbM2aNRw4cIALL7yQyy+//Ljv76IlHWoAUkoDMBtYCuwHvpBS7hVC3CGEuANACBEhhMgG7gMeE0JkCyH8gHBgjRBiJ7AJ+ElKucR86eeBc4UQh4Fzza9PPkKgFwZAh9aoQ9o2R+8uWDUAv2YB4NIA/nScCeWg7Xn99detq/ysrCxrsTo3NzdmzJgBwNChQ0lPT7eec/HFF6PRaOjXr18LzcDFieNUMTgp5WJgsd22eTbP81GmIXsqgUFtXLMEmOz0SLsKIdBK1RVMZzTR0FiNxykfxGnG6gT2UZnA4NIATjLtrdRPJqe7HLQtv//+O7/88gvr16/Hy8uLiRMnWquR6vV6a6VRrVaLwWCwnmcxYUHXCCEXzXS7TGCEQGcygNChM2qo765OYKFVq3+dywfwZ+VMKgcNUFFRQWBgIF5eXhw4cIANGzYc/5tz0SV0y3LQOtmIQI/eaKLWUEPA6R7TqcbSDEYIlwbwJ+ZMKwc9bdo05s2bR0pKCr1792bUqFEn/B5dnBjdUACAVjapxvDGBuqbak73iE49DdXgZnYAujSAPy1Dhw5l3bp1Dvfp9Xqef/55nn/eseutK5u029rzf/75Z4fHVFc3a+KXX3651dFr77OwPc7FidPtTEACgUaaQOjQmgR1hjrobnbFxiqlAYCNBuASAC5cdDe6nQDAYsPU6NAaJfXQ/XIBGqpVFjC0TARz4cJFt6L7CQAAKRFaPRoT1GsE1JWf7hGdWizNYMAmDNTlA3DhorvR/QSAEEgsAsBEvRBQX366R3VqabA1AZl9AC4NwIWLbke3FABIEDo9GmmiVpwmDWDrB1CZd+rvC3ZOYJcG4MJFd6WbCgCJVueOMBmVCehUawA1xfDjvbDz0/aP+2IWbPuo6+9v6wR2+QBcuOi2dEMBgBIAbm4gjdQLzanXAGqK1WN1O/Xvmuph3/ew6Z2uvbeUZg3ALAA0GtC6uoK5gHnz5vHRR2rBMXHiRLZs2dLBGY4pLi5m0qRJpKSkMGLEiE6Hbjpz77i4OIqLi49rfI4YM2ZMl13LlvT0dDw9PUlNTaVfv37MmjWLpqb2S687KoFt/5mkp6czYMCAEx5ftxMAwqwB6N08EEhq5WnQAGpL1GN1O3VNyjPVY/4uqHS6+GrHGOpV/X+LBgAqFNTQ0HX3cPGH5I477mDWrFknfJ23336b8ePHs2vXLr777jvc3Ny6YHQnB0u+Q1v5Eu2d4yyJiYns2LGD3bt3k52dzRdffNGp808m3U4AgBIAbh7K+VmH7tRrAFYB0E6Dm/KM5ueHlnbdva11gPyat+k8ncsEbqiGQ8u6biwuTio1NTVMnz6dQYMGMWDAABYuXAio1fNDDz3EiBEjGDFiBGlpaQDMnTuXl19u2dXVZDJx/fXX89hjj2E0GnnwwQcZPnw4KSkp/Pe//3V4Xzc3N7KzswGIiopqUwC0NT5b7rzzToYNG0b//v154oknWux76aWXWr0HW+bOnct1113H2WefTVJSEu+8o7Tp33//nUmTJnHNNdcwcOBAQBXOA1Vr6MEHH2TAgAEMHDjQOiZH53QWrVbLiBEjyMnJAWDr1q1MmDCBoUOHMnXqVPLyTr1PsBtmAqsoIDdzHfRa6XFmagBl6erRIwAOLYFhN3bNvW2bwVjQuTuXCbzzM1j8APxtL/g7qv3noi1Wf3GI4qyuzTcJifVh3JXJbe5fsmQJUVFR1mJtFRUV1n1+fn5s2rSJjz76iDlz5rBo0aJW5xsMBq699loGDBjAo48+yvz58/H392fz5s00NDRw1llnMWXKFOLj41ucl5iYyHPPPcfw4cO54447jmt8Fp555hmCgoIwGo1MnjyZXbt2kZKS4vR72LVrFxs2bKCmpobBgwczffp0ADZt2sSePXtajf2bb75hx44d7Ny5k+LiYoYPH8748ePbPcdZ6uvr2bhxI6+99hpNTU3cc889fP/994SGhrJw4UIeffRR3nvvveO69vHSDTUAhZunEgB1eJ9GDaAdH0BZunLQplwJR3+HxtquubdtMxgLeic1gIrslo8uzmgGDhzIL7/8wkMPPcTq1avx9/e37ps5c6b1cf369Q7Pv/32262TP8CyZcv46KOPSE1NZeTIkZSUlLQoNgeQk5PDM888w8GDB3n33Xf5+uuvAUhJSaGysmXp9fbGZ+GLL75gyJAhDB48mL1797Jv375OvYeLLroIT09PQkJCmDRpEps2bQJgxIgRDifyNWvWMHPmTLRaLeHh4UyYMIHNmze3e05HHDlyhNTUVIKDg+nRowcpKSkcPHiQPXv2cO6555KamsrTTz9t1ZocYV+Er61tnaVbagBI8PRSJqBGo9dp0ABK1WNDhXK+WmLxbSlLh4CekDwNNs2H9NWQPPXE723bDMaCzsM5DaAqXz1W5pz4OLoZ7a3UTxbJycls3bqVxYsX849//IMpU6bwz3/+E2g5ebQ1kYwZM4YVK1Zw//334+HhgZSSN954g6lT2/4erl27lkGDBhEeHs5PP/3E5MmTKSgoIC4uDj8/vxbHtjc+gGPHjvHyyy+zefNmAgMDueGGG6zVS519D/bbLa+9vb0dHt9euem2zvn222+trTLfffddhg0b1mK/xQeQl5fHxIkT+eGHH4iPj6d///5tCi57goODKSsrs74uLS3tkhab3U8DMDuBPb3VpGswep4+DQDa1gLKMyCwJ8SNVZP1oSWOj3OG0mOQu109t2oANt2g9J7OhYFWmZ3RXemUdnHSyM3NxcvLi7/85S888MADbNu2zbrPYtteuHAho0ePdnj+zTffzPnnn88VV1yBwWBg6tSpvP3229YolkOHDlFT07KYYkpKCitWrCA3N5fw8HBeffVV7r77bq65pnUTwfbGB1BZWYm3tzf+/v4UFBS0KiTnzHv4/vvvqa+vp6SkhN9//53hw4e395Exfvx4Fi5ciNFopKioiFWrVjFixIh2z7nkkkusJbHtJ39bIiMjef7553nuuefo3bs3RUVFVgHQ1NTE3r172zx34sSJfPLJJ1YB9eGHHzJp0qR2x+UM3VADQAkAHy8AjEZ3qO+6cDKnsBUANUVqordFSijLgB6jlX0+cZJyBEvZXMuoMyz/Jxz5De7d2YYPwMO51phWDcAlAP4I7N69mwcffBCNRoNer+ftt9+27mtoaGDkyJGYTCY+++yzNq9x3333UVFRwXXXXceCBQtIT09nyJAhSCkJDQ3lu+++a3F8nz59eOaZZ5g6dSp6vZ7w8HA+//xzHn74YYYMGUJycrMm1N74AAYNGsTgwYPp378/CQkJnHXWWS32O/MeRowYwfTp08nMzOTxxx8nKiqKQ4cOtfl+L7nkEtavX8+gQYMQQvDiiy8SERHBgQNd087z4osvZu7cuWzcuJGvvvqKv/71r1RUVGAwGJgzZw79+/cHlPltzpw5AMTGxrJy5UoOHDhgHdewYcN47rnnTng84o/UYWfYsGHyeGOTLWTefjvG4hIq73yYX96ZS0YfN1733gl/P9JFo3SC+ZOgIktN/ld/Cn2mt9xfWwovxsOUZ2DMbNj+CXx/N9y+GiJTju9+udtg5J0Q2hsWzYG/7QP/aLX/s5lQngV3rmn/Os/FQkMl9LsYrvyw8+PoZuzfv5++ffue7mG0Ii4uji1btnSJCeFMZu7cufj4+PDAAw+c7qGcUhx974QQW6WUrdQTp0xAQohpQoiDQog0IcTDDvb3EUKsF0I0CCEesNkeK4RYIYTYL4TYK4S412bfXCFEjhBih/nv/E69y+NEmMNAPcwaAAa98gGcSkFYWwJh5n+Qo0ggSwRQYJx6TJqiHo83HLQqDxCw+V0oNDvR3O00gI6cwA3VavIHlwbgwsWfhA5NQEIILfAWqnF7NrBZCPGDlHKfzWGlwF+Bi+1ONwD3Sym3CSF8ga1CiOU2574qpXyZU4k5DNTD7AMQBi3oDdBY03JSPJnUlqpJ/dhqxz4ASw6AxTTkEwaRqXB0BUx4sHP3MhmVkEm9FvZ8BVvMYWZudlFAHTmBLeYfrbtLAPzBsW3Q8mdm7ty5p3sIZzzOaAAjgDQp5VEpZSPwOXCR7QFSykIp5WagyW57npRym/l5FbAfiO6SkR8v5iggDx8lADRGrdp+siKBDv8CBpteq4YGVYvHNxy8gtrQAMwCIMDGNxA/DrI3d75kQ00RSBNED4ZRd4LJAHov0Gibj9G5d6wBVJmTVCIHqeemrusY5cKFi9ODMwIgGsiyeZ3NcUziQog4YDCw0WbzbCHELiHEe0KIwDbOu00IsUUIsaWoqJ3M2U7i5adWwBqD2al6MiKBSo7Agstg77fN2ywOYK9g8Al3rAGUpYNnEHjYhM3FTwBjI2RtbH18e1gmbt9IOGuOSixzs9N0dM5oAObrRA9VpSTail6qLoQFV8KXN8CSR1QtI4PjZuMuXLg4vTgjAByFnXTKYC6E8AG+BuZIKS3ZIG8DiUAqkAf829G5Usr5UsphUsphoaGhnbltW4NRUUC+KhFMazS/vZOhAVgSpsqONW9rIQDC2jYBWez/FnqMAqGFY6s6N4ZKGwHgGQAXvqE0AVv0Zh9Ae34QWwEAbZuBsjbC4aWQtVmZmxY/AMdWdm7MLly4OCU4EwaaDcTavI4BnDYCCyH0qMl/gZTyG8t2KWWBzTHvAK3zuE8GZgGgc9MBOrRGQROgPxkaQI1ZY6mwUaDsNYDMDa3PK0tXphZb3H0heojyG3QGWw0AoN+FrY/ReSozkbEJdG0U7qrKVz0EQs1hfJU5wNDWx1kqnd68DJDwan9X5rALF2cozmgAm4EkIUS8EMINuBr4wZmLC5V29z9gv5TyFbt9kTYvLwH2ODfkE8ScB6Ce69AZBSVa7cnRACyre9sJ0FYAeIeqY2xX3iajCsm01wAA4sapcE5LNq8zVOWD0Kh7tYUzjeErc8E3AvzM1j+LYLHHXsAhmh3ILs5oXOWgu5bdu3eTmppKamoqQUFBxMfHk5qayjnnnNOp63zwwQfMnj27y8cHTmgAUkqDEGI2sBTQAu9JKfcKIe4w758nhIgAtgB+gEkIMQfoB6QA1wG7hRA7zJd8REq5GHhRCJGKMielA7d34ftqE0s5aPVCj84kKNRpibDRANJ3bWfVx/9j5jP/Ru/mfvw3q3EkAMxlICwTpKFOJWFZ7P2VuWBqaukAthA/Dta8orSGJCe/RFV54B0G2nb+1S2awvg5PqYqXwkAr2DQurVdDqK2RPkYLELFO7Q5g9iF85iMUHIY/GJOWXRae4XbOoOlHPSTTz5Jbm7uGV8OWqvVdroctFar7fC4gQMHsmPHDkDV+J8xYwaXX3758Q71pOBUHoCUcrGUMllKmSilfMa8bZ6Ucp75eb6UMkZK6SelDDA/r5RSrpFSCillipQy1fy32HzOdVLKgeZ9F0opT1EtVIHFhSE1OrRGKNLqWmgAO5YuoigzncrCdoq1OYOtBmAROpYVsmegeYVMSz+ANQQ0rvX1YkeBRg/pnfADVOWBX2T7x1hqEbUXYVSVC35RyoTmG9m2D6C2RAkJC36R7be+NJlgxbMuM5E9xib1/2is6fjYNnCVgz6zykFbeOqppxg+fDgDBgzgtttus5Z3mDhxovX/kpyczOrVzebe3Nxcpk2bRlJSEn//+99P6P62dMNSEKK54JNGj8YEBR7NFUEbamtI37EVgJryMoJjYtu4kBNYJnZDvbKN+4SqCdLDH7R65QQGpSmE9FLPrUlgDjQANy+IGdY5P0BVPgT0aP+YjtpCStmsAYAyA7UlAGqKWwoA30ioaKd4XEkarHxBhaaOndP+OP/ArPhgPoUZR50/wWRUAkDr1qZfJqxnApNuuK3NS7jKQZ9Z5aAtzJ4921r07rrrrmPRokVccMEFgPrMN23axOLFi3nyySf55ZdfANixYwfbt2/H3d2d3r17c8899xAbewJzk5luWgzO/FTjhsYkKXL3tGoAR7ZsxGgwAFBTUdbGRZykphA0ZhlrcQTXloCXOQXfqgHY5AKUZSibvX8b/9z48ZC3A+pb/1gcUpXXPHG3RUeN4evKVAiqxZHsF9W+CcjbpsSAb2T7JqAKc+cz20gpF80a4wlkqLvKQZ8Z5aDtWbFiBSNHjmTgwIH89ttvLYrAXXrppQAMHTq0RcLe5MmT8ff3x8PDg379+pGRkWF/2eOi+2kAtmj1aBrrKdS7WTWAg+tX4+nrR11VJbXlJygAqosgrJ9q61iRraJ4bE0kFg3A1gRUlq7svlq942vGjVMr5ox10Pu89u9vaFD38+3IBNSBBmBZ7dsKgP25jovT2Za5sBxbW6LGonPgT7G0viz9cwuAFit1k1EJUN+otn0zNUXqO+PuC8G9juuernLQZ0Y5aFvq6+u566672LJlC7GxscydO7fFe3J3V78RrVaLwbwQtd3uaN+J0E01APVPFjo3hMlIoTkKqL66mvSd2+k3/my0Oh01JyIATCalAVji5ltoAGYB4BmkYvttNQBLGei2iBmuyjEcdSK23hJ905EA0HXgA7C/jl+00ghsq5pasPcBWLSPtiKBys2fS3fSABqq1OfU2E4FVqP5B246/h+6qxz0mVUOGrBO9iEhIVRXV7dq/n6q6X4agE0YqFbvhkkaKcAEdeWkbdmAyWigz5jxHNq49sQEQH25+vGG9ga9d7OTs7YUIswx/hqNORnM1gSUDknntn1dvQckT4Gdn8KkR1pmC9vjrACwagBtNIa3hHz62WgAoDQDW3NPYy001doJgKjmazgSbBbBWJGtMobbykOwxWhQZjLNH3T9Yvmc28uQtkz8xuMXAK5y0GdeOeiAgABuvfVWBg4cSFxcXIcC6aQjpfzD/A0dOlSeKNl/+5tMmzpNSinlf/42V7581ZVy5AeDpHwxUX717D/lO7NvkiaTSX7yyN/kl08/dvw3Ktgv5RN+Uu76Uso3R0j5+bVSmkxS/itMyqU21503TspPrlDPCw+qczbMa//aOdvUcStfav+4Pd+q4/J2t39c/l513J5vHO///QW1v6levc7aol4f+LnlcWWZavvWD22uvUdt2/2142u/O0Xtf8JPyuK09sdp4c2RUv7+onPHnkb27dvneEdpuvoflmW0fXLJEXVMznb1velCevbsKYuKirr0mmciTzzxhHzppQ5+I39CHH3vgC3SwZz6B11CnQjNJiAvL0/AQJPBjdLqGjJ37yB59DiEEHgHBJ6YD8CyqvcJUw3UK7LV6thQ33KF7BPefOyer9X4+l3U6nItiBoMSVNh/VvtJ4VZV+5R7V/PogG0VQ+oKk+N2WLDt2oAdo7gWnNijn0UELRtAqqwSXpzxgzUVA9F+yF7U8fHnqlYNACjExoAUmVpu3BxEuh+AsBcDhogIMQXZANTN4ax8MgATEYjvUeNBcDbP5CainLI3grzxjaXOHAWSxkIn3AlAMqzWmbJWvAOa84G3vOVagHZUdQOwIS/Q10pbPlf28dU5akwQk+HdfaasYaBtuMD8LURIj5hyndhHwpqfX82ZiHPQOWzcBQJZGxSY4xXYXZOOYItQqfkFDbw6Woszvb2TEC2pp8T8AM4Ij09/U/fDAZUHkB3awbTWbqlALCEgSYMGojQBKI36vH2rmbcpZcQFp8IgFdAILWVFZgOLIb83bD7y87dxxLZ4x2qBEBtcXM8fAsNIEw5i/N2qJj4gU5mCsYMg8SzYd0byvbuCEvsfkdtJHV2GkBjDRQdbN5vKQNhQaNVr+0FQI0DASdE28lglTlqdRszXI3BkgPRHhYBUJ5xQvbxU4W0jyoxGlQ1VTRKA2gr6sRkUMLb8tyFCydo9X3rgG4qANSH1H/CWegCbiC3Rz+Ce6UzYuKo5jCxgECQktrMXeq8HZ927j41hSpr1zOwOaY/33wtexOQyaC6dWl00NdBsba2mPCQ0jS2fuB4f1Vexw5gaM4EtmgAa1+H/4yGQrPjyzYJzIKjXACLBuAd3HK7b6RjE5AlAiighzIDOSMALELUZGjOIThD8fDwoKSkpOWP0rL6d/cBpCr7YY80KSFhEcwuAeDCCaSUlJSU4OHh4fQ53TMKyIxGI2jy0hBQH06Rr7ZFTwDvgAAAanIO46PzVJN3wV4I7+/cfaoL1epfiGYBkLdTPdprAAC7vlQreq8g599Lj1HKH7D/Rxh9V+v9lXnOjddeA8jaoCag5Y/D1Z8pYWbvR/CLgoJ9LbfVFivTkLtdQo9vpNJw7LHkAPjHQmC8kyYgm5IRpUchKKHjc04TMTExZGdn06KPRWO1igTzbFIJdiWidX6EyQiVheBRD/WVUGRo3cPBhQsHeHh4EBMT4/Tx3U8AQAu1WxfgTmBxBAW6lhVBvQOU3by2ohym3g7r34Sdn8OUfzl3j+rC5snd3/wPyd2hHm0neUs2sLEBBhxHoajwAXBoieN9VfnQy4micUKY+wLXq/yFnG1Kczm8DHYtVCvSVhpAtOp2ZpsMZskBsA/P9IuCgz+3ThyzhID6x0BQvOp14Ci5zJaKHKVZmZqg5CgcX47UKUGv17fOHF3+T1j/H7h9Jbx9Llz6LvS9ouUxebvgyyvhkvmw9DaY/ASMu+/UDdxFt6HbmYBaVAMFfMM88W0Ioli4tyivYBEANQY3SJykom52feG83bnGRgD4RQECig6o+HWPgObjLMfoPKDP+Z1/QyHJygxUZxex1FBlbj3phEPZcn9DvfJDNFTC2Y+riqRL/6H225uS/KKgqaa5UTy0rgNkwTdCmZfsy1eUZ6nr6tyVBtBU03anMQuVOSrTWO+tNICuxmhQ1VZztnb9tQGK0yA4Ub1fgPL01sdYAggCe6oaSZ0NQHDhwkm6nQCwDQMFCI/2RYOGSmNUCxOQl38AADUGPYQPhEFXQ3U+HPvdudtUF6kIH1BlHXwjlVnFM6jlCtkiAJKnqrT/zhKSpB6L7aohVplDS53xAYC5MXxd88TX8yw4Z27zpG1/HYtWY+lfDMq04e0gusQaCmrnCK7IbDaPORsKWpGjzglKgNIujAQqPqzaWL6UCO9NhQVXdHjKcVFyWJV2cPNSJsJyB34My4TvHao+z1qXAHBxcuh+AsAmDBSgZ7yyVzc2RrcwAendPXDTC2o0QcqpmTxVrdx3ft7xPSxlICyTO0CAeaKzXyF7+KvV9oSHj+/9BJsFQEnLolzWsMuOSkFb0LkrDSBni+r8FZIE/S+BGHMavL0AsNSnsb1vbbFjH4Zt5rAt5VnNn0uQeUXckSO4Mhv8o9XxXRkKuuwxOLwc+sxQf7UlXd/L2GhQfg6L0A7o2VKAWrBoAN4hKqTWpQG4OEl0SwFg29G4V0IAEommMRJZq8woDQYj2zPL8NY1UaM1T9g6dxhwGexfpBxz7WEpA2ErACwrZkcmkvEPQHi/43s/gT2VTbzYLr3d2TIQFnQ2GkD0YBXqKQRc/B+Y9FjL9wIQlAiIlpqHbaVTWxzVAzKZlDnHogEE9FDXa88R3FCtNBK/aGVG6apQUCkhaxP0vxgufgt6TTa/ny6eeMszlO/CIrQDerShARSp/6m7n9ICaopaH+PCRRfQTQVAswTw8NRTra/Hry6Cinr1g/9oXQYz/7MCL1FDrfRsPjflSmXLTlve/j1scwAsWAVAJ6J8nEGrV6vhYnsNwNIL2EkfgN5DTa75e5oL2IFarU54sLVj1s1LTd4WwWMyKj+EQx+AxQRkowFUF6g4eIsGoHNXn1F7JiBL2Kl/jBJAXRUKWnJEJdVZtB2LEOvqlbflf2TRAAJ7qgxxk7HlcTXFzRFk3iGOi+65cNEFdEMBQKvkm1ovAwF1YRTWqR/aioOF9BZZeGsbqWm0+YhihqvJ4WDLqoStsC0DYcG/DRNQVxCSrJy3tlTmKVOOs34FnSfkblcrVFsB0O59k5pNQHXlKlrIkQ9A76miimyTwawhoDbNagLj2tcALAX1/KKbwz+7whGctVE9xpoFgEVwd7UGYBGWFvNZQA/1edv7RmqKmj9Hr2D1+gT6Arhw0RZOCQAhxDQhxEEhRJoQopWxWgjRRwixXgjRIIR4wJlzhRBBQojlQojD5scO6hV0EXYaAAC+OgLqwihoqKC20cCW9DL6azLw1jVSU2NTIVOjheRpKjzS6CCBx4JtGQgL7ZmATpTgXmoVa2sOcaYRjC16DxWjDp0TAMVp6vN0VObCFvtkMEsIaICdAHBKAzCbgECFgjpi73cqTNUZsjep3IWQ3uq1ZfKtsVt57/sBXk6Gd86Gr2+Bjf/t3MRcclh9PhYt0PLe7c1ANUXNQsg7VGlKDe2Ujnbh4jjpUAAIIbTAW8B5qEbvM4UQ9gbrUuCvwMudOPdh4FcpZRLwq/n1acE31BeddCO3WsfGY6U0Gk0Mcc9Cp4PG+nqaGmyKpPU+T5lKMm06ENWVw9JHmxu+OzQBnUwNIEmtJC39hKVUsfyhvZ2/hqUngG9Ux8XjLAT3UqGblbmOC8HZYt8ZzDLpWUxAoExZNUVtF7iryAHMPYl9wtsOBZUSFj+gYu6dIWuzKq1hic6yvAd723vGOmXmcveF9DXw89+h0C4Zrj2K05rt/wABcerR3hFsMQFBszA6XZFAhfvh0DLnj6/MVVntJlcBuz8CzmgAI4A0KeVRKWUj8DnQolyllLJQSrkZsF8Wt3fuRcCH5ucfAhcf31voHPZ5AABRMepHVlwbwKpDRbjrNIzzyaVMq2rt11aUNx+cOEkVN7M1A615VSWKWQqz2ZaBsBDcS2kPlsJnXUmIuca6xQxUkqZs44lnO38NS0XQ6CHHcd/DHWsA9vWAKrJUSKybTZelwA4igSqzlVaj1StNrq1Q0OLDavIu3Nc6P2LVy/DzQ82v6yvUcRbzD6hoL6FtPelW5ytBPut7uO13te3gYsdjdUTJ4Wb7PzRrhfYaQG1x88RvEQQnIxJo77fqrz1WvgDf3en8NXd8Cj/dr85zccbjjACIBrJsXmebtzlDe+eGSynzAMyPdmEmCiHEbUKILUKILS1S6o+blmGgAIkJ6sdW0xDK6sPFjIoPILQmjTyN+vG9teb/aLKYfNy8IWFCc2ZrdRFsmq/2bftYrXxsy0BY0HvANQshMqUL3oMdFpuyxcac9qt6tESzOIOlHISz5h+wyUE4bBO73kaVSd9IJRgtZirbEFAL1lDQNsxAFTnK/m8hOMFxKGjGGvMTCZkbm7ebTLBxnvqznJezVR1nKwA0GvU+7CfdqoJms5pvBEQPgwNOCoC6ciWUbAWA3kN9LuU2GkBjjSobbpn4rdqIEwKgscb5qCgpYdnjsOrf7R9XelQJpLaaBdljMe2tfB4O/OTcOS5OG84IAEd5+c4aPk/kXHWwlPOllMOklMNCQ0M7PqHDEYlWI4iP9qNeV0VTQyR3lL3Mjb6b0BjryXFXk83aw7+xr9RG1e99npqkig7C2v9T8fMT/6F+yMd+b1kG4lTgFaQmCkuUyZFfVZSMJbnKGY5HAPhGqho1xU5oAL6RyklcYzaPVWS1bnxvcezaRzRZqMxR9n/b4x2FgmasU856jR4y1zVvL9jdbNbZOE89Zm0GhJrMbXEUf1+d39Kv0/s8yN3muNKpPUXmwnq2JiBoHQpqzQGwMwF1FApqMsJ/RsHvz3U8FlDf34qs9qOopGx2ytt2rWuPihwI7QtRQ+Cb26Go7e5bLk4/zgiAbMD2lxoDOCju3ulzC4QQkQDmxw5qAHQRDkxAoT7ulLlXYmyMYZpmExP3KdtxRg9lx/Rs0HKs4hjSZCLn4H4M8eaV9db3lb0z5Wo4a44y+Wz9sHUS2KkgJFlNnIYGZZ/uzOofVFgnQhWXcxYhlPZRfEgJADdfx43fodmvUJ6lPv/yrJYOYFBJcUGJjsswSKmigPxsCl05CgWVEtLXKlNb9BAlDCxYNaNzYPsCtSrP2qhKS9i31vQObm0CstUAAPpMV4+HOogKA6Ul6r1VAT9b7JPBbLOAoTkktSMfQOYGJUgyN3Q8FlB1l0CZwNrKa6ktaS710VZDH3sqspWD/qqPlYbz+TVdn1DnostwRgBsBpKEEPFCCDfgauAHJ6/f3rk/ANebn18PfO/8sE8AB2GgGo2g0qMO7/pwZujfRV74Jpmjb2e31zokkJo9mqNF6ez8ZQmf//NB5j3wd5ZWjCJnxacqGmjCg+rLPmimUntL05vLQJwqgnspG3PmemVCSOykABh2E1z+Xvs9hh0RkqR8DrUl7ec4BJj7Ab83FV5PVc5jewEAKtQ2e3Pr6Jq6MvW+bDUASySQrSO47JhyNsedBT3HqNBWS7+EI7+psh6Tn1D33/YhZG9R97THXgNoqFLn2GoAoX2U36IjM1DBPtjzDYy6o/VnFNBDaTYWLcY2CxiUYNZ7t45IsufAIvVYuNe5yCSLAIBms409tiG5zggAKZs1O/8YOPdf6jtZfLDjc083e76Gg20UVewKDA0qx+YMo0MBIKU0ALOBpcB+4Asp5V4hxB1CiDsAhBARQohs4D7gMSFEthDCr61zzZd+HjhXCHEYONf8+uTjKAwUqPNtwsPoRWzofjZH9mYuxeh1ekwaT3zq3Ck+UMe2xd8R0iOOxGEjOVjkwecZg8iLuazZdDHkehWN01BxyjSAb/47j58//ay5KNyeb5TpI25s5y4UlAADLu38AEKS1Y++PKtt+z+oVfZfvoFJj0JkqjIROHKIxwxT5gZLzL8FSwion50JCFqGgqavVY89x0KPMUpDyNmiIosyN0Cvs5UfJm6ccgg3VEDsyNbj8A5tueq21lay0QCEgN7nw7GV7Ydp/v6cMpWNnt16X2BPVSPKUubaXgBYnrdnApJSCQChUYKyo8laSji2uvnzc5SNDC0Fq/016ytalwOvr1ChxBbntsXfZZ+lfqYhpQoMWPF0+8dt/C987+B/6Axb3oP5E5ojBc8QnMoDkFIullImSykTpZTPmLfNk1LOMz/Pl1LGSCn9pJQB5ueVbZ1r3l4ipZwspUwyP56ST8ZRFBCAZ1wPGjWNBGZLbl52M5vzN/O33g+iE95IWYtuXw1lebmMuvQqzrv7Pm557lkEcFRvYzIJ69M8mZwCASCl5NCqX9j22y/NzsVdXygzg/spqh9vcUDnbms/xFUIZZaa8CBc+SHctsJxrwLLajx7c8vtlkYw/jYmIEsoqG0oZsZatXoP7W127ArIWA/pq5VwtmhGo+5sNm/YOoAteIeoCc1ivqjOb76nLX3OV3H6R35z/L7zdsH+H1S/BkcakkULspiBLBO9l50AaM8ElL9bTeIDzQXsCve2fSwo31VNIaReo16Xt6UBHAWEalRkn6y29jV4d3LLfBiL0LZoaUEJ6vy2fDpnCkUHzVFj+9vuiw2w8zPY/vHxVYrN26kWI2dYK9PulwncBsN7DmSfm4Y+pSP4v5Fv8tSYp0jIGwzCmyYq8M3Lxzc4hKQRYwDwiu1PRFJvMg6pf+jhssMYTAalBcApEQDVZSXoDfW4VRdjCjCv5gx1nbf/nwiWUFBDveM6QJ0lvL/KScje0nK7ZYVsqwEIoRyxOxaoHy8oDaDnGLXPM0D1S8hYq+z/eq9mG3zyNOUk9wxsFmK2WISZxbltra1kl1wXO0pd48Bide8FV8Izkaqy6JHfYMWzyrcxykHDHlAmKY2+OZy0plhpC25ezcd0VA/owE+AgHHmHEz7lbk9FvPPgMtUSHNbjuDSo8qc4xPeWgMoPqxMcrb+C6sAMLv99J5KwJ3pAiB9tXo0GdoWnsYm1RAKYN2bnb+H5fvZUbXbU0w3FACONYCrR/TgwdnDkCaJz+FYLky4iH1rcxHefmAoRdOUT9iQkWi0Wus5PVMGk592mPVHV3PpD5dy5aIrWeURzJfVF1HmdxLCPe0oylBfJo00UtHkoSYS6Lz9/0QINheFg66pc6TVK0e0Iw1Ao2stWKc9rxKzvrtTTVgVmS3NXz3HqGulLVdmH4uTWqOFS/4LF77puAGNfQKWtbyHnQag1Zl7RSyED85X5qa+F8DR3+HjS5SDePQ9Shg5wjsY+l2k4ucbqluWgbDgFdK+D+DAIiXYQpNVtFVHyWnHVqqJOShBaVRtaQBlx1Rorm9Eaw3AErpqWw3WtsGPhZCkM98ElL5aBTBAc9Mme4oOKE0vKBH2fe+4imtbmEzNn8HJ6GFxAnQ/ASCEwzhUvVZDcq8g4gaGsHdVDmlbCqmtaKRHcjRaaQL0LM3yYHd2c1OTngNSkdLEuo2L0Wl01DbVMu/Tf5GZVcr+7dtO+lvJP9a8mijJz1c/Vu8wteo9Veg9m1d87fkAOkPMMKUy28aeV+aoLGWNtuWxPqFw/svK2fvVzWpbz7Oa9/ccbV6pprdOjOsxCvrOcDwG+wSsqny1WrZN7rMw/GYVPnv+yzBnD1w6H+47AJf9D0beqcxN7THiVmWO2v1FyzIQ1rG0Uw+o9BgU7FElrAHC+qnXbWEyqSixOLP/JaBHO07go2YB4KCns2UCtJ3cK7LVIsQ2AMJSp+pMzQy2fB59Z6j/be52x8dZ2rnOeEUtGCxhxM5QnqG+g+ASAKedNnwAFgZNjqWuqomVnx3EN8iDnn2UycHgnUBAtTeXvr2WzBL1z4xM7o3e3YOCffsZFDqI7y76jmFF6vjdu9ee9LeSd+wodRoVv1+clQFj7oGzH2vdkvFkY/E/dFWZi5jhqkWmbdREhV0OgC0DLlWr6FxzK8swm0olPcY0P++Macy+Imh1gVr9O9IWYkfArb+qidxiutF7wMDL4bznO/bHxI5UpqDN/2tZBsKCd6g5uMBBuKYl2coSkhreT8Xet5UQVrBblSu3OOADYh1rAPUVyvwVlNBaA6ivaO6dYWveseRp2H7/QpLU5GdbBuRMouiAep9x41RwgqPe1aB8OW4+SnAOuAy2fdSigVSH9wBV3tuZvtenEJcAsCM6OYDgaB+a6o30Hx9FeHwinr5+FMf6EVUXiDRI1h5Rk4JWpyeiTx88s+sYFTmK4kNpyLJaGnUmqjNP/he+JCudPI9wqrXeFGRmwpBZMPT6jk/saqwCoKs0AAeO4MrslvZ/e87/txJA8eNbTkC+4WZTRw/Htv62sDcBVeWra50MhIARt6iVe+E+xyYgcJwNfOAnpfFZsqjD+ivh2Va3NIv9P36cevTvoRzCTXUtj7NMVIFmE1B9efMxtlFDtlVoK7JbJ/dZEt+cNQNZQnZPFRb7f9xYZXpsyxGctxMiBqrv1ujZKtpp6wetj1v7Grw1smWJb4v9v9dklwZw2nGQB9BitxAMOz8OLz83+o6JIrZ/Cne+swDZS6Ixaemnc2NrRnN9maYevvjV6kl178Oe35fj5ulJXl8dVNRTW1nR5n1OFENjI1UFuZTogynVB1KSndlqf4sidicTy8TaVRqAX6RK+LIIgJxtapVqmeQc4RMKd6yBC15rve+8l2DGq+03m7fHUg/IXgM4WQy8QlUklSbHGgC0FgD1lZC1QTm0LVgaCxU4cGYaGlVF0+Ck5sQ8SzkO+7Bby0QVlNDcz8HiB7EIgIiBLTWAiuyW9n9oDhKwb1nqiHVvwHMxcGRFx8d2FcdWKTNYYE+ISnXsCDYZVaRVhNmvF5kCCRNV/S/bsM6KHFjxnFrx5+9u3l50QJkvI1PVgqKjhlKnkG4nAGzDQGs2bCT/X08j7QRCr6Fh3PjiWLz83KznhCZ6YxRNTKypYGt68z/9iL96rjlcwsENa+g9ZjzeCWqlmn/k5Dm/SnKywGSi2C2YUrdAKvNzkDZ21sVvvMx3Lz510u7fgt7nKROMo7DO4yVmmBIANSXwxSw1YbUVSWPBL8qxjT7pHPXXGTQaJdBaaACdKK/dWdy8YfC16rkjHwC0DgXN3qwERpyNzyOktxJc9o7gxhr47GpV+nr03c3bLSt2+1wAqwCIb93RzWL/73WOGlNdmTI5Vea21tJ8wpTpoyMNYOVLqi2nNHbOvn4imEwqQsziD4lMVY/2foCSIyoJMHJQ87Zz/6Xe9xKbIsa/Pa0ECLRMtCs6oELELXkXbUUCFafB+9Nhwzz1/zoFdDsBYIkCMpSVkXP//ZQtWED9ng7ipoGEkDik4QhBJfWE7t1CcbVyUK5r2InBS8vGrz/H0NDAgInnEtOrLyYk2Yc6USq4kxRnpqtHN6UBGBsbqCpVE0RTYwPHtm8h58A+jIZ2+hZ0Ff4xcOVHXZt7EDNcOc8+n6lWnld+2PXd1DrCUhCuqV6ZQHxOogAAGH6LsjOH9rEbh0UDsAsFzVyvkr9sM5n1HioyyzYUtK4MProYjq6AC9+AYTc277NqAHZ+gLJjSuNx87bp6Gb2A5RnqKgZSwe14jSVJyGNrTUAIVo2DrJHSvj1KZWENWimKqlyaGnbyWknysqXYO3ralVfuFd9NpaosYAeZkfwjpbnWBzAtgIgMkWF3e5aqEKA83aqPIHRdymtxyIATCblkwnt26zBtmUG2vaBKmS45CF4tT/8MleZmXYuVJFHlmTELkTX5Vf8AyCB/LlPYqysBJ2OqmVL8RzYfuRMYpUX3hn7OJZwKVPTlrE1o4x+PZrIqcnBN3kSdTuOEhQdS2RSbxIz0lntu4j0g7s5CcWfAXMIqFZPhd4fL6OyzZZkZ+EXEkbO/r0YmlQCU3FmBuEJnbB9nylYJrWsjTDj/zpXpK6r8ApWAsBi+jhZPgALwYnwUIYKLbXFO0wV67M362RuUGYJ+65vYf2anZmGBvj4UuVfuOIDpanZ4hulNAZ7R3DpseYVq1UAmDWA8kw1WYbY2Pel2eZt7wMAZXKy2NptKTqoSkenr4ahN8L0V5SvZ+1rysl69mOtzzkRaorh92eV1nTw5+bS5xYBIMy1sOwdwfk7VQSYfX+NcfcrH8yiOSqnxCtIbWuohp2fq9yBiiyVmxPWp7nceVs9LPZ9D73OhfEPqiKTa15tecxfvu7y72D30wCEQNbWUrV0KaH33IP3qFFULlnaygxkj/9/v8WzJh2ApNoa9u84zPpc1RSm/1D1BRow6VyEECT6J1Ls30DpsfQOr9seP/z7WXYud1xorCgzHQIjkEJDqZsye1j8AOk7t1nt3flHzvAknLaIHKRs4oP/AkNvOD1jsJSDsOYAnGQNAFpP/gA6N0iYpGrVWL5PhkaVLNdjdOvjw/ursNeGalj+hIqOuvy91pO/5X5+0a01gNKjzROWZyBo3Zo1gLIMZTMPjFO5GSWHbZLA7DQAUIKiMqe50Y+xSa1u3x4D+bvUxD/jVWV2C+gBSVNUafX2uu4dD4eWqMl/7H3qvuvfVO/Btix5ZGprR3DeTuVb0epbXk/nBhf/R0URZW1UFYE9/FUgQlONMiUVmiOAQvsqDdk7zLEAyN2uBGu/i6DHSJj5GTycBffth3u2wR1rmzWuLqRbCgAAz0GDCL75JnynTqEpK4uG/futh8imJur27EUa1aqmetUqGletZe1gVe+lzjMM3bJFbMjbQLhXOENCk+gr9fRJUA6vnn49KQ00YKytp6JQTR5Gg4HNP35DRaFzVRWrS0s4vGkda7/4hKbGlrXYpZQUZRyj0S8cX3cd9VpP8PChNEf9iNN3bqNH/xQ8fHwpOPoHFQB6D5izs+1ErVOBxQRkzQI+yRpAe/SeppLcLFpA/i61srSvLgrNYbBrXoWNb6tchL4XtH1t+1DQxlo12Vs0ACGU8KvKN1dyNWsAWr0SEsWHW5eBsMW+YdHG/6qxDbwSZm9VeRS2/+NhNymTUke9tzvLgZ9UcMHkf8Idq5UPY+iNLY+xdwRLqQSArfnHlsgUmPqsSga0LFTizBFWx1ZCkXlesWgPQQmqWKQ9+75XwtQSzguqMKNflNIMIwZ0vlCjE3Q7AaD190N4ehL5/HMIrRbfc84BrZbKpc1t7wpeeon0yy8nbeIkCp5/gYJnn8OtZ0+OTOmBQddIaVQ/Bu1ayZacjYwNGErB3x8iftcBqj76BAA3rRu6KLUq3//CszSkpbFz+WJWffIe377wFE31HUfn5BxUX5y6ygr2rfy1xb7ainLqKiuo9g4jyMcNXw8dBr9QSrKzqCoppiQ7k7hBQwhP6NWlGoA0mU5qZFMrPAM7nPwLjh2hquQktUv0ClG2f8vkdio0gLawRPpYSk9byly3pQEArH5ZTVznPtn+tf1jW9rcLR3ZbKOuLLkAdWXQWNVc3dVSDbYiW0VO2ZujLMeAuXxEPax7HeInwCVvq+gte5LOVRP1lvfaH7c9u75sO6u5sVZFF/WZ3txN7i9fw9g5LY+zdwSXZ6i8h7YEAMDI2+HaL5o1BO9glddxbJXSAPximifvoITWGoDF/BM//pT7ubqdAAi66SZ6LVuKe7z6cusCA/EeOYKqJUuQUlK3cydlH3+Cz+TJeAxKoXTBAhrT0wn7x8P0DEmk0rOIuoh4QuoqSNhfzvSvMmnKzcVr5EgqFi/GYO5aFt4jEZDk7tjG0b/NYd0XCwiO6UFpTjbL5r/RwjTUlJeHNLRM3Mk9uA+dmzvhCb3Y8uO3mGziii0lIEo9Qgjw1BPgpafeO5TSnCzSd6kM5LhBQ4hITKI4K4PG+jqrNnMiHFi7knfuurFli8zTiJSSb557glUL3j85N7BE3xTuU87Wrsp0Ph58I5QfxLIqztxgDtF0oJUE9FRF8tx84PL32+7RYD0+ViVqWUwuthFAtvevym8WDoFmARDcSx1flu7Y/g9qnEKjfAXbP1YmtfEPtD0ejVatpo+ucL54WuF++OYW+O1fjvcf+U1pTH3Ob/86Fkdw+hrlKM7bpba3JwAcET9OdaPL26ns/xaC4tVnbZt3kb9bOd0dmehOMt1OAGjc3NDZdRbznTKVxowM6vfuI+/xf6ILCyPqheeJffNNklevIm7h5/hOnEi8fzwlbvkUNNZR5g13LtXhs3IHoffcQ+STc8FgoOyzzwHorYvCv7aeyqAAdtdW0FhbwwV/e5izrvoLB9auZPuSH6nZsJHMW24lbdLZFL3WMn495+A+InslM+KiyykvyCNtc3OjjyJzBFChLhB/LzcCPN2o9AiivqaafSt/wzswiJAecYQnJiFNJg7+83Eyb7BTdY+D3MMHMDQ1kpd2ZtR2qausoLai3BoR1eVYom8K9irbrX0ZilNN7/NUJcrKPBUB5Gj1D8qWPvUZ1ZTF0jOhPfxjlW280py8aAlTtJiAwFwOoqBZU7BUMQ1JUjVysjY5tv+DEkABPZUgXfuayny2mEnaYsgs5Xhd80rH4wfViAlg/4/NvgZbDi5W9nnbMiGOEEKZc/Z+C68OUM5YoVUJdp0hfrxKyCs+2DKqyxoKmt68bd936h592jHTnSS6nQBwhO+554BGQ86999Jw6BART/wTrY8KadQGBOA5SEn/0VGjIaAR34Yg1idNxK+qEe8xowm+7Vbc4uLwmTiRss8/x9TQwOAlRwioaaBMryErxJ+eReV4ZGYzfMYl9IiN5/f357N+zmzq9u/HvW9fShd8irG8HIDG+joK04/iV1hMaEEJAeGRbP7ha6vWUJRxDJ+gYEqadFYNoESvTE7Z+/cQlzIYIQQRCUr1zt25ndqtWzHVnFhscUmW+vEXHHUiqecUUGweT2luDkY7DapLsGTgFu4/vfZ/C73Nq9f1b0JdqWP7v4VhN7aufdQW9qGgRQfVKtg2p8I3QvVOsJQ1sAgAS6ZvQ0XbpTpA+QEOLlb3GPdAx34d33DlC9jxWcdaQFM97PpcaSNNtc2VVS0YDUpzSpra2pHriIvehCs/Vo7fnG3Kzq/36Pg8W3qOUVoPqF4YFuxDQaWEvd+pSCSLxnkKcQkAQBccjNfw4TTl5OA7ZQq+Zzv+4SQHJnPXhJsRCCrHXc2S3hOIfP55hLn0QND1szCWllLyzrv4/7Se3JAGpMmEp68v/Tz8yXnoIY7NuIDei3/D32hiZ89wtk0ahe6eu5G1tZR+sgCA/LRD6rxN28h/9DEGDhxMftohfv/oXb55fi6HN6wltEcc5XVNBHjp8ffUUyD8rePsOUiFt/kEBePl40uZyQAmE3V7O853aI9ic5RRwbEzQwCUZKuEJJPRQHn+SSi9YTH5GOpOr/3fQlg/NfFumq9et6UBdBaLPb88C7K3qhDGhEktj7GEgmZtVLZ+D/P3zeLghbY1AFCagjSpsNWkc50b19i/qeijVS+1f9z+H5Vv4vyXVGmLXQtb7s/aoASmrYO1PbR66Heh8hH8bS9c84Vz59ni4d/cXjXURgDYh4IW7FFlO/pf3Pl7dAEuAWAm4Ior0EdFEf7Yo+0e5x+min0lhIXyWt8LyBLNddu9Ro5E1yuJ4jffBAQ/D28CrYbxf7mZuJdexFRZhcbHh7hX/s0Nn3/HubfdQ3lhPl/+91WKxwyn7OOPMdXUkLVjG0hJZGIybrGx+H6wAC9fP7Yt/p6Kgnz6T5zMWVdfT0VdE/5mDaDA4AbuKoSw58BUQGUwB3v7UuGlbMD1u3dzvNRWVlBXWYEQGgqPnRlNLUqymx1+xVmdKM/rLLYZuWeCBmDpQGZsVNpJZ2obtYclezd/t+pj4BsB0//d8hhLNnDW5mb7P6hVq0VTaMsHAM1RMOOdWP1b7xmuaiTtWth+T4FtHyohFj8RUq5Q9v5qmxbjBxYrc9Lx9Mnwjz7+3h4Jk5QAC7URkl5BSoCWHlM+l0X3qUzpvhce3z1OEJcAMOM/Yzq9fvsVfVj7/+yAME8AYnRKlVyb1hyBIoQgfaKy4x0ZMw0SIsm7qRcDJp6DZ//+JK9bS9xXX+I3bRpavRspk6dy0//NJ7JXb/ZqDDRWVlD25Zek/7oM34Ymejz1JDFvvYmmvoGJ5Y3c+PBTXDrpfAYWVcLBo0iJEgCebpQ3VFHgU0tliMDLr1kb8Kupp9pdD7Gx1O3cddyfT4l5go0bNJjq0hJqyss6OOPkU5KdSVh8IkJorOagLsVSDwjODA0AlB8AlPmnq8Jj9R4q63fDf1SkzxUftI5GsWgAjVWtezlbzEDtaQADLldmlc5OdGfNUQ2Cfm+jY2zJEZVINmSW8n0MvFJpGnu+VvsrctTzhAmOI5ROJuPug1t/a33foHilAax4RpXmuOC10xZg4JQAEEJME0IcFEKkCSEedrBfCCFeN+/fJYQYYt7eWwixw+avUggxx7xvrhAix2ZfB+75MwN3Lz2evnpEtYEeQV6sPNQyPf+HsEG8PfAi3o6bRGJAIkdqmut+aLy9VS2iFtfzYsxVf6GmqpKiISkUvT2P4qoKImJ74pGcjHtCAlEvvgB79lIw81py//4QpR9/Qul99zImdzcBXm4EeOnxdt9BXGEevnXNphApJd7HMkAI6nv3om7X8QsAywq733hlHjsTzEAl2ZmEJ/QiICLCag7qUjSa5onwTNAAQDkxo4YcX//m9vCPBSRMeVrVYbLHtg5SQM+W+0KcEABuXsqs0lmh5R0CI29Tk3ieg+/vto+UkE4111EK66MidnZ9oRyt75+n/AITW01bJx83b1Uwz56gBOU0X/Oqinbq6v9lJ+hQAAghtMBbwHlAP2CmEKKf3WHnAUnmv9uAtwGklAellKlSylRgKFALfGtz3quW/VJKO8/NmUtAmBcVhXVMSA5l3ZESGg2qCJvBaGLl0TJ+6zeJvRUmgtxiSa9MV60i26HnwFQik3pzyFNLWWM9Bq2GxIsvs+73nTyZ6NdfI+JfTxH//fckb9qIqXc/Ht7yCeGHdhJSVczLS35g0h4D09bXUpGpTDSNaWn4FqpOUlXBgRjy82kqKHQ4ho4oyc7E3cubhCHDQYjT7giurSinrqqS4OgeBMf0PDkaADQ7gs8UDUCrV/2UB1zW8bGdIeVKGHG7iml3hIe/KkcBKnvWlrhxatvJ+ozG/FWZYRb+pWVF1Mo81Q40eaqqIGth4JUq+/ndc1UM/6zvT08pkbYISlCZwqF9Yepzp3UozmgAI4A0KeVRKWUj8DlgH7B6EfCRVGwAAoQQkXbHTAaOSClPwlLt1OIf7kV5YS3jk0OpbTSyJUNVBN2ZXU5lvYF7J6sVUWVlEAaTgayqNpJTzAghGHXZ1VRXVXJoqAo3i0lJbXGM35QpBF5xBR69k9H6+FD6+Atk+4QR/MLjJD4xm6DaRj69RE1W+R+qBJqajZtwNxjxCQikoLGWSg83Sjasw3QcOQHFWZkEx/TAzdOLwMhoCo6eXj+AZcIPju1BSGwPyvNzMTQ2dv2NLKr5yawEeiYw8nY4/8W2V+hCNH8G9iag1Jlw707HZSy6Aq8guPozlT/w+TUq6qfoIPzvXBVPP84up2Dg5SoCR5rghkXNNX/OFGJHKf/SFe+37P18GnBGAEQDtjNYtnlbZ4+5GvjMbttss8noPSGEgzq+IIS4TQixRQixpaioncbYp5CAME9qKxoZFu2PXiusZqCVh4rRCLhyWCwDov04lKX+uUfLO24CEZ86jPCEXhRXVeAdGIRfaPsmhzKtB4+OuRURGkqtj45/XK/FZ/qtbOgjMHz3M8bqGmo3bUIXFUl0v4FkHj3Mmt6xLPj0XRY8cl+nahRJKSnJziQkVqn+4fGJp90EVJKjBEBITA+CY3siTSZKc7M7OOs4sAiAk9kL4I+CxQ9gbwI6FcQMVT2cszYqIfC/KarQ3Q0/qX0txhkB132rurQ5MsGcbpLOgQcOtwwPPU04IwAcLQnsZ492jxFCuAEXAl/a7H8bSARSgTzALuzAfBEp50sph0kph4XaJXCdLgLMkUCGiiaG9Qxi1SGllq48VERqbAD+Xnqm9Itgf5ZSmdMr0zu8ptICZgIQ3btfK1+BPRW1jZR5+BH0+Zc8e3c4uZ49iHQfyE/DNWhq6qj4+itqN23Ce8RIzr11Npc/9jQjjW4kaD0oTD/SqeSp2opy6qurCI5VK7/w+ESqS4o7nRFsaOq64l4lWcok5R0YREiMGpd9U5wuwcslAKxYNYB2on1OJv0vhrMfhyO/qkqtNy9TtXsckTCxtanqTOJ01beywxkBkA3Y/sdjAPug646OOQ/YJqW0FrSWUhZIKY1SShPwDsrU9IcgIFwJgPLCWib0DmV/XiUH8ivZlV3OhGQVRXRuv3Ck0QMvrX+HJiALCUOGU9DHjap+HUcrVNSpybRY5nG0Jo2milRMBj+OxmgpT46g6M23MJaX4zViBO5eXvQcmEqvlFQSD2cghIZDG9Y4/X4tDuBg80RrKS9d0Ilw0JKcLN688UqObN3k9DntXi9bmaSEEARGRaPRap0KBa0sLqI8P6/D46wMuExVj9S5ncBo/yREDVY1bty8T/qtmhrq+f3j/7WuPTXufpj5OdzyS/sd4lw4hTMCYDOQJISIN6/krwZ+sDvmB2CWORpoFFAhpbT9lc3Ezvxj5yO4BNjDHwT/UBUKWl5Qy/gkpZU889N+pIQJvdXrPhG+xAZ5IgyhZFQ65/bIrs7m54TDrNJ0HK9fXtuEl5uW5Rk/oxVaDJWDqK4zEeIZwq7JcZiqVOVSrxHNctUjJQV9VTXR8Ykc3LDWaTOQJQTUYgIKi1flBTrjCD60fg3GpiY2fP3ZCZXIto4pO5PgGLXm0Or0BEZGd6gBNNbXsXDuw3z3Uhv1YhzRczSc88SJDPXPw1n3wp3OLxxOhAPrVrF10bekbVrfcocQKhT2VDcH+pPSoddGSmkQQswGlgJa4D0p5V4hxB3m/fOAxcD5QBoq0sdaeEYI4QWcC9iHF7wohEhFmYrSHew/Y9G5afEJcqe8sJZhkXGE+rqz+nAxAV56BkarGHwhBOf2jeDzdH/SvZwTAHuKlQzcUbQDo8mItp3aM+V1TQR46lmesZxRkaNYleZPeW0TEd4RbEnWMDkmBqTELabZFeOZokpa9AgIYd229ZRkZRDSI67DcRVnZ+Lh44uXfwAA7l7eBEZGdUoAHN68Hq1OR/6Rw2Tt3U2PASlOn2uPNQIoptkWHRzbk8IOxrPqk/epLFJKaHVZKT6BrknkeDEZjTQ1NODudXKcmPtW/QZAaa5z2vOJUJRxjI3ffmEtpw6QNOosRptNsn9mnMoDkFIullImSykTpZTPmLfNM0/+mKN/7jbvHyil3GJzbq2UMlhKWWF3zevMx6ZIKS+00xjOeALCvCgvqEMIwYRkteoflxSKVtNs25vSPxxDfTDFdUXUNtV2eM29JapUQ01TDYfL2y/jXF7bhLdPJZlVmYyLGUeglxvldU1EekeSV19AzJtvEP1qy0JabnE90fj6El5RA0JwaONa6770ndtY+cl7LfoKWyjJaja3WAiL7+W0I7iisICi9KOMuvRqvPwD2PT9lx2f1A6Wlb7FJwHKGVxemE9Tg+NS25l7drJz+WJ6pqj0/Ky97edEdIWW4gxSSo5u2+ywllFtRfkpG0dn2fT9V/zv3ltPSuRVRWE+2fvUYqgk5yQ49s2U5GTxwyvP8tHf7+HYjq34hYXjHx6ByWRi03df0VjX8W/2j44rE/g4UbkAtUgprQJgfFLLbL4RcUEMCFPV/z7fvqPDa+4t2Uu4l3I2bi/cTpPR1OYEUFHXiPBUVTlHR43G31OvNACvCPJr8nHv3RvPlJarbKHR4DlwIIZVq4kICuXQOtW3tCQ7ix/+/SxbfvyGXb8uaXGOfQSQhfCEXlQVFzmVEWypZNr7rPEMOe9CMnZt75T/wB5LTSKLCQjM5ikpKXUwYTTW1bJ03msERkZx4f2P4O7tTeae1gJASsmx7Vv46O/38NGDs497fJ3h2PYtfPvCk+z9/ZcW2yuLi5h/943s/m3pKRlHZ8nYvZ26ygoy9+487mtUlRSz69cl/Pb+f6mrqrRu37d6BQBRyX1brMq7ksb6Or548h9k7NrBqMtmcuub73Hxg49z0QOPMeX2ezA0NnBo4zqnrlWSk8WBdas6PvAMxCUAjpOAcC8aag3U1zQxtX8Ecy/oxwWDoloco9EIHp86AYAXf1vDtsy2J0ujycj+kv1Mip1EuFc4W/O3cc4rK3nzN8er7Iq6Jhr1B4jwjiDeL54ALz3ltY1E+kTSYGygrMHxvULuvgtdYCBBO/dSkpvD7jl/5Yd/P43ew4Oo5L6sWvCBtbk8QHVZCQ21NS1W26D6DYDqEWDL0aJqxr7wG9llzauntC3rCYntSWBEFIOmnI+bpyebv/+qzc/ClvqaajZ++wXv/vUWfvj3s1QWF1ojgHwCm6snWsbnyBG8ZuHHVBYXMfWOObh5eBLbbyBZdhNXaW42Xz71CN88P5fS3GyKszKoLi1xaownwp7flwPKRGbL4Y3rMDY1sW/VipM+hs5iMhqtjYZsy5SD8gstnfdau02PSnKy+OihvzL/rhtYPv9Nti/5kaXzXkdKiZSSfat+I7Z/CnGDhlBZVNimVncibFv8A7UV5Vz2yJOcdeW1eJir/wJEJvUhICKS/at/c+paaxd+zE+vv3TyypKfRFwC4DgJiFC2z6LMKtx0Gm44Kx4PfWubfXKwilTw8y3nlg+3kFXqWK1Mr0yn1lDLgJABDAkbwobcLWSU1LA5w/FEXlbbQAX7GB05GiGEEgB1SgMAyK9x3HrSa+hQEn78gRH/9wYAK7IOU5abw/l/fZBpd/8No8HAkscfJn3mNTTl5FhLQFtCLS2E9ogjMqk3u35Z0kJL2Z5ZTnZZHdsyywFVRC5n/z56DVeliz28fRh07vkc2rCWsrwch2MEtRpf9+UC3rn7RtZ8/hE+gcEc27mV9++7k8Ob1rUySQWER6LV61sJgPrqanb/uowBE88huo9KYI/tP4iKwgJru06AJW//H0UZxzj7xtu59GHVQetEtBRnqK2s4MiWTejc3cncvZOG2uZy3Yc3qdVnzsF9p0QQdYbirAwMDQ24eXpxZMvGFmbDNZ9/xJ4Vy1nx4XyH55pMRpb851WqiosYf+2NXP/Sm0y47maObNnArl9+JvfQAcrz8+g3/myCopWGV5rb9vfkeKirqmTzD1+TOGwkUcmtY/GFEPQdO4nMvbs77DZnMhnJ2rsbpGT9NwvbPfZMxCUAjpPopADcPLQc3tJ+aQVvvTfBHsGc1UdS32Tk+SUHHB5nsf/3D+5PalgqFU3FCF05hwuqMJgMXPnjlby4+UVATY6VpmMYqGVM1BgA/D3drE5ggLya9l0qwcNHEN2nH006Lcm5JXj9vgb/oBAG+ASQWZzPwexjLL39Rpb+51WERkNwbOvkn5RzzqM0N5ucA81lpnPLVaejY0VqMju6dRNSmug1vLl08ZDzL0Lv4c7iN15uMzfg6LbNrP/qM3oMSOW6F17n6idf4MZ/v01cymBqK8oJ7dkyBFCj1RIWn8iRLRtaZDrvXfkrhsYGBk9rbrZhcUBb/AB5hw+Sd+gAo6+4lsHTLiCiV1Knyl2U5ubw+0fvturdbEtxVgbfvfSvFiGoB9auxGQ0MOEvN2MyGji6XbnOasrLyDm4j96jx4GUTpsibHHky+kq8g4fBGD4hZdRW1FOXpp6XZ6fR/rObfiHhbP7t2UtfEwWti3+gfy0Q5x90x0Mv/AyQnrEMfT8i+iZMpjfP/of67/6FJ27O8kjxxAcrWoLtWcGMhoMGJqaOuUr2fT9VzTW1zH2quvaPKbfuEkgJfvX/N7utYrSj6kcmZgeHNqw5g+nBbgEwHGic9OSOCSMI9sKMTS2X1qhh18PypryuOmseH7alcfe3GZ/eE2DgTs/2cqSw5vx1HkS7x9Pgu8AAHz8ssirqOebQz+yv3Q/n+3/jKzKLOqbTEjPg4BgZORIAAK89FTUNVp9CG1pALaMu+ZGzrrqOgafNZHiN9/k2CWXEvn7egK9fdkTFcxBbzc8CoqYMeu2FhVGARqzcwjauBU3Dw92/dLsN8itMAuAYtWV6fDm9fiGhFpDRwF8AoOYduffyD9ymN8drBRNRiOrFrxPYGQ0M+Y8RFic8qP4hYZx0QOPce2zr3LWVX9pdd7wGZdSlpdrtcdKKdm5fDGRyX2s1wCVz+DlH0CmWQBs+/kH3Dy9GDBRlQt28/AkKCqGwnTnNIBVC95n60/fsfEbx3XjG2pr+P7lpzmyZSM//+dVa3vPPb//Qlh8IinnTMXLP8BqTjmyZSNIychLr7JOLJ2htrKCD+6/i+9eerpdJ+2uX5ew+7dlbe5vi7zDB/H08yd16nQ0Wq113Dt/+Rmh0XDlE88RkZjE8v++QWVxc/Z+WX4uaxd+QsLQEfQZM966XWg0nHf3feg9PMjYtZ2kEWNw8/QiIDIaITRtCoCa8jLm3X4dr/3lEl6ZeSGvX3+FNXqoLapKi9mxZBH9xk5sNwIuICKSqOS+7Fv1W7vCJWP3DgBmzHkINw+PE9ICasrL2PDNwlbmM6PBwKbvv6Khtuud0i4BcAIkj4ygqd7IsV3tq4k9fHuQWZnJreMT8PPQ8cqy5paKj3+/h5/35LMmcztJAX3QarTsPuaFNLrTL7EUMDJ/13zi/ePRaXS8vfNtyusa0XofJsIjkUAPVUEjwFNPk1HiofHHTeNGQU1BG6NpJrp3X0ZdehVR/3oK7zFjaMrMJObll7n46ZcZO/N6rrvvUUYX18DTz9NwtLmqqamujuy776bi/Q+IzC7g4JqVlO9SNvWccvXlPVZcQ31NNZm7dtBr+KhWmc1JI8cw7IJL2bn8Z/baNb3fs2I5pTlZjLvmerS61pHKEYlJePr6tdrea/goQnvEseHrzzEZjWTu2UlZXg6p57YsNCuEUH6APTupKinm0IY1DDx7Cm6ezSGN4fGJTmkAJTlZHNmyAQ8fXzb/8HWrXAQpJUv+8yqVRYUMOe9Ccg/uY+ui7yhMP0pR+lEGTDwHjUZL4rCRHNu+BUNjI4c2riUgIpKQ2J70Hj2uU2Ygo8HAolefp7wgnyNbNvDDK886FAINtTX8/uG7rPtyQacjjfIOHyAyqTce3j7E9k8hbctGmhob2LNiOb2Gj8IvJIzz//ogRqORRa8+z57ffyH7wF6W//cNNFot59xyV6vvg3dAINPumoNGqyPl7KkA6PR6/MPDHTr2ATZ8s5CG2hpGX34Noy65Eu+AADb/+E2772fD159jMpkYc+W1Hb7PfuMnUZKdSWF626VcMvfsJDimByGxPRk87cLj1gKkycTiN15i7cKP2bLo2xb7dv26hNWffkD2/uPv59EWLgFwAkQnBeAd4M6hTe1Ptj39elJUV4Re18TtExL59UAh2zLL+HprNt9sy+Hi1HBM+hzKyyKQUvL11ly8ZCI14jA6v50U1GVz75B7mdlnJouOLmJL3g60npn09W8u2xvgpfoTVNQbiPCO6NAEZIvQ64n97zx6/fYr/jOmExQVzciLryBs5Gh6fvQRAJk330xTbi5SSvLnPknDoUNEvfQSAydNwYRk3ew7qduzl7zyOpAS45GdfPjAbAyGJvqMmeDwvuNmXk9sv4H88u5/OLxpHVJKGuvrWPflAqJ692thNnLqfWg0jL78GsrycjiwbhU7ly3Gw9eP5FFjWx3bY8AgqstKWfHBfKRJMnjajBb7wxN6OdX3YOuib9Hp3bj6yRdw8/Rk+TtvtTC/bP7ha9I2b2D8tTcx8fpb6TV8NGsXfsyazz5Eq9PRZ+xEAJKGj6apvo7DG9eStXcXSSPPQgihxt4JM9CKD/5L1r7dTL3zXs69bTbHtm9xKAT2rvyVpoZ6qktLWvhCOqK+uprS3GyiklSf217DRlGWm83GbxZSX11F6hTVdSswIoopt82mMOMoS9/+PxY+8RBZ+3Yz4bqb8A1yXPs+YfBw7vngC2L6DbBuC4qOpcSBBlBRmM+uX5YwcNIUxlxxDWdddR3DZlxKcWY6BUcch1A31Nawd+WvDJh4Dv5hHRf3Sx49Dq1O1ypCy4KhsZGc/XutDZiGTr9IaQFff97hte3Z/OM3ZO7ZhV9oOJt//MZaZqWhtob1X35KbL+BJAzp+mIJLgFwAgiNIHl4OJl7SqirblvV7uGnHKiZVZncMCaOEB83/vn9Hh7/fg8j4oO49RxvhMbAwUx/5q08yoH8KoaGDyaz6igeYcsJ0MVxduzZ3DTgJrz0Xry0/VGEMDE4pPkL4e+pShWU1zYS4R3hlAmoxXvR69E5qLXknhBPj3ffwVRdTeZNN1Py3/9S8f33hNx1F/4XzKD3Y48TEZ9IZog/m154hpAjq7mkYBGTcn9G7+3DzKdeJCq5j4M7Krv99Hv/jn9YOD/8+1k+/+ff+fV/b1NTXsaEv9zYYT0kR1i0gLULPyZtywYGTDwHnVvrMg6xZj/A4U3r6DV8VKsJwWKyaq/7WU15GftW/Ub/iZMJjunB+GtvJOfAXnavWE7mnp0snfcaaz77iN6jxzHk/AtVcuBts3Hz8ubYjq0kDhuFp4+veTyDcPP05PeP/4fJaCRphBJ+wTGxTpuBti9dxM7lPzP8wsvoN24SKZOnWYXA0nmvWY+TUrJj2WJrIpytD6cj8s32/sgk1eErcZgyQW787ksCo2KI7d8cetznrAnc88GX3PTafC59eC4X3PcPBppX921h/78Kjo6lLC+3VQXbdV9+ikajYdTlV9vcbzw6N/c2zVqHNq7F2NTEgEnOtaT09PElefQ4ti/5kV/+93YrH0/uoQMYmhrpYRYAnr5+DDlPaQGOwozbIv/IYdYu/JjkkWdx6T/mYmhsYIPZlLTx2y+oq65iwnU3H9fvoSNcAuAESR4ZgckkSWvHGdzD1ywAKjPxdtdx58Re7MmpxF2n4fWrB3OwbD8AUZ5JvLDkAG46DVcOGI9EIvRlBDdOV5E+HgHM6jeLssYipEnP4IhU6z2sGoDZEZxf2zkB0B4effsSO+9tmvLzKfq/1/AeN46Qu++y7k8970Jq9Fq2NFYyrHgD4cYyVgadRf87nnAYZWGLd0Ags158g3Nvm01lUQH7Vv1G8sizOjyvLSxaQGVRIdJkYtA55zk8LiA8Et9gJfCGnN+6S1VYnLncRTsCYNvPP2A0Ghk64xIAc6RRf5bPf4Mv//UohzasYcCkc5hyx1+tP14vP3+m3HYPQmhIOWea9Vo6vZ741GHUVpTjExxCRGJzG8GOzEBNDfX88u5/+O29eSQMGc7YmbOs+1ImT2PMlddyYO1KqxDJ3L2Tstxsxs68Hg8fX7L3t6zC8vKSA9w5/zfy0g5yeNM6ijKazX+5hw+CEEQkqpLnvsEhhCckgZQMOue8VpOUVqcjMCKK+MHDSDZrNZ0hKDpW9XwuaP4+F2ems2/1ClKnzWihTbh7edN79FgOrFvpMAx1/+rfCYiIJKJXcqt9bTHl9r8ydPrF7Fz2Ewv+8bcWn0Xmnh0IjYaYvs0ay4iLryAgIpLl899wKny1sb6OxW+8hHdAEOfedg/B0bEMnDSFnct/JnPPTrYt/p5+4yZZ6291NS4BcIKExPgQHO3NoU1tT7i2GgDAtSN7cOmQaN66ZggR/h7sKd6Dr96XFy5U3bam9AtnZHQqOqHDR/SgsCDJeq3r+l2Hp9YXY00ioTaxyxYBUF6nBEBhbWGHjWg6g9fQocS89Sa+U6cS9eILCE3zV6ff+LOZOfcFxhdUE5fVSMDNz7DLP4X0sjqnrq3RakmZPI2bXpvPtLv+xuRb7ur4pHboNXwUEYlJ9Bo+ioAI+7YUCiEEfcZOoGfKYKL79G+1393Li8DIqDY1gMa6WnYuX0zSiNEERqj8D6HRMPXOexkw6VxmzHmIO+Z/wpTb/4qbh2er8d31v0+tpgPb7QBJI0a3mCgtZqBN33/Vyr5dlHGMBY/cx87lixk64xIuuO8RNHYlREZefCXhCb345X9vU1tZwY5li/D09aP36HFE9+nfSgDkL1lAr19f4dNH7+eHfz/Lgkf+ZhWEeWkHCYnt2cJf0nfsRDx8fOk/4Th67nZAUJQ5Esim1PeahZ/g5uHJiIsub3X8gEnn0lhXx0E7jamqpJisfbvpO3ZSp4SQTq9n4qxbuOyRp6ivruLzJ/5u9Q1l7t5JZK/eLcph6N09mHLbPZQX5LH2iwUdXn/VJ+9Tlp/HebPvs+YijL58Jhqtlm+eewKh0TL26lkdXOX4cQmALiB5RAT5Rys5vLnAoQPKW+9NiGeItSich17LK1emMqaXWr3sLdlLv5B+jE4M4f0bhvPY9H546b14ZuwzTA2dQ255PTUNajL3dfPl0ojnqc+/lABPvfUeAVYTkBIAJmmiuK5953Rn8TnrLGJe+z90gS1bNwghiOrbn6ZLZ9GvNItReXvQawVHi2taHFdQ2f6KSO/uQf8Jk1tFHHUWodFw1ZMvMmNO+20Ax19zA5c/+q82J4S2yl2YjEZ+e/+/NNTUMPyClp25AiOimHrHvfQePQ69m3ub9/bw9mm1LXHoSHqPHme1o1sIjokldeoMti/5kU3fNZfR2LNiOQsevY/6mmoue/RfTLzuZnR6vf1l0Wi1TL1zDg01Nfz0+ksc2bKJgWdPQefmRkyffpTn51Fdppoa1ddUE5q/i2OePTn33ke4+skX8fT146fXXqChtpb8wwet5h8LQ867gNve/qBFMlVXYcn2tkQC5R0+yJEtGxh+waUOAwGi+/QnMDK6lRnowNqVICV9x008rnHEDRrCtc++ioePL18/+09yDx0g/8hhq/nHltj+KaScM41tP31vDZF1hKU8ydDzLyK2X3PfAp+gYIZOvwijwcCwCy7BN/jk9Qt2CYAuoO+YSIKivFn2v7189fwWMveWUJZfQ1FWFSU5KhzSEglkT3VjNYfKDtE/WK1CJ/UJI8Jf9RFIKBxMcn44Axq0bNmQS2O9EgIaQxhakz9ebs0rvWYNoJFIb7Xq7awf4ERJGzKBLJ9QvD56h7hAT2suAMC+3EpGPfdrqx7KJwudXu8wgqgzhMcnUllU2KJMQVN9Pd+99C/2rvyV0ZfPbDUZngh6Dw9mzHnIuuq15ewbbqPv2Ims+fwjtv38A8vfeZOl814junc/Zr34BnHmGkdtEdojjtGXzyTTHLY4yBwZZTFfWPwA21esQCeNbAochjauP9F9+nH+Xx+kPD+f7156ivqa6lbvWWg07Qq7E8HS86E0JwspJas/+xAv/wCGTLdvSmgeixAMmHQuuQf3tXAe71+9gsik3lZt7XjwDQ5RCwaNhi+e+gdSmug5YJDDY8dfexPeQUEsffs1h/khtuVJHIU0j7zkSqbc/ldGXHzFcY/XGVwCoAvw9HXjqsdGcPasPtRWNvLjGzv5dO5GvnhmM5//axPbl2XSw6+H1QRky5I9vzAwayKjvVtGylSXNfDbh/sp21jMeXVu7PksjbVfqdVoeV0TAV76FitXD70Wd51G+QC8nEsG62pyq5pYMOB8jMeOMmv3Io4UV5BWpsa8fF8BUsKmY2dWVmt72Pc9qK2s4It/PUL6jm2cc8vdjLmi41DCrkKZl+aQMHQEKz6Yz65fljD8osu57JGnnNaYhl94GbH9U+g34Wz8QlXfirD4RPTuHlYz0O7fl1OsD6LQLZQcswkvtt9ARl12tbVAmyUC6FQRHB1DSU4WGbt3kLV3FyMvuaqVWc2W/hMmo9Fq+fnNVyjNzaYo4xhFmen0HTfphMcSGBnNZY88hc7NDb27B5HJjhcA7l5eTL3tHkqyM1nxQetcl1ULPrCWJ9G7e7Tar3f3YODZU06aYLVwkpp4dj80GkHfMVEkDQ/n2M5ipJTo9Fr2rsph00/H6HF1AsV131HTVIO33puy/Bq2Lcskb703I+UFlK7Qgc3v6tCmfKSEyx8Zxvn/WcssnS95R1QCWUVtE/6erVV9VQ+oiQhvpTafKg1ASkl2VTYHSvdyeFAwlWFjGfbDYnb6/sIlP5iYd848fjenPuzOqWz/YmcQFkdw4bEjBIRF8PVz/6S6pIQL73/Eaq8HSNtVxIqPD3D9U6Nx8zx5PymtTseMOQ+xesEHxPYfSNKIMZ0+/4rHn2mxTaPVEtW7L9n791KUmU5V1lH2BY0BIci28eGMuuwqsvftpjg706GGcjIJjIpl/+rfWPPZR/iFhrVwnjvCOyCQ6ff+neX/fYOP//5XQuPi0Wi1KrO6CwiLS2DmUy9TW1mOVtf6d2ghLnUoIy6+gk3ffUlM3wH0GzcJKSW7flmiTD/TL7aWJzlduARAF6PTa0ka1tw+MCTGh0/nbsRtUywEqEgg96wQlr6zB6GBfWFrSQlKJX0XVJXW4xvkgZSSAxvyiUjwI7yHHyHh3hTWgC6nhsZ6A+V1jQR4tQ5tDPB0o7yuER83H3z1vlYNYM+qHKpK6hl9SWKL47dnlrE/r4prRvZodS0LRpOkvLaRAC8dnx34jC0FW3hh/Au4a5tXJmtz13LnL3eqF0Fwa4DkoQN6bvylkapAD5Yk/sqOrKFoNYLd2arEcVt2d5M0oRFnhmLq4eODf3gEhzasZetP32EyGrn88WeI7t0yQmnFikwaq5rYu7+YwUNObvN4vZs7Z994/K0zHH3uMX0HsHbhx2xd9C1SoyXNrzceeg055c0CQKPRcsnDT1BXVdkiAOBUEBwdQ2NdHQVHDzPtrr859HPYY4kkWz7/DY5u20zCkOEn7FtqMaaYWIJbNEF0zFlX/oXcg/tZ/s6beAcEsnXRtxzbsZUeAwZx1tVtl6I4VbgEwEnGL8STIVN7sPmndKL69WLX5qOU/phPSKwvhRO2sPbQNzxw9k0seTaNvatyGHVxIsVZ1ZTl1TDhGqVe9gr3Ie1QOVFSFZ8rrWkiyr+12hjm587e3EoaDSbCvcPJr8lHSsm2pRnUVjQyYkY8Wr368RZU1nPTB5spq20iIdSbUQnBra4H8P7aY7z020r6pSwhrXIfADsLdzIisjkHYX3uetw0bmiKr6NfRAgPnptK1Ug/Dt18C/d8k03lkoVcUP8d7kKS7+bH4YyvCOibTNBNN6ELUrHojcZGPtj7Ae/ufpfHRz3OBYkXOBzPqSY8LpFDG9fiFxrGpf94kuDo1j/6moJa9MCegyUnXQCcDGLMUVB7V/5KTWR/QkOC0Gs1LSq6gjJLODJXnGwsReGCY3p0yonrExjExX//J8d2bGlVzvxUodFqmf7XB/noob/y1dOPoTML8NQp00+5IHU4vtM9gO7AkKk98Q1259yj11P4vRv+0R7MuGcgP+Z+x6jIUSTG9iBuYAj71uZibDJxYH0eGp2g11Blp00K82FPnVqNrdqQw/68SlJiAlrd56az4skuq+PTjRnE+MaQVp5GaV4NVSX1GA0mCjNVm0iTSXL/FzupM1YSGlTKUz/uw2hynD7/yc6l6Hu+xpHyTB4e9hgCwdaCrS2O2V64nf4hAygpTCIleDgDQgbQKzacuaNuYv+oAWxLkKxL6I9m+oVk+YZRl5VDyQcfkv3Xv1JfV8/1ny7ggm8u4Y3tb2CSJr465Fyp6PZYtjefrW1UUu0M/SeeQ+Kwkcx86iWHk7+UElGhCtrlZP5xzFu2RPRKtjrM0wL6EhfiTXSgZwsN4GRhMknSthYi2/j+AYTH9yIwMoqJ193cKsS1I4QQJAwejl9I2IkO9bjxCQrmwvsfoc9ZE5j14usMnnbBGTH5g0sAnBJ0blrGXpGMZ70fJT45LOk3n23lW8ipzuGiXiqaYeCEaOqqmji0uYBDmwuITwnBw1upuklhvtQI0Pro2Lg1n9TYAO6cmNjqPhN7hzI6IZjXf0tjeNgYsqqy2Lq5ufpoxkEV6vfumqOsSSumf8oyjBGvsb8oi6+2tk63P5hfRYFmKR4ikKojf2PX/r70DurN1sJmAVBnqGN/yX6S/VMwSYgKUM65EB83TH6BrJt+G/89X8uqKwaQ9NQ/eX70jSy7/99EPfccdVu28tWcy9jW9DyV9Q28fc7b3DzwZrYXbqewtv0qqxZe3foqi48utr42mSTP/LSP2z7eyiPfnHjtlIQhw7n4wcfxCXKsIVWV1KMzJ6lWF3V93fpTgc7NjcjkPvgEBbPNGEZ8iDfRAZ5WJ/DJJH1XMUvf2UPGnraDAzx8fLjp/+YTlzr0pI/nZBHTpz/T//oggZHRHR98CnFKAAghpgkhDgoh0oQQrYKrzc3gXzfv3yWEGGKzL10IsVsIsUMIscVme5AQYrkQ4rD5MdD+un8m4geFcPF9gxl9azTbK7Zw/8r78dZ7c3YPlfwV2zcI/1BP1nx5mPrqJnqPak5gSgpX8dUHGxsINwjeunYIbrrW/zohBI+c35fSmkbSMxPQCA07N2dRrDVRojHx1ZI07vxkKy8tPciEfoLD1Rtokg1Exa/mpaWHqKpvWZr5063b0XkfYWbfy7hrXAoLt2QRpO3NrqJdNJnUsXuK92CQBiLdlQfbIgCEEMSHerN6H5gaQsDrAB56LUnhvuzOqeTQ8HBWj/Jl6MqjDN3Uh6DyRxgbPZapPacikSw7spzPntrI6i8Otbk6LK0v5f097/P69tcxSRN1jUbuXLCVd1YfIzHUm4MFVdby1CeLIrNWVS0k+lpjq8+wMxiajKz87CCVJSd/4rVn2p1zmDTncWqaJAkh3sQEelFW22TNPzlZFKQrrSnvSPlJvY8Lx3QoAIQQWuAt4DygHzBTCGHvuj4PSDL/3Qa8bbd/kpQyVUo5zGbbw8CvUsok4Ffz6z8tQgiikwOZmnwutw68lZqmGqbFTcNTZ54wNYIBE6JprDPg4aOnR//mhuVxwd7oNIIcjQk/oyBY37brZmCMPxelRrFgXSkxmlTci32oCtLRq18wPU061h8pIczXg8TEnWiFlvPizqNKt466+hzmfb3feh0pJYvTf0Rv8OAct6nMOSeZQbEBrNvjR52hjgMlSrPYVrANAG+pNJLogGYbcXyIN8XVDRhqksms3U29oZ6B0X7sKt7OLctu4cfzQzgUFsk9Kw8zcMWPFCz9hdg6T3oF9GLDjp2U5taw67dsfvvkACYHQmBtzlokkpzqHLYWbGX2p9tYtq+Af87ox9t/UavF9vIOcg6WcWjziUVKZRwtx4SkPtyNAJNgR0b5cV8ra18pe1bmsHd17gmN6XjwD4ugRKfWYBYTEHDSzUBFGWYBkFbRwZEuTgbOaAAjgDQp5VEpZSPwOWCfhXER8JG5OfwGIEAI4TgHv+U5H5qffwhc7Pyw/9jcnXo3j496nNmDW/ad7TM6EjcPLX1GRaDVNv9r3HQaLkqNZsIopT4WZrRva35gSm+kBNPBYWjRcuEFAQweEoHGIFly02i+u2coizO+Z2r8VP4x8h946T2ZLhpxX13EhgNqwtyaWUqt20YmFl3DmnlZ1JU18MbVg6FBNWLZkLcZUPb/XgG9KKtW5qpI/+b47PgQbwB6eA6lwdjA1oKt9In0oCngc0I9w/n7kP/yr8E3Ux8awfX7llB67z2kTTqb2zb5UZeuQWgg9dweHFiXxy/v78NobNnkZE3OGgLdA/HSefHV/u/Yv7eIO0bGcdPYeJLCfIjy9+D3g22bktZ/d4QVnxzE0NR+P4f2yEuvpFQjSe4TjA7B9gPHn32dbi4rnrH79ORKpJeoxL34EG9izALA3hHclUgpyT2mvsv56ZUn9H9wcXw4IwCiAVsDcbZ5m7PHSGCZEGKrEOI2m2PCpZR5AOZHh14aIcRtQogtQogtRUWnJov0ZKPVaLmy95WEeLZM8fbw1nPtU6MZdXFr+/6/rxzELReqqKDC9Kp2rx8b5MXcC/tzrscgGrS17NCsIrKXCoErPlbJ0owfqWmq4bq+1xHoEcgNyTcRVRKDFsHLH++koLKe97f8isatjN7VKlM0Y08JPYK9+L/Lx2NqCOHzXSsxmozsKNrBkLAh5JbX4e+px9u9WTuxCIApCaNx17qzJmcNhxq/RuNezIXR97L6UDUVPoH0/vF7Zl70LCtmP4PfjBnEfb2JPnm90YQ3ctZlvRh9SSKHNxewzpwIt2hXLvvyylmbu5ZzNBdxZdYcwr4exbVVHkTsUZnXQggm9A5jbVoJjYbW3bEa6wwUZlRhaDCSc6jcmX8byzOW8/jax6k3NNv6K/NrKdSa6N1LaWxpRxw7ng+VHeLan64lu8pxbXtpkqTvKUGjFZTkVFNVeur9CceKa3DTaYjy9yTGbMo7mX6AqtJ6jPVGjumMSKOkKKP977WLrscZAeAoYNteH2/vmLOklENQZqK7hRDjHRzbJlLK+VLKYVLKYaEOyhX/2fDyc0PrwL4P4O6lJyDcq0MNAGDm8FgCKjTURhaxLGsZfiEeePm5kZtWxoL9CxgcNpj+ISr8b6xhGnqTOxITkbWN3P7xVtYU/IxfQwSGYhV1kW5elU7uG05yQAoFDQd4Y80qappqSA1LJbe8zmr/tzA8LojEUG8uSY1nWMQwFh9bzM9ZCzGUD6ehKpFle/MZnRhCiI87fRMjWSxDiXr2GbTDRuNljCW/aRuFVfWkToygd7KGXb9nc/RACXM+38HjPy/GoziQ4BWp+BZFkBG4h32+BVRn11gT5ib2DqW6weAwGig3rdzqW0jvoKEPwMIDC7n/9/v5Lu07nlz/JFJK6muaMFUbKNZJEhMDACjOq2llrjKajMxdN5ddxbv4cO+HDq4ORVlV1FY0knqOijTK3HvqtYBjxTXEBXuh0QhCfNxx02laJIN1Nflm+/82d+VnsPzfXJw6nBEA2dAi4yEGsDdStnmMlNLyWAh8izIpARRYzETmR+fCPro5oT18KWxjpXRoUz47fsmkrqqRoqwq6iob6dE/iIzKDA6XHyaylz9HD+STXZ3NX/o21x/J2FqG1ldyNGQnPQ0G9lX/gNFzJ+OalKWvR78gcg6V0WRufXnd4EkIXS3zt38GwJDwIeSU17Ww/4NyCP96/0R6hfkwNmosxjIdowtmcFXGNei+zyUip5Fz+irFb1RCMHtzK6k0Crj1MRAaRq9Zy+abbuHw6DGE/28OHk1V/PrBXkxGSVrxNs45dD0+Qe7M+tdYVsYvY1efH3H31rF9mSq6d1avEPRawe+HWn+1sg+WodVp6NEviPRdxW12kZJSMn/XfJ7e+DQTYiZw68BbWXR0EQv2L6A4W2kbRj89fgHuCDcNXg2So+Z2mBa+PPQlu4t308O3B98f+Z6KhuaJLrusliH/Ws7qlVkgIPWcHvgGeVgF7qlECQCltWk0gugAT7I76QNQTX1aO44ri+tY+enBFu1Td+0qxIikIdiNcq0k93D5CY2/s/z4xk6+e3Ub1WV/zOitrsAZAbAZSBJCxAsh3ICrgR/sjvkBmGWOBhoFVEgp84QQ3kIIXwAhhDcwBdhjc8715ufXA9+f4HvpFoTH+VFT3kBNRXOBKSklG747wvL39rH2qzQ+eHgty9/bBwLOGTcajdDw6tZXWVb/PcZKDX30A6zRR3XVjWTuLSVlVE8uO3cqnk0+xHrvRWiaGFCfgl+IB4POicXYZCLnoFpJDw8fisakpX+DYGT6ZexeWEaf9EZi3FtnJ1sY2DSSq3b8g4FHJuOv0ZOnMTKuXk/IgRpMRhOjEoKQEjYfKyUnuxGjMBJUlk5w2m58p08n+tG/k3x4IY3lBsbWweSSXng3BTDtlhSKG5qoK02lXLeHuNH+HNtVzJLtv/HBvnmE9fqMhXl3MWfFHCobmzWnnINlRCT6kzg0jOqyBmvRPns+2PMJb2x/gxkJM3hl0ivMHjybs2PP5uUtL7Ntryqg5hPhiRACvzBPgkyihcZRWFvIa9teY1TkKF6Z+Ap1hjq+PNRc0fO3A4WU1jSStqOIiHh/PH3d6DkwmOwDpVabuJSSH3fmklXatfb4LemlbDiqBI3RJMksqSU+1Nu6v7OhoCajieXv7eODh9e2mlS3Lc1gz6ocju5oNuNmHqmgVCe5bWIimVojuUfK280H6Ar2Fu8ltzqX8oJaMveWkHOwnIVPb243DPXPTIcCQEppAGYDS4H9wBdSyr1CiDuEEHeYD1sMHAXSgHcAS0H3cGCNEGInsAn4SUpp6SD+PHCuEOIwcK75tYsOCOupOkgVmtVno9HEbx/tZ+uSDPqdFcnVj49g4MQY6qubiOkdSFRIGKMiR7E2dy0lgcpN81j8s+g0ylZ/ZGshJpMkaUQ4Q4f1Rgi4xW8Od/S7i+p0E3EDQ4hOCkTnrrU6J2N8Y5iUeyUTj15FSt5Y9u8qome9IHRLhUPbtckk2f9jGf5BXsx6dgwhl/XkC+9GjoZqObaxgJ//u4f+4b646zRsOFpC2q5ijmrhwTsGc9s9ktVXnE3QNdcw6IlbCC3cxsgGDxIrkqkTm5GfvM6+Dz7HUD4YkLxc/wgGmvjx23W8s/sdtO7F1NeGsTJrJbMWzyK7Kpv66iaKs6qJ6R1I3MAQEI7NQEeKy3h1y38w1PTCu+JaTCYNGqHh2XHP0tOvJ6t3baJGYyIyXE2a4dG+BJs0bLOJBHphw0s0GBu5vOe9lJaFMCpyFJ/t/4wmowoX/eXQPoJDfsSn1oQmVllSew4IxtBosq6Id2SVc89n27nkP2vZlV1OWxiMrX0dbSGl5K13d/Dv/2wlrbCa3PI6Go0mEkKaBUBMoKfTJiCT0cQvH+zn8OYCmuqN7FmVY93XWG+wtk09uFE9mkwmZGkDmiB3zuoVQo7WRFOdkbL8rhFyjQZTK62uwdjArctu5fblt7N/Uw4IuOhvg/EOcGfRmzvZtcJx8/k/M07lAUgpF0spk6WUiVLKZ8zb5kkp55mfSynl3eb9A6WUW8zbj0opB5n/+lvONe8rkVJOllImmR9LT8Yb/LMR0sMXIWD7skx+nrebT+du5MD6fIbPiGfiX/oQHO3D2CuSuPHFs7jgHlWq9pmxz/DlBV/y3sz/oHfXUpHe3L7y0OYCAiO9CYnxwcNbT0SiP5osP6a7X4GxyUTPgcFo9Rpi+wSSsacEKSUVRXX0yhnBgdAN7J6yh9c8a/nCpwHRaOK7V7e3EgIH1uVRkl3N6EsT8Q3yYGBMAAhIODuacVclk767mNWfHGRIbAA7DhTTWNFIma+G/13xfxgNIfx75+MU1RZRkjKS5V5N6A01BJfsZsZvH1P25ZfE/vclXl35Obd6TSE6NAJ93xr6l45hxYzVvDv5C+qzZ3FeyD/Jrsrngq+v5ImPvwMguncgXn5uhMf5cWxnMaaGZq1qf14lVyx4hcG5o7nxyB0sWJXBJW+tI62wGm+9N/8661/4VIZS6F5KjyA1aQZGeOFjEmw/VsLvBwu57fWPiP56Av7pl3D7+xnMfGcDqX4XUlhXyNKMpews3M1241MkmuftV8sf5ualNyOi69DqNVaB+9mmTLx8CnDTG7h6/gaHkU1V9U2c88pK/vn9nlb7HLHrSCmDiiVjqrXcv2AbB/OVWdFiAgKlARRXN1DvIDrny0Nfcv3P17MqexVGg9E6+Y+6OIH4QSHsXZ1r1WAOby6gqcFIdO9AsvaXUlvZyJZ9RXiYBHFJgSSEeFPho6aizuYDlNSVtJroaxoMjH9xBS8va1mLf032GqqaqkivSGfz2kNE9Qogpncglz80lKikALYtzWy3ofyfEVcm8B8MvZuWqOQACtIrKcuvISjSm3Nv6seIGfEtCn1ptBo05lDSEM8Q+gT1QavTEpHgR9q2QrYvyyTvSAV5aRUkjwi3nhs3MITirGr2rslF564lOknFhvccEExVaT2leTWs//YIQivY1OMn5oyfyoj4IPJ0kr5XJVJf1ch3r2yzOqob6wxs+P4IkYn+1tIWg2L8ee7Sgcwa3ZOUSTGMvTyJo9uLGFOroylHrQDPmdSTxJAQenE39cZa7l95Pz/vO8QvCZFkDvqKNf0XcsOUf7Bl3nf8d9S1xNYUc+7cpTz6diljl32JbJKseGwRusP5xPh58OkqN0oP305EvgZt2l6aNA3cvesm3t72H8LdiinMqGLf9MvJOJjBh+vSuXLeaqINeYzImoF3jZ6/+4dQUFHPZW+vo6bBQP+AAQTVRVDqd5BYc8hkQJjqDFVeUMdNn35PcHYd7kYvrqgYx/yrBxPgpefgsSgS/BN4c9ub3LzsZkxGN842zKTJQ1JUO4DdxXt4ZcfLxPQOJH1PCRV1jWzctZ2JTTn0Cf+J2BC4+cMtLNnTstT3678eJr2klo/WZ7AurWOn9sqfjqJH4IZAk1nLEz8oc5atCSgmyHEuwNaCrTyz4Rn2luzl7l/v5tE3X7VO/kOnxZEySWmgBzcVUFHbxL41uQRFeTPuqiSkSXJ4SwFrNqnxjx4WiUYjSIz3p14rWbzud2YumsnkLyYz/JPhbMnfQk15Awuf2cQPr21n4w9HSd9djDRJ8mvymfb1NB5b+1iLiXvBxgxKKur53+pjFFU1C/Wf038myCOIa8JuRFvuiS5Zfdd0blr6jI6kpryB4qyWpsCS3GpyDp14SZEzFVcxuD8gF907GIly1HWWERcmsHrhYdZ909zpKnl4c/XSngODWf/tEdJ3FRM/KMRaPK7nAFUKYeP3Rzm2s5hhM+IYOvTf9A/py5sz61mwMZOxo6LpG+nH4nm7+fL5LQwcH40E6qqamDE7ySpkhBDMHNFcgTTl7BjKCmpVMTyho0YHt56t8g0u6DuY51dfxnbxGduZhU+ichZdMfwKfNfF8vbKo+RGDGbCjZcyZv2PNGZmEuzhTnLTEdIaevLzJ1lcKyT6EMFZGathYwkbhifh3niEGz7LR1v4Bh5VUTD8UXJkFLU33MrTY+8iOeb/27vv8Kiq9IHj3zMtk0nvpAKhCwktJPQiUsKCgKKguKJrwbaKve5P3FVBVkV0bYjYBRVRUBFBmqAICZ0QEiAkpPeemWTK+f0xQ+gQiuuSnM/z5EnunXNn7jtJ7jv33HPfk8Gw9ImYwgRxgzvwy+J0nuobysP7s1iXVkSCrxcaqaXMO51aTRoQhl8rZwK4KsrELvefidg2nYhYH3L3VKLfW0Vit1CW7cjlkS63UbVJT73BQr7DDaQkumcI5vTh9GsXxNrszxnd+gaq9pr5/MUkri+OAqKoLzFjTViKQTeRB7/YResAD7qEenOgsJoPfs1kYs9wdhwp58lv9vDTjMEY9VoabA7eWn+Qzq28GN3NeWuOtd6OPb2aXL/D+Dk8GWQP5PVyMx5uWoI8j1V5Dfd1xpNbbqZdkCfltQ3sK8rhmaRHiPCK4JPET/jp4Cpy3zWR5ZuCPuwgXRpu5ceicszuGpYsSmXV8t3cWGkg/too0tlDYKQn6VsKyKyuoQPQtr0vAL1b+5OxL5XgPBM+vXzo4NeBtdlr+Sz1MxIzbqc8vw5CTWxbmYV0SOLHtSU5fCUWu4Xlh5YTGxjL5M6TsVjtrFl5mPuq3MnS2Zm/7iBPX92VOmsdG7I3ML79eAbmjmGnyOHd6n8ztKE7XgYv59+3gMw9JTy36QAaIZg3pQc/zd9LeUEdsVdG0P+a9mccoXe5UgngMiQ04rTjbpuiVVsfrnsijorCOtK3FqDVa/AOPDZ80z/UAy9/I9VlFtrEHrtPwdPPSEC4J4d3leDh60avkW3QG5z3KwR7G3lwhHOi7VbRPkydmcCW7w6zd30OUkLnfq0Ibn3q9H2N8QjBoMkdqCiqg/3l+HT0xaBzDj8dcUUIz//QnTE92/J9yj76REVw+4Cu9AruhWdNDq+vOQBAvx7RhAx5vPE5w4H+BzNJeXEB2WUeFMgE9pu70Pue/tTtC8VsL6BPvhu1wp8FwwqJqK9kT8cx9NmziM/NO1id3QWNRnDtPX3xDnSnOLua1F/zuUZTyeZVWdi0zhFPxcZSNhUtYzLD8AlyBwHSvo3o3Fg0Ohj51xh2/nyE7T8dYfD41lRVaDD/4olXaztllT6E1jnHUPcZEskgWcve1FgCon9iacPH9NJcR015Nbtar2D8sKsoX+pJ96SxbO3zOZ4e47nzk2SW3zuQZ5enYDJoeeYvXUgrqObGBVuYt+YA0/q14Z7PtpFxuBI3o5Z+7QLxcdfz2+pMDHbYFv4tIfVR9D9wLb3aFqPx7njCWWS4nzta0yE+TttKhYjn9R/N5Os/xt2rhndHvIuf0Y/YykGUWvdj7FXHGzvm803KZlL3jOVKT396FwtGmQ3YhINniu4nLy+bR6NnUb3BRJDGgc7PiE7v/D37+RdQGLCd9lkTeKXPPDx83fBO8mbN75tpn1JI3Jg2JFwdjbXezuqFKexYfYTv4lfQN7Qveo2e2Umz6ejVmaTFDQwu02AMNNKuxELmz3kUDIxmW8U6LHYLiW0SSfmujID2bmTbMnkl+RVm9p/Z2BW4f3sR39eWoNUI7useSXlBHSFtvdm9NoeCQ5WMuqPbCf8vl7vmlc6UJvMNMRE/znnKfjwhBG1inJ+Gjn7qP6p1jHO574Ro9IYzV2V0M+kZPLkj1z3Zh5ihEfSb2P6c+6PVakicHkOHuGCuGnvsRrjWAR50DPHkp6QAakv6MrXbBAaGD8SkNzE21vmJtn2wZ+M0msfzaN+GPu//ixHTexATbSbPvze/VjjnXv0orAvF731Jj3W/YhjyDPuDtuAuvdjb7U622obgXR1Iu2uMjf/sCQl6vC35tHO0IuygmfKCWmojjVTb2rExdz0FtQXUyhrq3WuwFxroUtqXjnGtcPcyED82Gv8wDzKWZdHFqiUv0o3JM4aySGvBMTqUO18fQmg7H/42sC1FlRBsv5rfazYiJ5XzceyLFEZnc23CWK57KAEvvRdx2ybiE/wBRdZdTHjrV347VMqjozoR4OlG//aBXNc7gvm/ZDD29Y0YM2q5vdbI9SU6Fi5KwWF3sH3NAfK9MhjaaxjP3/wYNl09kdWFDO+besL711BTxuiGOnw2+/LcLzMp9HkOjekwHTS30tGvI1JKdq3JJiDCk5mTHuXRuMfIqd+Of6fX8By0DGmwEdAAhwKTqLJLYgNjWVA3FwcSf4eG1q5P/w7pYHnOm2R7Oi/Crpy/F3N1AxPaTaRfxkTwstJrtLOcs95NS8L4aKwWO+EHY5ncaTKzBs0iQh/FirkpWA9Ukxms5ZaZCXQb35Y2DVoWv7adlQd/IsQUQlhdO6pLLfTq356br7iZrw98zc6inYCz+7MqtxZvBHaHZMPKTHQGDVc/0IPE6TFUFJn5du4O7NbTX2y3O+wkp+xl1TfbTlu65KhDFYd47JfH+D3/9xO6rqRDnrYOVGWdlds/Smq8TnMpqTMA5RR9xrWlbY8gPHxOnI6u+5WRePq60Sm+aTXvg6K8CIryavLrurnrGHl7t1PWX9UlhLfWH0KnEfRrdywpdQzxYminIBLanr5SJzgTmndiIoMTwfhdBkk/ZGJw12Hx0PJFcjYdQrxYmeRLQseBaEYfpCCvhPZLM2mflkerSi/MAYFIm53cu++mh9GXwuDuGA9vw/zPf7E2X0OE5Upy5Abe3Pkmu4p30dWQSOuKrkggomQzB4ffT+S77zDib135ZXEaBwI0fHkwnz77i7DaJQM7BDZ+6h7aMYj7hrXnzfV2fNoH8faRf4KbnWf7v4xGaPBr5cE1M+L4+uVkBmVMYkn7V8kvHUaX0Gu4MeFYvfun/9KF3w/sZlhxCCFmHW1iA0k9XI5haxkLc9ZjMBvY1+4QS/q9gEZoiOlfg2aTjve3PUOEdzDDg0axY1UW29dm0kn2Qkgtf6nqRF7/Q2iMelYnRbIvrwrPCitlebUMv6ULGo2GVoygLquKvj33km3OoiFoIzG5w7C3NZG/7y6G9vNll+Zh8ryyiaiOIsqVAL458A2pZSn4aaeR3s4N7ZFqlryUTNvuQQSYw9jWfRk6/cjG+ALCPKmMOkK3nMH08e6Hp8adKZmPUlpbx3dRq3j82ofQ6rQMSWzL2v2FBKfV0Wb5CIKC+vHhtl14CHjo1zRq6IopxJ/nf3+exWMX4x3t/FudEhHE2roa6g5W0TEugDpqiO4ZhM6g4bs3dpH6Wx7dhjhnRZNSsjJzJV+lf0VqURrjku/Hpz4IavcwYmrMaSfgWZj8EYd2lvB/O2cT0TqIyZ0nU7lbQ9FWG6JaR8I1bYkb2bax/Wtr0lm7v6jxLPtSUglAOYW7p4HILv6nrDd5G4gZ+t+dDhCc3UBvrT9E79Z+eLqd+Cf74a3xZ9jqVPHjonH3MiA0gpzychYlOT9x1tsc/N/oYY2lK+Q4O5XfLqPotblkXj8Z9Hr0YaF0WvAe7TVado0Zj+nFf1A45mE6tmlNm+CBfHvwW3zcfOjdMYbCrQ342gpxLHgZh1ZL4azZRC54j2se6c3e3EreTstj1o+pGHQa+rQ59j4LIXhkVCcGtA/k/uUHsPt/SKgugYGRx2IMivKi34T2bPpSckPXO1kUOB/heZhVWWZGth5JQV0B8za8xdiC3hhtkphrAhk0IoYOBdU8/8oK4vMCqXArI6Hb9Y0zr3Uf0prUXwqZkHc3W94t4Ej1JpCSA0HJHA6V1BzqycQ6Ix33x3Hl9G5s2bOZOT/t59pqAyYfQ+MMeF8m5+Cv68RHf7kbnVZD/SgrOemlTO86lIL5v7NoczmRUZNIC1lPRPXNWIOq+ebAN8zbPo9ewb0IN4/ku135PD4jgZXv7GHXmmyMbWwkua8lqSCpcRKiI5V5rAj4mCnZT7Pog32Ya6wY8hrYELaX3PAfcPO8mqOVZW75awx3vPEeVzgsRBT2wsNhp8xPS2SIB1VmI0lHEqmL+IzF+xeTl9Ubu3DQyaFD52NA56jnP+bneeW7cpaMW0LkFf6EtvMh+ccsOvcPpcpeyb82/4ufj/yMtzaciTV34FEfRKbfXtjUDX//TOLGHDuQA5SUlWNc0ZEr64Y6V+yDtJV2tBIKPbOx+lhgKbi56YkZEkF6YTUfb87ipi5hdA5p+oepplIJQPmf1z3ClwHtA5jU++KTz9EEJvI8+WhzFst25nFT36jGgz+A0GrxvfYavEaNonT+fOozDhH6z382zl625aaHGL7wX0xa8xGVjz7LmB73ohEaHol7hNJleRQCEVlrCJvzEvbycgpnzab2l1/wHDKErmHeRAd6kFFSS/92ARj1p3al9WsXwKo772PmmgDu6Xfq/LcxQ8LZvzkfj129eOVvr/F26n947JfHeMPrDcoqKxm75x48pBere73HN+VFvFfxHkWOQnbFzOFwWWeqCyfwaWx04/MFhHsS1sEXDkC1Zwl7o9aTFbwHv1YmYhseY3lhAYNuvILkT9P57qVtTA/wZPPOco7U60kYH41Wp6GoysK6tCLuGBSNzjX6zM2op12s82zxzRt7sTjpCLcOGMHTvz7EFx6zeMdViTXAGMDTfZ9mT4aJz7dm83tlDdc+1pvtK7PoNiKU99d5seTAEuJD49mdU8FNX7+C9C1mt1sd3dMFBmBPgEAf2odW7qt5ceuLLL16KQatgUh/N9xjf2d3QzlPjLofQ50DL3833Ex6HA7JXZ9q2VidxGvb3qAhZzpjg33IT5fUuudgNbpjDPEn33yIZ359humdnqe2owe1P1ay/PuNzK3/Pyrrq6kvTKS2eDDGGhOBV/iytf02dEkCloPBXU+3wWHUWu2sSM4lZ1kq3uZAUjpWkJZvwt/mIMTdgqmDgR6xPflq3zLs+2ywCBw2yWebM5lW5UbAb+Xk9Co/pVv2YonLadxrXFycTE5OPndDRWmCcW9s4mBRDRseG0qwV9OnOtx4oJhlT7zEbSk/UJx4DYNefR4hBA2ZmaTfeCv5kYMZ9NJtGNtEIRsayLh6PAhB9PJlCL2e135O57WfD/DY6E7cM/Tc10dOpyCjkq/nbKPHiCj6XRPN6qzVfLb3c7onj8W9KIBx9/fAGlrBHT/dgcVuwWwzE+nZln3bpxDsEcCmx4ed0D1hqbVSX2elwq2YqSumYraa+WrcVwS7R1FjsdHKx0hZXi17N+SQnV5ORX4dNg1MnplAq2AP3tlwiNk/7mftw0OIDvI8676Xmkv5ZN8ntPVpS0xQDG2826ARGspqG5j09m9klNTSLdybGcM7MrxLMLO2zmJJ+hLu6Pow727cgcPrN6J9OvB4pznseX8/neJbMXiK8wL2b7m/Mf3n6dzX4z7Gtx/PY788xo6iHTwR/wRTu0w9ZV/qGmxMnL+MXI/nERobUeVXMGa/c87l3UE1VEYGMW5QBrO3zobS8VQX9uWGejN+dh2fd1uApXASDw8djHFzGaWZ1Sz0sTBsYB7ri9/g0dLXqTxox2DSka13oKm24ScdrGj3BTX2GxnTLZTxPcLpGubd+LswN9gYvvABBh/uSmSlc46NBj8r/j0aGDa0F1EhFzahjBBi20nl+J3rVQJQWqqDRdWU11lP6IZpCqvdQZ/nVzNlyxLGZ2wiaMYD+E2ZQuaUG7BXVNDmyy8wRB0b5lq9bh05d99DyFNP4X/zX8mtMHPvZ9uZN6UHrY+78ep8rft0P6m/5ROX2Bprg4PirCpy0ysYfksXOrsmFMquyuaO1XcQ6B7Im8Pf5KfdVXgZdSTGnLlae0ZlBpX1lfQM7nnGNj8k5fCPr3dj9HHjjRt78uiS3QR4GPjqrv4XHA8439tvd+TyxtqDHCmro1u4N9f30/FyynSkq76kn1sgc4bMom9oX2xWe+NIoqMeXv8wG3I24K5zp8HewLP9nmVM9JgzvmZhlYWx77+Dj1clr469ls0vlGC3OahPDOX1zRksv3cAN39/NzZjKjH+fSjJKmZ8yv3khWi4Kj4KyhvYtymP3hOi+bSsjO/3HMGv82yGhg/kLp9HWLw8HWOJFU+d4Lv2b3LdlWO4Lea2M+7PweIqJn1xD+3NRvK9DlHl7ryv440r32Bo5NALel9VAlCUS+jxJbv5MimL1fXrsa5cgT4qClt+PlEfLMQUd+L/mZSS7Ntux7x3L4HT78Q9NhZj165oTKaL2gdLjZVF/9xCXVUDWr0Go4eeHldF0uOqqBPaWe1WtBptY5//pbI7p4J7P99OTrkZKWHOpFiujzt13uQLYbU7+GZHLv9xJQKjqQwhdXxyy1XEtT57VeDC2kImLptImGcYLw95mTY+bc75enUNzgJ2JoOODYvSsNscRIyMYOTcX3DXaxHaWoI6v0VZfRH397yf4LVx5Ox33iCm1TuLCo6+sxtCI3h/02FeTp6D3u93BhjmsXJ3Df8a35VS3bd8mPohqyetJsh09hiW7crimVWfMX1wJwa2bUcrj1YEugc2lnA5XyoBKMollFVay/e787l7QBS5D8ygZt06wua8hM/VV5+2fX1GBjn3/Z2GjAwAhF5P8OOP4zf1xsbTf0taGsWvv4EuOAiP+HhMffqgCww87fMdZbPaQTrvZv0zVJqtPLl0NzuPVLD6oSEnzAdxKRw9I/gyOZu/X9mBwR2bVhK+wlKBh8EDvUZ/Ua8/cu4GDhXXsmBaHO1D6ym1lNIjuAeWGiuluTV4B7nj6euGOOmmzEU7tvLi7tuwFCZyd8/beWB4O0YuGUnngM68OfzNJr22ze5ovJ5ysVQCUJQ/iLRaaThyBLd2p07kczJbWRnm3bupWLSYmg0b8L3uOlr94xkqli2j8PkX0BiNSKsVR52zTIHXiBEEPTgDt2jnRVtps1Gfno4+PBytj0/j85r37KXk3XcwxcXhP23aaYcf/pEcDnlBd6b/r0vNr6LKbCUh+vwvvk5efhOZVYeJC+2B2WYmqSCJV4e+yojWI/6APT07lQAU5X+IdDgonvc6pe++iy4kBFthIR79+xE2Zw5aX18sqalUr1lD+cef4Kivx2fcOGRDPTW//oajshKh1+MxZDDeI0dSvW4d1T+uRBgMyIYG/KZOJeSpJxHa8z8rcNTVUbdjBxqTCVPPE68BVK9bR8OhQ84Eoz/9J+vqn3+m7KOPMURH4x4biym+D4bIS9MtdLnZnLeZedvn4ZDOG8dCTCG8MvQVDNozl03/o6gEoCj/gyq//4HCWbPwm3ojgdOnn3LQtpWWUvLOu5QvXozW1wfPgYPw6JuAJXU/lT98j724BGEyEXDLNPxvvZWSt96m7IMP8Bo5Er+bpmLZswdLSgoeAwbie+01Jzx36QcfUrtxI8JoRGN0w5pfgHnPHrA5+8O9Ro0i5Mkn0Li7U/jii1Quc04D4h7Xm4i5c9GdNENfzcaNZN9zL7rAQBzV1ThqakCnI2rh+3jEn/5+DVtxMeVffYW0OIu2aUwm/G68Aa33mUuHKOdPJQBFuYw5LBaEwYDQHOsTlnY75t27MURFoQs41kVR+sGHFL30UuOy1scHe2UloS++iO81E51t3l9I0b//jaF9O4ROj7RY0Pr4YIqPxxTfB0tKCiVvvwNaLVoPD2xlZQROn46hTWvyn52J1tOTsJdmY0pIQGi11G3bxpHbbsfQti2tP/oQjacnDRkZ5Nx7Hw6LhbbffoPOz++EmKp+/JGCmc9hr6yEo2cUVivuPXsS9f6Ci75IrhyjEoCitCDmnTuxVVTgHhuL1tOT7LvupnbLFiLe/A+OykryHn8Cr8TRhL/88hm7ihpyciicNRtbfj6tnnsO9xhnmQ5LWjo5f/871iNHECYT7l27Ytm/H11AAK0/+/SEZGTZt4/MyVPwGDCAiLffQgiBNTeXwpdfpvrHlRhjYgibPavx+knVT6vIffBBPPr3J/KtNxGGpnWXWAsLOXLLrfhcPY7Au+9u8vskpWzy9RJrYRH2ygqMHZteksFRX0/16p+p+OorLCkpuMfGYIqPx6NfP4yxsf+1azUqAShKC2avqeXItGnUHzqEtNkwxcUROf9dNE08wJ76fDXUrF2LedduZ7eRgIi5c9GHhZ3StuyTTyl84QUCbr8Na1ERVT+sAI2GoHvvIeD22xG6E0cOVXz9NflPP4PXyJH43zIN4eaGxmgE1zBWodOij4xsPHjKhgaypt2CeccOAEJnz8J3woSz7r95zx7yn3oKW2kZ7jExGLvH4jlocGOSO5mttJTD112HraiY0JnP4jtp0jnfo4qvv6Zozr+xV1aij4jAlBCPZW8K9WnOiWrcOnXC76ap+Iwdi8b9j60wqhKAorRwttJSsqbehMZkIurjj9B6nv2O3UtFSknOfX+nZs0ahMmE33XX4X/LNPShZ74Z7eRurJOZ+vUl7IUX0IeFUfDCi5R/8glh/55DxdKl1CVvo/XC9zF2707F4sWUvPceWi9vfCdNwufqcVQs/Ybi119HFxSER0IC5r17aDiUAVJi7B6L/01/xXvUyMazD9nQQNatf8OSkoKxW1fMydsIuOMOgh6cga2oiLqkJBxmM96JiWi9vJwX+OfOpfS9BZji4wm8azqmvn0bu+9s5eXUrFlD2SefUp+WhsbbG8+BA/AYPBj3mBgs+/ZRt3Ur9RmH8ZkwHt+JE09JkufrohKAEGI0MA/QAguklLNPely4Hh8D1AG3SCm3CyEigY+BVoADmC+lnOfaZiZwB3B0luinpJQrzrYfKgEoysVxNDQgNJqLPqCcL3tNDdWrVuN15TC0vr5N2saSlo6tuBhZb8FhseC6ERhbQT4lb70NQuA9biwVi7/Af9rNhDz5JPbKSucd2WVlaDw9sebmYkpIQNbXY965s/G5vRJHEzpzZuNQWntlJZXLv6P8009pyMpCFxyM/7Rp+E6+nsLZs6lc8jXhr76C14gRFDz/AhVffIE2IAB76bHJ5DUmEz4TJmArKaF61Sp8J0+m1T+eOeN7LaXEnJxMxdJvqNm4EXvJsZncNF5e6IKCaMjIwBAdTdCDM/C66qoL7jK64AQghNAC6Tgnbs8BkoAbpJT7jmszBvg7zgSQAMyTUiYIIUKBUFcy8AK2AROklPtcCaBGSvlyU4NQCUBRFHBen8h/8inqkpJw792b1h9+0Dg0teHIETJvnIo+OJighx/Cc8AAACzp6VR9/wNuHTrgPfYvpz2YSoeD2k2bKH1/IXVbtiDc3ZFmMwF3TSd4xgxnGykpX7SIui1bce/ZA4/4eKTdTvmnn1G1YgXSZiP40Ufxv/WWJh+wpcOBJTWV+tRU3Lp0wdi5M2g0VP/8M8VzX6MhI4PwV1/Be8yZS1qczcUkgH7ATCnlKNfykwBSylnHtXkXWC+lXORaTgOGSinzT3quZcB/pJSrVQJQFOViSIeDmvXrMfXqdcpZhWxoAL3+oi6ymvfsoeyDD9B4etFq5rMnjMA6E1tpKbbiYucB/BKRNhtVK1bgnZh4xvsvzuVMCaAp54HhQPZxyzk4P+Wfq0040JgAhBBtgJ7AluPa3SeEuBlIBh6WUjbf2ZcVRbmkhEaD15VXnv6xC7y4fTz3mBjCX331vLbRBQScMArqUhA63RlLjFysphSaOF0KPfm04axthBCewNfADClllWv120A7oAfORPHKaV9ciDuFEMlCiOTi4uLTNVEURVEuQFMSQA5w/L3cEUBeU9sIIfQ4D/6fSSmXHm0gpSyUUtqllA7gPeC0twpKKedLKeOklHFBQU0rBKUoiqKcW1MSQBLQQQjRVghhAKYAy09qsxy4WTj1BSqllPmu0UHvA6lSyhPOpVwXiI+aCOy94CgURVGU83bOawBSSpsQ4j7gJ5zDQBdKKVOEEHe5Hn8HWIFzBNBBnMNAb3VtPgD4K7BHCLHTte7ocM85QogeOLuKMoHplygmRVEUpQnUjWCKoijN3JlGAV3aKYIURVGUy4ZKAIqiKC2USgCKoigtlEoAiqIoLZRKAIqiKC2USgCKoigtlEoAiqIoLZRKAIqiKC2USgCKoigtlEoAiqIoLZRKAIqiKC2USgCKoigtlEoAiqIoLZRKAIqiKC2USgCKoigtlEoAiqIoLZRKAIqiKC2USgCKoigtlEoAiqIoLVSTEoAQYrQQIk0IcVAI8cRpHhdCiNddj+8WQvQ617ZCCH8hxGohxAHXd79LE5KiKIrSFOdMAEIILfAmkAhcAdwghLjipGaJQAfX153A203Y9glgjZSyA7DGtawoiqL8lzTlDCAeOCilzJBSNgCLgfEntRkPfCydfgd8hRCh59h2PPCR6+ePgAkXF4qiKIpyPnRNaBMOZB+3nAMkNKFN+Dm2DZFS5gNIKfOFEMGne3EhxJ04zyoAaoQQaU3Y59MJBEoucNvLlYq5ZVAxtwwXE3Pr061sSgIQp1knm9imKduelZRyPjD/fLY5HSFEspQy7mKf53KiYm4ZVMwtwx8Rc1O6gHKAyOOWI4C8JrY527aFrm4iXN+Lmr7biqIoysVqSgJIAjoIIdoKIQzAFGD5SW2WAze7RgP1BSpd3Ttn23Y5MM318zRg2UXGoiiKopyHc3YBSSltQoj7gJ8ALbBQSpkihLjL9fg7wApgDHAQqANuPdu2rqeeDXwphLgNOAJcd0kjO9VFdyNdhlTMLYOKuWW45DELKc+rS15RFEVpJtSdwIqiKC2USgCKoigtVItIAOcqZXG5E0JECiHWCSFShRApQogHXOubfbkNIYRWCLFDCPG9a7lZxyyE8BVCLBFC7Hf9vvu1gJgfdP1d7xVCLBJCGJtbzEKIhUKIIiHE3uPWnTFGIcSTruNZmhBi1IW+brNPAE0sZXG5swEPSym7AH2Be10xtoRyGw8AqcctN/eY5wErpZSdge44Y2+2MQshwoH7gTgpZTecg0mm0Pxi/hAYfdK608bo+t+eAnR1bfOW6zh33pp9AqBppSwua1LKfCnldtfP1TgPCuE083IbQogI4C/AguNWN9uYhRDewGDgfQApZYOUsoJmHLOLDnAXQugAE857iZpVzFLKX4Cyk1afKcbxwGIpZb2U8jDO0ZfxF/K6LSEBnKlMRbMkhGgD9AS2cFK5DeC05TYuY68BjwGO49Y155ijgWLgA1e31wIhhAfNOGYpZS7wMs6h4vk47zFaRTOO+ThnivGSHdNaQgK46HIUlwshhCfwNTBDSln1Z+/PH0kIMRYoklJu+7P35b9IB/QC3pZS9gRqufy7Ps7K1e89HmgLhAEeQoib/ty9+tNdsmNaS0gATSllcdkTQuhxHvw/k1Iuda1uzuU2BgBXCyEycXbrXSmE+JTmHXMOkCOl3OJaXoIzITTnmK8CDkspi6WUVmAp0J/mHfNRZ4rxkh3TWkICaEopi8uaEELg7BdOlVK+etxDzbbchpTySSllhJSyDc7f6Vop5U0075gLgGwhRCfXquHAPppxzDi7fvoKIUyuv/PhOK9xNeeYjzpTjMuBKUIINyFEW5zzsGy9oFeQUjb7L5xlKtKBQ8DTf/b+/AHxDcR5Crgb2On6GgME4Bw9cMD13f/P3tc/KP6hwPeun5t1zEAPINn1u/4W8GsBMT8H7Af2Ap8Abs0tZmARzmscVpyf8G87W4zA067jWRqQeKGvq0pBKIqitFAtoQtIURRFOQ2VABRFUVoolQAURVFaKJUAFEVRWiiVABRFUVoolQAURVFaKJUAFEVRWqj/BxSbQ8lo44E2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(1-np.array(model1.History_learning), label = 'BNN - ReLU')\n",
    "plt.plot(1-np.array(model2.History_learning), label = 'BNN - Tanh')\n",
    "plt.plot(1-np.array(model3.History_learning), label = 'SGD - ReLU')\n",
    "plt.plot(1-np.array(model4.History_learning), label = 'SGD - Tanh')\n",
    "plt.plot(A, label = 'spike & slab prior - ReLU')\n",
    "plt.plot(B, label = 'spike & slab prior - Tanh')\n",
    "plt.ylim([0, .2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db429e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
