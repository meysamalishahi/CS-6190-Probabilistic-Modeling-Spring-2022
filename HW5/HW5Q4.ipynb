{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e28928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.distributions import Normal as norm\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e45c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45cabe",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5a7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f6c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not exist, download mnist dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, transform=trans, download=True)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24be868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "N = len(mnist_trainset)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3baca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_test = len(mnist_testset)\n",
    "N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fdfbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=mnist_trainset,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=mnist_testset,\n",
    "                batch_size=N_test,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1b7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "FF = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdce4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "Flatten torch.Size([128, 784])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "Flatten torch.Size([128, 784])\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for batch_idx, (example_data, example_targets) in enumerate(train_loader):\n",
    "    c += 1\n",
    "    print(example_data.shape)\n",
    "    print(example_targets.shape)\n",
    "    print(\"Flatten\", FF(example_data).shape)\n",
    "    if c ==2:   \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1471cf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd4d8b",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292fb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(nn.Module):\n",
    "    def __init__(self, mu, rho):\n",
    "        super(Gaussian, self).__init__()\n",
    "        self.norm   = norm(0,1)\n",
    "        self.mu_    = mu\n",
    "        self.rho_   = rho\n",
    "        self.sigma_ = torch.ones(self.mu_.shape).to(device)\n",
    "        \n",
    "        \n",
    "    def sample(self):\n",
    "        self.eps    = 1*self.norm.sample(self.mu_.shape).type(self.mu_.type()).to(device)\n",
    "        self.sigma_ = 1*torch.log(1 + torch.exp(self.rho_)).to(device)\n",
    "        self.W      = self.mu_ + self.sigma_ * self.eps\n",
    "        return self.W\n",
    "            \n",
    "    def loss(self):\n",
    "        return (0.5*self.mu_**2 + 0.5*self.sigma_ - torch.log(1e-20 + self.sigma_)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552d31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blinear(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(Blinear, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.n_input  = n_input\n",
    "        self.n_output = n_output\n",
    "        scale = 1.0/np.sqrt(2*self.n_input)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.mu       = nn.Parameter(scale*torch.randn(n_output, n_input))\n",
    "#         self.rho      = nn.Parameter(scale * torch.ones(n_output, n_input))\n",
    "        \n",
    "#         self.W        = Gaussian(self.mu, self.rho)\n",
    "\n",
    "#         self.b_mu     = nn.Parameter(torch.zeros(n_output))\n",
    "#         self.b_rho    = nn.Parameter(scale * torch.ones(n_output))\n",
    "        \n",
    "#         self.b        = Gaussian(self.b_mu, self.b_rho)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mu    = nn.Parameter(torch.Tensor(n_output, n_input).normal_(0., .05))  # or .01\n",
    "        self.rho   = nn.Parameter(torch.Tensor(n_output, n_input).uniform_(-3., -3.))\n",
    "        \n",
    "        self.W     = Gaussian(self.mu, self.rho)\n",
    "        \n",
    "        self.b_mu  = nn.Parameter(torch.Tensor(n_output).normal_(0., .05))\n",
    "        self.b_rho = nn.Parameter(torch.Tensor(n_output).uniform_(-3., -3.))\n",
    "        \n",
    "        self.b     = Gaussian(self.b_mu, self.b_rho)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        W = self.W.sample()\n",
    "        b = self.b.sample()\n",
    "        \n",
    "        return F.linear(x, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe5bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers, act):\n",
    "        super(BNet, self).__init__()\n",
    "        \n",
    "        self.act = act\n",
    "        self.fc  = nn.ModuleList()\n",
    "        self.flatten = nn.Flatten()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.fc.append(Blinear(layers[i], layers[i+1]))  \n",
    "            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        for i in range(len(self.fc) - 1):\n",
    "            x = self.fc[i].forward(x) #forward based on Blinear \n",
    "            x = self.act(x)\n",
    "            \n",
    "        x = F.log_softmax(self.fc[-1](x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c75b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN():\n",
    "    def __init__(self, train_loader, layers, act, n_epochs = 10000):\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.n_layers = len(layers)\n",
    "        \n",
    "        self.nepochs = n_epochs\n",
    "        self.BNet    = BNet(layers, act)\n",
    "        \n",
    "    def get_neg_elbo(self):\n",
    "        neg_elbo = 0\n",
    "        for i in range(self.n_layers-1):\n",
    "            neg_elbo += self.BNet.fc[i].W.loss()\n",
    "            neg_elbo += self.BNet.fc[i].b.loss()\n",
    "            \n",
    "        p_pred = self.BNet(self.x)\n",
    "        \n",
    "        loss_1 = 0\n",
    "        for i in range(10):\n",
    "            loss_1 += p_pred[self.y == i, i].sum()\n",
    "        loss_1 /= 128\n",
    "        \n",
    "#         return neg_elbo + N/batch_size * F.nll_loss(p_pred, self.y, reduction='mean') \n",
    "        return neg_elbo - N/batch_size * loss_1\n",
    "    \n",
    "    def train(self, lr, decay, step_size = 1000):\n",
    "    \n",
    "        optimizer = torch.optim.Adam(self.BNet.parameters(), lr = lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=decay)\n",
    "        \n",
    "        for n in range(self.nepochs):\n",
    "            for batch_idx, (example_data, example_targets) in enumerate(train_loader):\n",
    "                \n",
    "                self.x = example_data\n",
    "                self.y = example_targets\n",
    "             \n",
    "                loss = self.get_neg_elbo()\n",
    "                if batch_idx %10 == 0:\n",
    "                    print(n, batch_idx)\n",
    "                    with torch.no_grad():\n",
    "                        print(\"Loss = \", loss.item())\n",
    "                        acc = 0\n",
    "                        pl = 0\n",
    "                        for i in range(100):\n",
    "                            p_pred = self.BNet(self.x).numpy()\n",
    "\n",
    "#                             pl += sum([np.log(p_pred[self.y == a]) for a in range(10)])/p_pred.shape[0]\n",
    "\n",
    "                        \n",
    "                            y_hat = np.argmax(p_pred, axis = 1)\n",
    "                        \n",
    "                            acc += (self.y.numpy() == y_hat).astype(int).mean()\n",
    "                    \n",
    "                        print(colored('learning rate:{}'.format(optimizer.param_groups[0]['lr']), 'blue'))\n",
    "                        print(colored('Train accuracy for iteration {} is {}'.format(n, acc/100), 'red'))\n",
    "#                         print('Predictive log-likelihood for trainat iteration {} is {}'.format(n, pl/100))\n",
    "                    \n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e716c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [10,10]\n",
    "# lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79fed219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  641988.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.09640625\u001b[0m\n",
      "0 10\n",
      "Loss =  3888907.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.21234375\u001b[0m\n",
      "0 20\n",
      "Loss =  3877616.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.17234375\u001b[0m\n",
      "0 30\n",
      "Loss =  3865684.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.2725\u001b[0m\n",
      "0 40\n",
      "Loss =  3854036.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.364375\u001b[0m\n",
      "0 50\n",
      "Loss =  3842904.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.344375\u001b[0m\n",
      "0 60\n",
      "Loss =  3831450.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.4984375\u001b[0m\n",
      "0 70\n",
      "Loss =  3819730.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.46703125\u001b[0m\n",
      "0 80\n",
      "Loss =  3808518.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.50640625\u001b[0m\n",
      "0 90\n",
      "Loss =  3797182.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.61203125\u001b[0m\n",
      "0 100\n",
      "Loss =  3786020.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.613359375\u001b[0m\n",
      "0 110\n",
      "Loss =  3775275.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.65734375\u001b[0m\n",
      "0 120\n",
      "Loss =  3765063.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.66890625\u001b[0m\n",
      "0 130\n",
      "Loss =  3755019.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.6525\u001b[0m\n",
      "0 140\n",
      "Loss =  3744658.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.70703125\u001b[0m\n",
      "0 150\n",
      "Loss =  3734453.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.684375\u001b[0m\n",
      "0 160\n",
      "Loss =  3724202.5\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.757578125\u001b[0m\n",
      "0 170\n",
      "Loss =  3714078.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.655078125\u001b[0m\n",
      "0 180\n",
      "Loss =  3703850.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.741328125\u001b[0m\n",
      "0 190\n",
      "Loss =  3693844.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.709921875\u001b[0m\n",
      "0 200\n",
      "Loss =  3683516.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7665625\u001b[0m\n",
      "0 210\n",
      "Loss =  3674181.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.75703125\u001b[0m\n",
      "0 220\n",
      "Loss =  3665095.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.744140625\u001b[0m\n",
      "0 230\n",
      "Loss =  3655848.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.75140625\u001b[0m\n",
      "0 240\n",
      "Loss =  3646781.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.78046875\u001b[0m\n",
      "0 250\n",
      "Loss =  3637718.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.808984375\u001b[0m\n",
      "0 260\n",
      "Loss =  3628510.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.759453125\u001b[0m\n",
      "0 270\n",
      "Loss =  3619371.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.77875\u001b[0m\n",
      "0 280\n",
      "Loss =  3610161.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.806171875\u001b[0m\n",
      "0 290\n",
      "Loss =  3601089.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.799765625\u001b[0m\n",
      "0 300\n",
      "Loss =  3591974.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.798515625\u001b[0m\n",
      "0 310\n",
      "Loss =  3583651.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.79515625\u001b[0m\n",
      "0 320\n",
      "Loss =  3575464.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.78046875\u001b[0m\n",
      "0 330\n",
      "Loss =  3567265.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.823984375\u001b[0m\n",
      "0 340\n",
      "Loss =  3559152.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.79609375\u001b[0m\n",
      "0 350\n",
      "Loss =  3550966.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8025\u001b[0m\n",
      "0 360\n",
      "Loss =  3542705.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.801953125\u001b[0m\n",
      "0 370\n",
      "Loss =  3534744.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.76125\u001b[0m\n",
      "0 380\n",
      "Loss =  3526425.0\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8021875\u001b[0m\n",
      "0 390\n",
      "Loss =  3518284.0\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7975\u001b[0m\n",
      "0 400\n",
      "Loss =  3510161.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.793203125\u001b[0m\n",
      "0 410\n",
      "Loss =  3502678.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.844296875\u001b[0m\n",
      "0 420\n",
      "Loss =  3495476.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.799140625\u001b[0m\n",
      "0 430\n",
      "Loss =  3488107.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.79453125\u001b[0m\n",
      "0 440\n",
      "Loss =  3480706.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.830390625\u001b[0m\n",
      "0 450\n",
      "Loss =  3473322.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8471875\u001b[0m\n",
      "0 460\n",
      "Loss =  3466018.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.81890625\u001b[0m\n",
      "1 0\n",
      "Loss =  3459546.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.784296875\u001b[0m\n",
      "1 10\n",
      "Loss =  3452185.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.82125\u001b[0m\n",
      "1 20\n",
      "Loss =  3444950.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.842890625\u001b[0m\n",
      "1 30\n",
      "Loss =  3437662.5\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.791484375\u001b[0m\n",
      "1 40\n",
      "Loss =  3430986.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.772890625\u001b[0m\n",
      "1 50\n",
      "Loss =  3424371.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.80984375\u001b[0m\n",
      "1 60\n",
      "Loss =  3417863.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.799375\u001b[0m\n",
      "1 70\n",
      "Loss =  3411203.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.788984375\u001b[0m\n",
      "1 80\n",
      "Loss =  3404764.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.803984375\u001b[0m\n",
      "1 90\n",
      "Loss =  3398111.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78390625\u001b[0m\n",
      "1 100\n",
      "Loss =  3391451.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.840234375\u001b[0m\n",
      "1 110\n",
      "Loss =  3384928.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.85203125\u001b[0m\n",
      "1 120\n",
      "Loss =  3378635.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.798828125\u001b[0m\n",
      "1 130\n",
      "Loss =  3371909.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.795625\u001b[0m\n",
      "1 140\n",
      "Loss =  3365896.5\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.783515625\u001b[0m\n",
      "1 150\n",
      "Loss =  3360137.75\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.813671875\u001b[0m\n",
      "1 160\n",
      "Loss =  3354102.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.80546875\u001b[0m\n",
      "1 170\n",
      "Loss =  3348327.5\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.757734375\u001b[0m\n",
      "1 180\n",
      "Loss =  3342473.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.7921875\u001b[0m\n",
      "1 190\n",
      "Loss =  3336459.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.80890625\u001b[0m\n",
      "1 200\n",
      "Loss =  3330762.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.792890625\u001b[0m\n",
      "1 210\n",
      "Loss =  3324902.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.831875\u001b[0m\n",
      "1 220\n",
      "Loss =  3318885.5\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.790625\u001b[0m\n",
      "1 230\n",
      "Loss =  3313069.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.795\u001b[0m\n",
      "1 240\n",
      "Loss =  3307681.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.797734375\u001b[0m\n",
      "1 250\n",
      "Loss =  3302313.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.838828125\u001b[0m\n",
      "1 260\n",
      "Loss =  3297190.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.816640625\u001b[0m\n",
      "1 270\n",
      "Loss =  3291921.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81640625\u001b[0m\n",
      "1 280\n",
      "Loss =  3286630.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.845859375\u001b[0m\n",
      "1 290\n",
      "Loss =  3281265.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.84890625\u001b[0m\n",
      "1 300\n",
      "Loss =  3276248.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.719453125\u001b[0m\n",
      "1 310\n",
      "Loss =  3270876.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78703125\u001b[0m\n",
      "1 320\n",
      "Loss =  3265658.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78984375\u001b[0m\n",
      "1 330\n",
      "Loss =  3260350.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.806953125\u001b[0m\n",
      "1 340\n",
      "Loss =  3255693.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8065625\u001b[0m\n",
      "1 350\n",
      "Loss =  3250905.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.788125\u001b[0m\n",
      "1 360\n",
      "Loss =  3246123.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8046875\u001b[0m\n",
      "1 370\n",
      "Loss =  3241456.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.813359375\u001b[0m\n",
      "1 380\n",
      "Loss =  3236643.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.828984375\u001b[0m\n",
      "1 390\n",
      "Loss =  3232061.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81390625\u001b[0m\n",
      "1 400\n",
      "Loss =  3227297.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.815234375\u001b[0m\n",
      "1 410\n",
      "Loss =  3222572.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.817265625\u001b[0m\n",
      "1 420\n",
      "Loss =  3218043.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.732265625\u001b[0m\n",
      "1 430\n",
      "Loss =  3213134.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8178125\u001b[0m\n",
      "1 440\n",
      "Loss =  3208937.5\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79078125\u001b[0m\n",
      "1 450\n",
      "Loss =  3204564.5\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.82375\u001b[0m\n",
      "1 460\n",
      "Loss =  3200510.25\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.83125\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.8072)\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  641477.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.10640625\u001b[0m\n",
      "0 10\n",
      "Loss =  3888554.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.172109375\u001b[0m\n",
      "0 20\n",
      "Loss =  3877548.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.25015625\u001b[0m\n",
      "0 30\n",
      "Loss =  3865850.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.30984375\u001b[0m\n",
      "0 40\n",
      "Loss =  3854392.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.31625\u001b[0m\n",
      "0 50\n",
      "Loss =  3843085.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.350078125\u001b[0m\n",
      "0 60\n",
      "Loss =  3831613.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.5090625\u001b[0m\n",
      "0 70\n",
      "Loss =  3820279.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.54015625\u001b[0m\n",
      "0 80\n",
      "Loss =  3808607.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.55625\u001b[0m\n",
      "0 90\n",
      "Loss =  3797382.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.60921875\u001b[0m\n",
      "0 100\n",
      "Loss =  3786080.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.567734375\u001b[0m\n",
      "0 110\n",
      "Loss =  3775601.5\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.66765625\u001b[0m\n",
      "0 120\n",
      "Loss =  3765517.5\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.638125\u001b[0m\n",
      "0 130\n",
      "Loss =  3755515.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.706953125\u001b[0m\n",
      "0 140\n",
      "Loss =  3745252.5\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.684375\u001b[0m\n",
      "0 150\n",
      "Loss =  3734771.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.720390625\u001b[0m\n",
      "0 160\n",
      "Loss =  3724780.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.71046875\u001b[0m\n",
      "0 170\n",
      "Loss =  3714488.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.726328125\u001b[0m\n",
      "0 180\n",
      "Loss =  3704366.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.723984375\u001b[0m\n",
      "0 190\n",
      "Loss =  3694340.5\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.706171875\u001b[0m\n",
      "0 200\n",
      "Loss =  3683950.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.775234375\u001b[0m\n",
      "0 210\n",
      "Loss =  3674760.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.76234375\u001b[0m\n",
      "0 220\n",
      "Loss =  3665526.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.814453125\u001b[0m\n",
      "0 230\n",
      "Loss =  3656471.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.776171875\u001b[0m\n",
      "0 240\n",
      "Loss =  3647379.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.75109375\u001b[0m\n",
      "0 250\n",
      "Loss =  3638275.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.754609375\u001b[0m\n",
      "0 260\n",
      "Loss =  3629164.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.767578125\u001b[0m\n",
      "0 270\n",
      "Loss =  3620096.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.772578125\u001b[0m\n",
      "0 280\n",
      "Loss =  3610949.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.784921875\u001b[0m\n",
      "0 290\n",
      "Loss =  3601901.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.76921875\u001b[0m\n",
      "0 300\n",
      "Loss =  3592738.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.764765625\u001b[0m\n",
      "0 310\n",
      "Loss =  3584361.0\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.830234375\u001b[0m\n",
      "0 320\n",
      "Loss =  3576132.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.77546875\u001b[0m\n",
      "0 330\n",
      "Loss =  3568089.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.781015625\u001b[0m\n",
      "0 340\n",
      "Loss =  3560039.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.731875\u001b[0m\n",
      "0 350\n",
      "Loss =  3551657.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7878125\u001b[0m\n",
      "0 360\n",
      "Loss =  3543547.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.749921875\u001b[0m\n",
      "0 370\n",
      "Loss =  3535413.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.780234375\u001b[0m\n",
      "0 380\n",
      "Loss =  3527392.0\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.801796875\u001b[0m\n",
      "0 390\n",
      "Loss =  3518963.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7784375\u001b[0m\n",
      "0 400\n",
      "Loss =  3510896.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.849609375\u001b[0m\n",
      "0 410\n",
      "Loss =  3503549.5\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7846875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 420\n",
      "Loss =  3496130.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.814453125\u001b[0m\n",
      "0 430\n",
      "Loss =  3488908.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.77984375\u001b[0m\n",
      "0 440\n",
      "Loss =  3481439.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.82375\u001b[0m\n",
      "0 450\n",
      "Loss =  3474257.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.799375\u001b[0m\n",
      "0 460\n",
      "Loss =  3466988.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.767578125\u001b[0m\n",
      "1 0\n",
      "Loss =  3460287.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.816875\u001b[0m\n",
      "1 10\n",
      "Loss =  3452981.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.83625\u001b[0m\n",
      "1 20\n",
      "Loss =  3445925.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.811171875\u001b[0m\n",
      "1 30\n",
      "Loss =  3438479.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.784921875\u001b[0m\n",
      "1 40\n",
      "Loss =  3431796.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.790859375\u001b[0m\n",
      "1 50\n",
      "Loss =  3425275.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.77671875\u001b[0m\n",
      "1 60\n",
      "Loss =  3418575.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.84703125\u001b[0m\n",
      "1 70\n",
      "Loss =  3412128.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.773125\u001b[0m\n",
      "1 80\n",
      "Loss =  3405450.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81\u001b[0m\n",
      "1 90\n",
      "Loss =  3398972.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.766328125\u001b[0m\n",
      "1 100\n",
      "Loss =  3392418.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.80203125\u001b[0m\n",
      "1 110\n",
      "Loss =  3385972.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.80859375\u001b[0m\n",
      "1 120\n",
      "Loss =  3379281.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.83671875\u001b[0m\n",
      "1 130\n",
      "Loss =  3372836.75\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.782109375\u001b[0m\n",
      "1 140\n",
      "Loss =  3366985.75\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.743125\u001b[0m\n",
      "1 150\n",
      "Loss =  3360847.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.810703125\u001b[0m\n",
      "1 160\n",
      "Loss =  3355018.75\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.805\u001b[0m\n",
      "1 170\n",
      "Loss =  3349177.75\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.784296875\u001b[0m\n",
      "1 180\n",
      "Loss =  3343182.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.812578125\u001b[0m\n",
      "1 190\n",
      "Loss =  3337379.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8140625\u001b[0m\n",
      "1 200\n",
      "Loss =  3331604.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79859375\u001b[0m\n",
      "1 210\n",
      "Loss =  3325670.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.799921875\u001b[0m\n",
      "1 220\n",
      "Loss =  3319867.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.810859375\u001b[0m\n",
      "1 230\n",
      "Loss =  3313972.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78203125\u001b[0m\n",
      "1 240\n",
      "Loss =  3308638.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8065625\u001b[0m\n",
      "1 250\n",
      "Loss =  3303309.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79953125\u001b[0m\n",
      "1 260\n",
      "Loss =  3298030.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.822265625\u001b[0m\n",
      "1 270\n",
      "Loss =  3292774.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8303125\u001b[0m\n",
      "1 280\n",
      "Loss =  3287565.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.809609375\u001b[0m\n",
      "1 290\n",
      "Loss =  3282244.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81140625\u001b[0m\n",
      "1 300\n",
      "Loss =  3277310.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.785859375\u001b[0m\n",
      "1 310\n",
      "Loss =  3271946.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78\u001b[0m\n",
      "1 320\n",
      "Loss =  3266509.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.848359375\u001b[0m\n",
      "1 330\n",
      "Loss =  3261332.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8221875\u001b[0m\n",
      "1 340\n",
      "Loss =  3256609.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.788125\u001b[0m\n",
      "1 350\n",
      "Loss =  3251962.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79921875\u001b[0m\n",
      "1 360\n",
      "Loss =  3247048.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.82640625\u001b[0m\n",
      "1 370\n",
      "Loss =  3242302.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81875\u001b[0m\n",
      "1 380\n",
      "Loss =  3237763.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.835390625\u001b[0m\n",
      "1 390\n",
      "Loss =  3232821.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.811640625\u001b[0m\n",
      "1 400\n",
      "Loss =  3228342.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.827578125\u001b[0m\n",
      "1 410\n",
      "Loss =  3223447.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.7896875\u001b[0m\n",
      "1 420\n",
      "Loss =  3218768.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.774453125\u001b[0m\n",
      "1 430\n",
      "Loss =  3214158.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.828359375\u001b[0m\n",
      "1 440\n",
      "Loss =  3209656.0\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.85578125\u001b[0m\n",
      "1 450\n",
      "Loss =  3205511.5\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.849921875\u001b[0m\n",
      "1 460\n",
      "Loss =  3201408.5\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.771953125\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.8191)\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "0 0\n",
      "Loss =  641662.375\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.103828125\u001b[0m\n",
      "0 10\n",
      "Loss =  3888641.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.15390625\u001b[0m\n",
      "0 20\n",
      "Loss =  3878018.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.229609375\u001b[0m\n",
      "0 30\n",
      "Loss =  3866150.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.26578125\u001b[0m\n",
      "0 40\n",
      "Loss =  3854502.25\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.344453125\u001b[0m\n",
      "0 50\n",
      "Loss =  3843131.0\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.4228125\u001b[0m\n",
      "0 60\n",
      "Loss =  3831659.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.444921875\u001b[0m\n",
      "0 70\n",
      "Loss =  3820292.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.531171875\u001b[0m\n",
      "0 80\n",
      "Loss =  3808962.5\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.61734375\u001b[0m\n",
      "0 90\n",
      "Loss =  3797598.75\n",
      "\u001b[34mlearning rate:0.001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.617734375\u001b[0m\n",
      "0 100\n",
      "Loss =  3786011.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.657421875\u001b[0m\n",
      "0 110\n",
      "Loss =  3775793.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.66625\u001b[0m\n",
      "0 120\n",
      "Loss =  3765544.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.669140625\u001b[0m\n",
      "0 130\n",
      "Loss =  3755430.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.698828125\u001b[0m\n",
      "0 140\n",
      "Loss =  3745116.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.719375\u001b[0m\n",
      "0 150\n",
      "Loss =  3734918.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.736484375\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 160\n",
      "Loss =  3724856.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.679375\u001b[0m\n",
      "0 170\n",
      "Loss =  3714560.25\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.721328125\u001b[0m\n",
      "0 180\n",
      "Loss =  3704439.75\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.73765625\u001b[0m\n",
      "0 190\n",
      "Loss =  3694346.0\n",
      "\u001b[34mlearning rate:0.0009000000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.697265625\u001b[0m\n",
      "0 200\n",
      "Loss =  3683954.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.76796875\u001b[0m\n",
      "0 210\n",
      "Loss =  3674789.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.752265625\u001b[0m\n",
      "0 220\n",
      "Loss =  3665604.25\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.773359375\u001b[0m\n",
      "0 230\n",
      "Loss =  3656364.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.78796875\u001b[0m\n",
      "0 240\n",
      "Loss =  3647222.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.782734375\u001b[0m\n",
      "0 250\n",
      "Loss =  3638317.5\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.74265625\u001b[0m\n",
      "0 260\n",
      "Loss =  3629180.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.759375\u001b[0m\n",
      "0 270\n",
      "Loss =  3619874.75\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.811484375\u001b[0m\n",
      "0 280\n",
      "Loss =  3610829.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.78734375\u001b[0m\n",
      "0 290\n",
      "Loss =  3601826.0\n",
      "\u001b[34mlearning rate:0.0008100000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.80140625\u001b[0m\n",
      "0 300\n",
      "Loss =  3592622.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.7884375\u001b[0m\n",
      "0 310\n",
      "Loss =  3584381.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.768671875\u001b[0m\n",
      "0 320\n",
      "Loss =  3576093.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.80625\u001b[0m\n",
      "0 330\n",
      "Loss =  3568013.5\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.826640625\u001b[0m\n",
      "0 340\n",
      "Loss =  3559979.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.762734375\u001b[0m\n",
      "0 350\n",
      "Loss =  3551506.75\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.79296875\u001b[0m\n",
      "0 360\n",
      "Loss =  3543402.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.80125\u001b[0m\n",
      "0 370\n",
      "Loss =  3535262.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.8059375\u001b[0m\n",
      "0 380\n",
      "Loss =  3526985.0\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.855625\u001b[0m\n",
      "0 390\n",
      "Loss =  3519027.25\n",
      "\u001b[34mlearning rate:0.000729\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.74546875\u001b[0m\n",
      "0 400\n",
      "Loss =  3510727.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.81875\u001b[0m\n",
      "0 410\n",
      "Loss =  3503356.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.79421875\u001b[0m\n",
      "0 420\n",
      "Loss =  3495943.5\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.776796875\u001b[0m\n",
      "0 430\n",
      "Loss =  3488661.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.801328125\u001b[0m\n",
      "0 440\n",
      "Loss =  3481279.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.824296875\u001b[0m\n",
      "0 450\n",
      "Loss =  3474027.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.863203125\u001b[0m\n",
      "0 460\n",
      "Loss =  3466750.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 0 is 0.818046875\u001b[0m\n",
      "1 0\n",
      "Loss =  3460247.25\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.751953125\u001b[0m\n",
      "1 10\n",
      "Loss =  3453020.75\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78375\u001b[0m\n",
      "1 20\n",
      "Loss =  3445587.5\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.779609375\u001b[0m\n",
      "1 30\n",
      "Loss =  3438413.0\n",
      "\u001b[34mlearning rate:0.0006561000000000001\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.804453125\u001b[0m\n",
      "1 40\n",
      "Loss =  3431525.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.823203125\u001b[0m\n",
      "1 50\n",
      "Loss =  3425173.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.7740625\u001b[0m\n",
      "1 60\n",
      "Loss =  3418339.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.840234375\u001b[0m\n",
      "1 70\n",
      "Loss =  3411853.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8346875\u001b[0m\n",
      "1 80\n",
      "Loss =  3405356.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.830625\u001b[0m\n",
      "1 90\n",
      "Loss =  3398881.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.77921875\u001b[0m\n",
      "1 100\n",
      "Loss =  3392281.25\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.805625\u001b[0m\n",
      "1 110\n",
      "Loss =  3385618.5\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.843046875\u001b[0m\n",
      "1 120\n",
      "Loss =  3379141.0\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78859375\u001b[0m\n",
      "1 130\n",
      "Loss =  3372587.75\n",
      "\u001b[34mlearning rate:0.00059049\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.836796875\u001b[0m\n",
      "1 140\n",
      "Loss =  3366562.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8075\u001b[0m\n",
      "1 150\n",
      "Loss =  3360737.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.809375\u001b[0m\n",
      "1 160\n",
      "Loss =  3354910.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79609375\u001b[0m\n",
      "1 170\n",
      "Loss =  3349119.5\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.755\u001b[0m\n",
      "1 180\n",
      "Loss =  3343172.25\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8346875\u001b[0m\n",
      "1 190\n",
      "Loss =  3337167.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.866171875\u001b[0m\n",
      "1 200\n",
      "Loss =  3331363.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.826796875\u001b[0m\n",
      "1 210\n",
      "Loss =  3325624.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.807421875\u001b[0m\n",
      "1 220\n",
      "Loss =  3319642.0\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.792109375\u001b[0m\n",
      "1 230\n",
      "Loss =  3313733.5\n",
      "\u001b[34mlearning rate:0.000531441\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.843046875\u001b[0m\n",
      "1 240\n",
      "Loss =  3308472.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.79515625\u001b[0m\n",
      "1 250\n",
      "Loss =  3303092.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.84265625\u001b[0m\n",
      "1 260\n",
      "Loss =  3297838.5\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.7996875\u001b[0m\n",
      "1 270\n",
      "Loss =  3292701.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.833984375\u001b[0m\n",
      "1 280\n",
      "Loss =  3287426.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.7671875\u001b[0m\n",
      "1 290\n",
      "Loss =  3282100.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.770703125\u001b[0m\n",
      "1 300\n",
      "Loss =  3276958.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.793671875\u001b[0m\n",
      "1 310\n",
      "Loss =  3271755.75\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.755546875\u001b[0m\n",
      "1 320\n",
      "Loss =  3266336.25\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.828203125\u001b[0m\n",
      "1 330\n",
      "Loss =  3261102.0\n",
      "\u001b[34mlearning rate:0.0004782969\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.84953125\u001b[0m\n",
      "1 340\n",
      "Loss =  3256343.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.779453125\u001b[0m\n",
      "1 350\n",
      "Loss =  3251664.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.791640625\u001b[0m\n",
      "1 360\n",
      "Loss =  3246891.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.81328125\u001b[0m\n",
      "1 370\n",
      "Loss =  3242093.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.8196875\u001b[0m\n",
      "1 380\n",
      "Loss =  3237371.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.814765625\u001b[0m\n",
      "1 390\n",
      "Loss =  3232655.25\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.822890625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 400\n",
      "Loss =  3227979.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.766328125\u001b[0m\n",
      "1 410\n",
      "Loss =  3223307.5\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.790078125\u001b[0m\n",
      "1 420\n",
      "Loss =  3218537.0\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.865234375\u001b[0m\n",
      "1 430\n",
      "Loss =  3213826.75\n",
      "\u001b[34mlearning rate:0.00043046721\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.875546875\u001b[0m\n",
      "1 440\n",
      "Loss =  3209487.25\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.83109375\u001b[0m\n",
      "1 450\n",
      "Loss =  3205450.0\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.78359375\u001b[0m\n",
      "1 460\n",
      "Loss =  3201015.25\n",
      "\u001b[34mlearning rate:0.000387420489\u001b[0m\n",
      "\u001b[31mTrain accuracy for iteration 1 is 0.796640625\u001b[0m\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "tensor(0.7955)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for lr in [1e-3, 1e-4, 1e-5]:\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    #print(colored(\"\\n\\n Start training for lr = {} and hidden_layer size = {}\\n\\n\".format(lr, l), 'green'))\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    model = BNN(train_loader, [784, 800, 800, 10], act = nn.ReLU(), n_epochs = 2)\n",
    "    model.train(lr = 1e-3, decay = 0.9)\n",
    "    #models.append(model)\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    \n",
    "    for _, (example_data, example_targets) in enumerate(test_loader):\n",
    "        A = example_data\n",
    "        b = example_targets\n",
    "    z = model.BNet(A).detach()\n",
    "    T_pred = torch.argmax(z, dim = 1)\n",
    "    print((T_pred == b).sum()/len(T_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dd5e97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  2, -1,  3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.clamp(torch.tensor([3,2,-1,6]), max = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a40625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
