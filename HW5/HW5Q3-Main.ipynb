{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb1cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal as Gaussian\n",
    "import time\n",
    "from scipy.stats import logistic, truncnorm, multivariate_normal\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d109d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(y):\n",
    "    O = np.zeros(y.shape)\n",
    "    I = (y>=0)\n",
    "    J = (y<0)\n",
    "    O[I] = 1/(1+np.exp(-y[I]))\n",
    "    O[J] = np.exp(y[J])/(1+np.exp(y[J]))\n",
    "    return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1d8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma__ = lambda z: logistic.cdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21148aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt(\"data/bank-note/train.csv\", dtype = float, delimiter = ',')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bee1b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.hstack((np.ones((data.shape[0],1)), data))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7cbadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((872, 5), (872,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[:,:-1]\n",
    "label_train = data[:,-1].astype(int)\n",
    "data_train.shape, label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960300e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ = np.genfromtxt(\"data/bank-note/test.csv\", dtype = float, delimiter = ',')\n",
    "test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc17037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ = np.hstack((np.ones((test_.shape[0],1)), test_))\n",
    "test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361ed109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 5), (500,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_[:,:-1]\n",
    "label = test_[:,-1].astype(int)\n",
    "test.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_(x, t, w):\n",
    "    s_ = x @ w\n",
    "    y_ = sigma(s_)\n",
    "    I = (t == 0)\n",
    "    y_[I] = 1-y_[I]\n",
    "    y_ = np.log(y_+1e-10)\n",
    "    return -y_.sum() + 0.5 * np.dot(w,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085b66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = lambda w: nll_(data_train, label_train, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21994dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_train.shape[1]\n",
    "mu = np.zeros(d)\n",
    "M = np.eye(d)\n",
    "M_inv = np.linalg.inv(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = lambda r : 0.5 * r @ M_inv @ r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d35058ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = lambda w : nll(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a55bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dU_(x, t, w):\n",
    "    y = t - sigma(x@w)\n",
    "    return w - x.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2c8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dU = lambda w : dU_(data_train, label_train, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8edda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lambda w, r : U(w) + K(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91798aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leapfrog(eps, w, r, dU = dU):\n",
    "    r_half = r - eps * dU(w)/2\n",
    "    w_new = w + eps * M_inv @ r_half\n",
    "    r_new = r_half - eps * dU(w_new)/2\n",
    "    return w_new, r_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b166dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_step_Leapfrog(w, r, eps, L):\n",
    "    r_ = r.copy()\n",
    "    w_ = w.copy()\n",
    "    for l in range(L):\n",
    "        w_, r_ = Leapfrog(eps = eps, w = w_, r = r_)\n",
    "    return w_ , r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92db18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMC(w_0, r_pdf = Gaussian, L = 10, eps = 0.01, \n",
    "        n_sample = 10000, burn_in_after = 10**5, pick_every = 10, display = True):\n",
    "    \n",
    "    Sample_points = []\n",
    "    iteration = -1\n",
    "    c = -1\n",
    "    sampled = 0\n",
    "    w_new = w_0.copy()\n",
    "    \n",
    "    while sampled <= n_sample and iteration < 200000:\n",
    "        iteration += 1\n",
    "        r_0 = r_pdf(mu, M)\n",
    "        w_new, r_new = L_step_Leapfrog(eps = eps, w = w_0, r = r_0, L = L)\n",
    "        \n",
    "        log_p = np.log(np.random.uniform(0,1))\n",
    "        log_q = H(w_0, r_0) - H(w_new, -r_new) \n",
    "        if log_p <= log_q:\n",
    "            c += 1\n",
    "            if display and (iteration % 10000 == 0):\n",
    "                print('Iteration is {}, number of accepted points is {}'.format(iteration, c))\n",
    "                \n",
    "            if iteration == burn_in_after:\n",
    "                print('Burn-in stage started!')\n",
    "                \n",
    "            if iteration >= burn_in_after:\n",
    "                if sampled % 10 == 0:\n",
    "                    Sample_points.append(w_new.copy())\n",
    "                    w_0 = w_new.copy()\n",
    "                sampled += 1\n",
    "            else:\n",
    "                w_0 = w_new.copy()\n",
    "                \n",
    "    if len(Sample_points) == 0:\n",
    "        Sample_points.append(w_new.copy())\n",
    "        print(colored('acceptance rate is ZERO!!', 'red'))\n",
    "                    \n",
    "    return np.array(Sample_points), c/iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d249d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [0.005, 0.01, 0.02, 0.05]\n",
    "L_list = [10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2a6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, t, w, f = sigma):\n",
    "    y = f(x @ w)\n",
    "    l_pred = (y >= 0.5).astype(int)\n",
    "    return (t == l_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e23e5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_likelihood(x, t, w, f= sigma):\n",
    "    y = f(x @ w)\n",
    "    I = (t == 0)\n",
    "    y[I] = 1 - y[I]\n",
    "    return y.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24365ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictive_likelihood(x, t, w, f= sigma):\n",
    "    y = f(x@w)\n",
    "    I = (t == 0)\n",
    "    y[I] = 1 - y[I]\n",
    "    y = np.log(y)\n",
    "    return y.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36408d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.005 and L: 10\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.005 and L = 10 is 517.7730922698975\n",
      "Acceptance rate: 0.9984715284715284\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.005 and L = 10 is -0.031044802106972993\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.005 and L = 10 is 0.9887272727272726\u001b[0m\n",
      "Emperical mean is:  [ 2.89527225 -2.61487265 -1.48940474 -1.80841787 -0.08164588]\n",
      "eps: 0.005 and L: 20\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.005 and L = 20 is 973.8321611881256\n",
      "Acceptance rate: 0.9992607392607392\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.005 and L = 20 is -0.02993368366148391\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.005 and L = 20 is 0.9887272727272727\u001b[0m\n",
      "Emperical mean is:  [ 2.89267323 -2.73551013 -1.45113489 -1.78636197 -0.0788671 ]\n",
      "eps: 0.005 and L: 50\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.005 and L = 50 is 2444.69638299942\n",
      "Acceptance rate: 0.9988711288711288\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.005 and L = 50 is -0.03170123112682328\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.005 and L = 50 is 0.9905454545454545\u001b[0m\n",
      "Emperical mean is:  [ 2.78815142 -2.6846012  -1.7049756  -1.96703701 -0.34047011]\n",
      "eps: 0.01 and L: 10\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.01 and L = 10 is 524.0571129322052\n",
      "Acceptance rate: 0.9964335664335664\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.01 and L = 10 is -0.028425985446085645\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.01 and L = 10 is 0.9881818181818179\u001b[0m\n",
      "Emperical mean is:  [ 3.5984885  -2.90460384 -1.62465371 -2.00026112  0.10973764]\n",
      "eps: 0.01 and L: 20\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.01 and L = 20 is 1083.7294700145721\n",
      "Acceptance rate: 0.9959640762829542\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.01 and L = 20 is -0.033669302581908415\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.01 and L = 20 is 0.9894545454545457\u001b[0m\n",
      "Emperical mean is:  [ 2.71762801 -2.49211366 -1.63058755 -1.82577998 -0.29521406]\n",
      "eps: 0.01 and L: 50\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.01 and L = 50 is 2487.4950137138367\n",
      "Acceptance rate: 0.9951049440065534\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.01 and L = 50 is -0.02959154041182951\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.01 and L = 50 is 0.988909090909091\u001b[0m\n",
      "Emperical mean is:  [ 3.05829022 -2.9982526  -1.87938406 -2.13580538 -0.25363048]\n",
      "eps: 0.02 and L: 10\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.02 and L = 10 is 505.79063510894775\n",
      "Acceptance rate: 0.984065934065934\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.02 and L = 10 is -0.03343021283115493\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.02 and L = 10 is 0.9876363636363638\u001b[0m\n",
      "Emperical mean is:  [ 2.64320109 -3.02534336 -1.87835465 -2.21763822 -0.39684017]\n",
      "eps: 0.02 and L: 20\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.02 and L = 20 is 1032.1218807697296\n",
      "Acceptance rate: 0.9789314898803221\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.02 and L = 20 is -0.03092510160172818\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.02 and L = 20 is 0.9883636363636363\u001b[0m\n",
      "Emperical mean is:  [ 2.86984455 -2.94686667 -1.74471858 -2.08743077 -0.23820889]\n",
      "eps: 0.02 and L: 50\n",
      "Burn-in stage started!\n",
      "Running time for eps = 0.02 and L = 50 is 2573.7114408016205\n",
      "Acceptance rate: 0.980480300487493\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.02 and L = 50 is -0.030294708615908883\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.02 and L = 50 is 0.9874545454545456\u001b[0m\n",
      "Emperical mean is:  [ 2.94712703 -2.93823008 -1.70524062 -2.03816666 -0.21170203]\n",
      "eps: 0.05 and L: 10\n",
      "\u001b[31macceptance rate is ZERO!!\u001b[0m\n",
      "Running time for eps = 0.05 and L = 10 is 1138.877209186554\n",
      "Acceptance rate: -5e-06\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.05 and L = 10 is -0.24005012579799798\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.05 and L = 10 is 0.966\u001b[0m\n",
      "Emperical mean is:  [  3.62270329 -19.41307566  -8.86043249 -10.8355991   -4.87018692]\n",
      "eps: 0.05 and L: 20\n",
      "\u001b[31macceptance rate is ZERO!!\u001b[0m\n",
      "Running time for eps = 0.05 and L = 20 is 2247.9701759815216\n",
      "Acceptance rate: -5e-06\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.05 and L = 20 is -0.5537632558655898\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.05 and L = 20 is 0.966\u001b[0m\n",
      "Emperical mean is:  [ 16.49072021 -36.3585016  -27.61946602 -24.08211023  -9.62075221]\n",
      "eps: 0.05 and L: 50\n",
      "\u001b[31macceptance rate is ZERO!!\u001b[0m\n",
      "Running time for eps = 0.05 and L = 50 is 4845.927500963211\n",
      "Acceptance rate: -5e-06\n",
      "\u001b[31mTest predictive log-likelihood for eps = 0.05 and L = 50 is -0.25584281169557904\u001b[0m\n",
      "\u001b[31mTest predictive accuracy for eps = 0.05 and L = 50 is 0.986\u001b[0m\n",
      "Emperical mean is:  [ 29.70140064 -25.98189086 -18.88693858 -18.10660091  -8.50399153]\n"
     ]
    }
   ],
   "source": [
    "S_list = []\n",
    "for eps in eps_list:\n",
    "    for L in L_list:\n",
    "        print('eps: {} and L: {}'.format(eps, L))\n",
    "        t = time.time()\n",
    "        S, p = HMC(w_0 = np.zeros(d), L = L, eps = eps, \n",
    "                   n_sample = 100, burn_in_after = 10**5, pick_every = 10, display = False)\n",
    "        print('Running time for eps = {} and L = {} is {}'.format(eps, L, time.time()-t))\n",
    "        print('Acceptance rate: {}'.format(p))\n",
    "        S_list.append(S)\n",
    "        \n",
    "        av = 0\n",
    "        av_log = 0\n",
    "        mean = np.zeros(d)\n",
    "        for i in range(len(S)):\n",
    "            mean += S[i]/len(S)\n",
    "            av_log += log_predictive_likelihood(x = test, t = label, w = S[i])\n",
    "            av += predict(x = test, t = label, w = S[i])\n",
    "\n",
    "        print(colored('Test predictive log-likelihood for eps = {} and L = {} is {}'.format(eps, L, \n",
    "                                                                                            av_log/len(S)), 'red'))\n",
    "        print(colored('Test predictive accuracy for eps = {} and L = {} is {}'.format(eps, L, av/len(S)),'red'))\n",
    "        print('Emperical mean is: ', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01b6acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599454"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_predictive_likelihood(x = test, t = label, w = np.zeros(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73ea8e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.442"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x = test, t = label, w = np.zeros(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553a295",
   "metadata": {},
   "source": [
    "## (b) Gibbs sampling for the Bayesian probit model with augmented variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d613bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncnorm.rvs(a = 0, b= np.inf, loc=0, scale=1, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb2c0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d = data_train.shape\n",
    "S_inv = np.eye(d) + data_train.T @ data_train\n",
    "S = np.linalg.inv(S_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045053d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Z_update_(w, x, t):\n",
    "    Z = np.zeros(N)\n",
    "    mu = x @ w\n",
    "    for i in range(N):\n",
    "            Z[i] = (2*t[i]-1)*truncnorm.rvs(a = 0, b = np.inf, loc=mu[i], scale=1, size=1)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25c5388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Z_update(w, x, t):\n",
    "    mu_ = x @ w\n",
    "    mu_ *= (2*t-1)\n",
    "    #a_ = np.zeros(N)\n",
    "    b_ = np.inf * np.ones(N)\n",
    "    Z = (2*t-1) * truncnorm.rvs(a = -mu_, b = b_, loc = mu_, scale=1)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e400986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _w_update(z):\n",
    "    mu_ = S @ data_train.T @ z\n",
    "    w = Gaussian(mean = mu_, cov = S)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba48b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gibbs_sampling(x = data_train, t = label_train, burn_in_at = 10**5, n_samples = 1000, pick_every  =10):\n",
    "    w_ = np.random.normal(0,1, size = d)\n",
    "    itr = 0\n",
    "    while itr< burn_in_at:\n",
    "        if itr % 10000 ==0:\n",
    "            print('Iteration {} has started!'.format(itr+1))\n",
    "        z_ = _Z_update(w_, x, t)\n",
    "        w_ = _w_update(z_)\n",
    "        itr += 1\n",
    "    itr = 0\n",
    "    w_Samples = []\n",
    "    z_Samples = []\n",
    "    print('burned in')\n",
    "    while itr < n_samples * pick_every:\n",
    "        if itr % pick_every == 0:\n",
    "            w_Samples.append(w_.copy())\n",
    "            z_Samples.append(z_.copy())\n",
    "        z_ = _Z_update(w_, x, t)\n",
    "        w_ = _w_update(z_)\n",
    "        itr += 1\n",
    "    return w_Samples, z_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2efb990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 has started!\n",
      "Iteration 10001 has started!\n",
      "Iteration 20001 has started!\n",
      "Iteration 30001 has started!\n",
      "Iteration 40001 has started!\n",
      "Iteration 50001 has started!\n",
      "Iteration 60001 has started!\n",
      "Iteration 70001 has started!\n",
      "Iteration 80001 has started!\n",
      "Iteration 90001 has started!\n",
      "burned in\n",
      "4483.266856908798\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "W, Z = Gibbs_sampling(burn_in_at = 10**5, n_samples = 1000, pick_every  =10)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28f3d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "pll = 0\n",
    "K = len(W)\n",
    "for w in W:\n",
    "    pll += log_predictive_likelihood(x = test, t = label, w = W[i], f=multivariate_normal.cdf)/K\n",
    "    acc += predict(x = test, t = label, w = W[i], f=multivariate_normal.cdf)/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0f6c4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9879999999999906, -0.02897856072681373)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, pll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af74cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.18676179, -2.14897079, -1.30251199, -1.5515661 , -0.1651304 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(W).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52687377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
